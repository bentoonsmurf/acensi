{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6546abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importation des librairies \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score,precision_score,recall_score, precision_recall_fscore_support \n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn_som.som import SOM\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from GEM.gem.utils      import graph_util, plot_util\n",
    "from GEM.gem.evaluation import visualize_embedding as viz\n",
    "from GEM.gem.evaluation import evaluate_graph_reconstruction as gr\n",
    "from GEM.gem.embedding.gf       import GraphFactorization\n",
    "#from GEM.gem.embedding.sdne     import SDNE\n",
    "from argparse import ArgumentParser\n",
    "from GraphEmbedding.ge import DeepWalk\n",
    "#from GraphEmbedding.ge import SDNE \n",
    "#https://github.com/shenweichen/GraphEmbedding/blob/master/ge/models/sdne.py\n",
    "\n",
    "\n",
    "num_frame=200#arbitraire , a tester plus serieusement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc48bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fonctions declaré a : 11:20:16\n"
     ]
    }
   ],
   "source": [
    "def create_graph(X_train_ultra_simple):\n",
    "    g = nx.Graph()\n",
    "\n",
    "    start = time.time()\n",
    "    i=0\n",
    "    while (i<len(X_train_ultra_simple)):\n",
    "        a=X_train_ultra_simple[\"merchant\"][i]\n",
    "        b=X_train_ultra_simple[\"cc_num\"][i]\n",
    "        g.add_edge(a,b,weight=0,edge_id=i)\n",
    "        i=i+1\n",
    "    i=0\n",
    "    while (i<len(X_train_ultra_simple)):# on lis 2 fois mais ca coute que 4 sec\n",
    "        a=X_train_ultra_simple[\"merchant\"][i]\n",
    "        b=X_train_ultra_simple[\"cc_num\"][i]\n",
    "        g[a][b][\"weight\"]=g[a][b][\"weight\"]+1 # il falais initialiser en premier\n",
    "        i=i+1\n",
    "    \n",
    "    print(\"---graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return g\n",
    "\n",
    "def fill(g,liste):\n",
    "  \n",
    "    while(liste):\n",
    "        a=liste.pop()\n",
    "        i=0\n",
    "        while(i<len(liste)):\n",
    "            b=liste[i]\n",
    "            g.add_edge(a,b,weight=1)\n",
    "            i+=1\n",
    "    \n",
    "    #return g\n",
    "\n",
    "def invert_graph(g):\n",
    "    new_graph=nx.Graph()\n",
    "    #tous les arc d'un sommet sont connecté entre eux\n",
    "    #step 1 = dans new_graph creer un sommet pour chaque arc\n",
    "    for edge in g.edges:\n",
    "        new_graph.add_node(g[edge[0]][edge[1]][\"edge_id\"])\n",
    "    #pour chaque node de g relier enssemble tous les arc\n",
    "    for node in g.nodes:\n",
    "        dico=dict(g[node])# traitement de 1 node\n",
    "        node_list=[]\n",
    "        for key in dico:\n",
    "\n",
    "            node_id=g[node][key][\"edge_id\"]\n",
    "            node_list.append(node_id)\n",
    "        fill(new_graph,node_list)\n",
    "\n",
    "\n",
    "    return new_graph\n",
    "\n",
    "def init_sub_graph(nb_frames):\n",
    "    # divison en plusieures sous graphs \n",
    "    sous_graph=[]\n",
    "    i=0\n",
    "    i2=0\n",
    "    sub_g=0\n",
    "    while ( i<num_frame):\n",
    "        sous_graph.append(nx.Graph())\n",
    "        i=i+1\n",
    "    return sous_graph\n",
    "\n",
    "def bipartite_dict(dict_merchants,dict_cc_num):\n",
    "\n",
    "    dict_merchants_copy=dict_merchants.copy()\n",
    "    dict_merchants_copy = dict([(value, key) for key, value in dict_merchants_copy.items()])\n",
    "    dict_cc_num_copy=dict_cc_num.copy()\n",
    "    dict_cc_num_copy = dict([(value, key) for key, value in dict_cc_num_copy.items()])\n",
    "\n",
    "    for key in dict_merchants_copy.keys():\n",
    "        dict_merchants_copy[key] = 0\n",
    "    for key in dict_cc_num_copy.keys():\n",
    "        dict_cc_num_copy[key] = 1\n",
    "    return dict_merchants_copy,dict_cc_num_copy\n",
    "\n",
    "def create_sub_graph(g,nb_frames,dict_merchants,dict_cc_num):\n",
    "    sous_graph=init_sub_graph(nb_frames)\n",
    "    dict_merchants_copy,dict_cc_num_copy=bipartite_dict(dict_merchants,dict_cc_num)    \n",
    "    time_frame_size=len(X_train_ultra_simple) / num_frame\n",
    "    start = time.time()\n",
    "    connected_count=0\n",
    "    i=0\n",
    "    i2=0\n",
    "    sub_g=0\n",
    "    while (i<len(X_train_ultra_simple)):\n",
    "        a=X_train_ultra_simple[\"merchant\"][i]# rendre plus lisible\n",
    "        b=X_train_ultra_simple[\"cc_num\"][i]\n",
    "        if(sous_graph[sub_g].has_edge(a,b)):\n",
    "            sous_graph[sub_g][a][b][\"weight\"]=sous_graph[sub_g][a][b][\"weight\"]+1 \n",
    "        else:\n",
    "            sous_graph[sub_g].add_edge(a,b,weight=0)\n",
    "            #sous_graph[sub_g][a][\"bipartite\"]=0\n",
    "            #sous_graph[sub_g][b][\"bipartite\"]=1\n",
    "        i=i+1\n",
    "        i2=i2+1\n",
    "        if i2>= time_frame_size:\n",
    "            nx.set_node_attributes(sous_graph[sub_g], dict_merchants_copy, \"bipartite\")\n",
    "            nx.set_node_attributes(sous_graph[sub_g], dict_cc_num_copy, \"bipartite\")\n",
    "            i2=0\n",
    "            if(nx.is_connected(sous_graph[sub_g])):\n",
    "                connected_count+=1\n",
    "            sub_g=sub_g+1\n",
    "\n",
    "    print(\"---graph split = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "\n",
    "    return sous_graph,connected_count\n",
    "\n",
    "\n",
    "def create_inverted_sub_graph(g,nb_frames,dict_merchants,dict_cc_num):\n",
    "    sous_graph,connected_count=create_sub_graph(g,nb_frames,dict_merchants,dict_cc_num)\n",
    "    inv_sous_graph=[]\n",
    "    for sg in sous_graph:\n",
    "        inv_sous_graph.append(invert_graph(sg))\n",
    "    return inv_sous_graph,connected_count\n",
    "\n",
    "\n",
    "\n",
    "def start_time_eval():\n",
    "    start = time.time()\n",
    "    i=0\n",
    "    while(i<1000000):\n",
    "        i=i+1\n",
    "    boucle_time=time.time() - start\n",
    "    start = time.time()\n",
    "    i=0\n",
    "    while(i<1000000):\n",
    "        poubelle =time.time()\n",
    "        i=i+1\n",
    "    print(\"---1 milion de time.time=  %s seconds ---\" % (time.time() - start-boucle_time));start = time.time()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#return le nombre d'arete du graph weighted_g\n",
    "def nb_edge(weighted_g):\n",
    "    summ=0\n",
    "    NODES = list(weighted_g.nodes)\n",
    "    for node in NODES:\n",
    "        summ= summ+G.degree[node]\n",
    "    return summ/2\n",
    "\n",
    "def replissement(weighted_g, nb_merc,nb_cc_num):\n",
    "    nb_edges=nb_edge(weighted_g)\n",
    "    nb_max_edges =(nb_merc* nb_cc_num)#graph bipati\n",
    "    return  nb_edges / nb_max_edges\n",
    "    \n",
    "def edge_repartition(g,len_dict_merchants):\n",
    "    repartition=[]\n",
    "    #remplissage de repartiotion avec 0 pour eviter les bugg\n",
    "    \n",
    "    #for each vertex \n",
    "        # for each edge in vertex.edges\n",
    "            #repartition[ edge.poid ] ++\n",
    "    print (\"\")\n",
    "    \n",
    "\n",
    "def slow_concat(d1,d2):\n",
    "    return dict(d1.items() | d2.items())\n",
    "\n",
    "def ditc_maping_so_slow_but_why(X_train_ultra_simple,dict_merchants,dict_cc_num):\n",
    "    #---dictionary maping = 4272.313026428223 seconds ---\n",
    "    start = time.time()\n",
    "    size =len(X_train_ultra_simple)\n",
    "    i=0\n",
    "    time_val=[]\n",
    "    while (i<size):\n",
    "        X_train_ultra_simple.iat[i,0]=dict_merchants[X_train_ultra_simple.iat[i,0]]\n",
    "        X_train_ultra_simple.iat[i,1]=dict_cc_num[X_train_ultra_simple.iat[i,1]]\n",
    "        time_val.append(time.time() - start);start = time.time()\n",
    "        i=i+1\n",
    "    return time_val\n",
    "\n",
    "\n",
    "def ditc_maping(X_train_ultra_simple,dict_merchants_cc_num):\n",
    "    X_train_ultra_simple[\"merchant\"].replace(dict_merchants_cc_num, inplace=True)\n",
    "    X_train_ultra_simple[\"cc_num\"].replace(dict_merchants_cc_num, inplace=True)\n",
    "\n",
    "    \n",
    "def create_split_dict(X_train_ultra_simple):\n",
    "    start = time.time()\n",
    "    dict_merchants=dict()\n",
    "    dict_cc_num=dict()\n",
    "    index =0\n",
    "    merc_id=0\n",
    "    cc_id=0\n",
    "    while index < len(X_train_ultra_simple):\n",
    "        if X_train_ultra_simple[\"merchant\"][index] not in dict_merchants.keys():\n",
    "            dict_merchants[X_train_ultra_simple[\"merchant\"][index]] = merc_id\n",
    "            merc_id=merc_id+1\n",
    "        index=index+1\n",
    "\n",
    "    print(\"---remplissage dict_merchants  %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    index=0\n",
    "    while index < len(X_train_ultra_simple):\n",
    "        if X_train_ultra_simple[\"cc_num\"][index] not in dict_cc_num.keys():\n",
    "            dict_cc_num[X_train_ultra_simple[\"cc_num\"][index]] = merc_id\n",
    "            merc_id=merc_id+1\n",
    "        index=index+1\n",
    "\n",
    "    print(\"---remplissage dict_cc_num %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return dict_merchants,dict_cc_num\n",
    "\n",
    "def create_dict(X_train_ultra_simple):\n",
    "    dict_merchants,dict_cc_num=create_split_dict(X_train_ultra_simple)\n",
    "    \n",
    "    return slow_concat(dict_merchants,dict_cc_num)\n",
    "\n",
    "\n",
    "def print_info_diverses(X_train_ultra_simple,dico):\n",
    "    print(X_train_ultra_simple[\"merchant\"][0])\n",
    "    print(X_train_ultra_simple[\"cc_num\"][0])\n",
    "    print(X_train_ultra_simple.columns)\n",
    "    print(X_train_ultra_simple.loc[0][\"merchant\"])\n",
    "\n",
    "    print (len(dico) , \"humans in the system \")#1676\n",
    "    print(X_train_ultra_simple[\"cc_num\"][0])\n",
    "    print (dict_merchants[ \"fraud_Rippin, Kub and Mann\"], type(dico[ \"fraud_Rippin, Kub and Mann\"]))\n",
    "    \n",
    "\n",
    "#laplacian similarity 1/2\n",
    "def select_k(spectrum, minimum_energy = 0.9):#\n",
    "    running_total = 0.0\n",
    "    total = sum(spectrum)\n",
    "    if total == 0.0:\n",
    "        return len(spectrum)\n",
    "    for i in range(len(spectrum)):\n",
    "        running_total += spectrum[i]\n",
    "        if running_total / total >= minimum_energy:\n",
    "            return i + 1\n",
    "    return len(spectrum)\n",
    "\n",
    "#laplacian similarity 2/2\n",
    "def laplacian_similarity(graph1,graph2):\n",
    "    laplacian1 = nx.spectrum.laplacian_spectrum(graph1)\n",
    "    laplacian2 = nx.spectrum.laplacian_spectrum(graph2)\n",
    "\n",
    "    k1 = select_k(laplacian1)\n",
    "    k2 = select_k(laplacian2)\n",
    "    k = min(k1, k2)\n",
    "    print(\"k selected =\",k)\n",
    "    similarity = sum((laplacian1[:k] - laplacian2[:k])**2)\n",
    "    return similarity\n",
    "\n",
    "def string_edit_dist():\n",
    "    print(\"https://anhaidgroup.github.io/py_stringmatching/v0.3.x/Levenshtein.html\")\n",
    "def edit_dist_nx(g1,g2):\n",
    "    \n",
    "    for v in nx.optimize_graph_edit_distance(g1, g2):\n",
    "        minv = v\n",
    "    return minv\n",
    "\n",
    "\n",
    "def print_graph_info(connected_count):\n",
    "    \n",
    "    print(connected_count,\"connected graphs\")\n",
    "    print(len(sous_graph[0].edges),\" transactions \")\n",
    "    print(\"sous_graph[0][0] , type = \",type(sous_graph[0][0]),\"\\n\")\n",
    "    print((sous_graph[0][0]))\n",
    "    print(\"------------\")\n",
    "    sub_g=0;node=0\n",
    "    dico=dict(sous_graph[sub_g][node])\n",
    "    for key in dico:\n",
    "         print(sous_graph[0][0][key],\"key = \",key)\n",
    "    print(dict(sous_graph[0][0]))\n",
    "    print(\"------------\")\n",
    "    print( type(sous_graph[0][0][693]))\n",
    "    print(sous_graph[0][0][693])\n",
    "    print(\"---------\")\n",
    "    print((sous_graph[0].edges))\n",
    "    \n",
    "def draw_1(g):\n",
    "    start = time.time()\n",
    "    #subax1 = plt.subplot()\n",
    "    nx.draw(sous_graph[0], with_labels=False, node_size= 1)\n",
    "    plt.savefig(\"draw_1.png\")\n",
    "    plt.show()\n",
    "    print(\"---draw  %s seconds ---\" % (time.time() - start));start = time.time\n",
    "def draw_2(g):\n",
    "    start = time.time()\n",
    "    #subax2 = plt.subplot()\n",
    "    options = {\n",
    "        'node_size': 100,\n",
    "        'width': 3,\n",
    "    }\n",
    "    nx.draw_spectral(g, **options)#approximation of the ratio cut\n",
    "    plt.savefig(\"draw_2.png\")\n",
    "    plt.show()\n",
    "    print(\"---draw  %s seconds ---\" % (time.time() - start));start = time.time\n",
    "def draw_3(g):\n",
    "    start = time.time()\n",
    "    #subax3 = plt.subplot()\n",
    "\n",
    "    nx.draw_shell(g, with_labels=False,node_size= 1)# font_weight='bold')\n",
    "    plt.savefig(\"draw_3.png\")\n",
    "    plt.show()\n",
    "    print(\"---draw  %s seconds ---\" % (time.time() - start));start = time.time\n",
    "    \n",
    "def draw_4(g,numb_merchant):\n",
    "    start = time.time()\n",
    "    total=len(g.nodes)#les valeures ascossié ne sont pas les bonnes mais c'est \n",
    "    X = list(range(0,numb_merchant ))# juste pour la position geographique \n",
    "    Y= list(range(numb_merchant,total ))\n",
    "    pos = dict()\n",
    "    pos.update( (n, (1, i)) for i, n in enumerate(X) ) # put nodes from X at x=1\n",
    "    pos.update( (n, (2, i)) for i, n in enumerate(Y) ) # put nodes from Y at x=2\n",
    "    nx.draw(g, pos=pos,node_size= 1)\n",
    "    plt.savefig(\"draw_4.png\")\n",
    "    plt.show()\n",
    "    print(\"---draw  %s seconds ---\" % (time.time() - start));start = time.time\n",
    "    \n",
    "def drawing(g):\n",
    "    %matplotlib inline\n",
    "    draw_1(g)\n",
    "    draw_2(g)\n",
    "    draw_3(g)\n",
    "    draw_4(g,len(dict_merchants.keys()))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def complexity_calculations(exec_time=0.5):\n",
    "    val=0\n",
    "    train_size=len(Y_train)\n",
    "    test_size=len(Y_test)\n",
    "    #l'idee premiere\n",
    "    print(\"-----------------\")\n",
    "    print(\"tester la similarité de 1 graph modifié avec un autres :\",exec_time)\n",
    "    print(\"pour \",exec_time,\" sec par calcul et \",num_frame,\" frames\" )\n",
    "    print( num_frame*exec_time,\" sec\")\n",
    "    print(\"-----------------\")\n",
    "    print(\"modifier le graph et recomencer , pour chaques valeures dans train\")\n",
    "    print(\"pour completement calculer  les similarité de 1 transaction\")\n",
    "    print( num_frame*exec_time*train_size,\" sec\")\n",
    "    print(\"donc \",int(num_frame*exe_time*train_size/(3600*24)),\" jours\")\n",
    "    print(\"-----------------\")\n",
    "    \n",
    "    big_number = num_frame*exec_time*train_size*test_size\n",
    "    big_number_year=int(big_number/31540000)\n",
    "    print(\"pour un total de \",big_number,\" sec\")\n",
    "    print(\"donc \",big_number_year,\" ans\")\n",
    "    print(\"-----------------\")\n",
    "    print(\"en reduisant la precision au minimum\")\n",
    "    print(\"chaque transaction n'aura que 1 calcul de similarité\")\n",
    "    print(\"precision max 50% , doubler le temps de calcul double la precision\")\n",
    "    big_number=0.5*test_size\n",
    "    print(\"pour un total de \",big_number,\" sec\")\n",
    "    print(\"donc \",int(big_number/3600),\" heures\")\n",
    "    \n",
    "    \n",
    "print(\"fonctions declaré a :\",time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfab0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28be0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here marks the end of the function\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "###############################################################\n",
    "#here marks the start of the program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728ee61",
   "metadata": {},
   "source": [
    "download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0d7347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long']\n"
     ]
    }
   ],
   "source": [
    "program_start = time.time()\n",
    "\n",
    "import os\n",
    "data_file= os.path.abspath('../../data')\n",
    "full_path=data_file+'\\\\'+'fraudTrain.csv'\n",
    "train_df=pd.read_csv(full_path)\n",
    "full_path=data_file+'\\\\'+'fraudTest.csv'\n",
    "test_df=pd.read_csv(full_path)\n",
    "\n",
    "cols = train_df.columns.tolist()\n",
    "cols = [c for c in cols if c not in [\"is_fraud\"]]\n",
    "target = \"is_fraud\"\n",
    "print(cols)\n",
    "\n",
    "#Definition des nouvelles variables X_train and Y_train\n",
    "X_train = train_df[cols]\n",
    "Y_train = train_df[target]\n",
    "\n",
    "#Definition des nouvelles variables X_test and Y_test\n",
    "X_test = test_df[cols]\n",
    "Y_test = test_df[target]\n",
    "\n",
    "features = [ 'merchant', 'cc_num']\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]\n",
    "\n",
    "X_train_ultra_simple = X_train.copy()\n",
    "X_test_ultra_simple = X_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2157c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---remplissage dict_merchants  16.268182039260864 seconds ---\n",
      "---remplissage dict_cc_num 14.147745847702026 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#remplissage des dictionaires\n",
    "\n",
    "dict_merchants,dict_cc_num=create_split_dict(X_train_ultra_simple)\n",
    "#dictionary=slow_concat(dict_merchants,dict_cc_num)\n",
    "#dictionary=create_dict(X_train_ultra_simple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9bbec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---dictionary maping = 0.0 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# associer a chaque marchant son numero dans le dictionaire\n",
    "#pour la lisibilité , et l'affichage\n",
    "start = time.time()\n",
    "#ditc_maping(X_train_ultra_simple,dictionary)\n",
    "\n",
    "print(\"---dictionary maping = %s seconds ---\" % (time.time() - start));start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca4f56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcbebbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de063ef",
   "metadata": {},
   "source": [
    "\n",
    "    creation du graph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68cfbca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---graph construction = 76.06967902183533 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = create_graph(X_train_ultra_simple)#40 sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23bb77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter notebook --generate-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8075fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---graph split = 41.10678672790527 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# divison en plusieures sous graphs #20 sec\n",
    "\n",
    "sous_graph,connected_count=create_sub_graph(g,num_frame,dict_merchants,dict_cc_num)\n",
    "#sous_graph,connected_count=create_inverted_sub_graph(g,num_frame,dict_merchants,dict_cc_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2115b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour afficher , attention au cascades\n",
    "#!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49384d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 connected graphs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(connected_count,\"connected graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bbd80e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_5568/3997549475.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\BENJAM~1.MAR\\AppData\\Local\\Temp/ipykernel_5568/3997549475.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    exe_time=(time.time() - start):.4\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "#while(i<num_frame):# doesnt work or my graph are the same\n",
    "exe_time=0\n",
    "while(i<3):\n",
    "    start = time.time()\n",
    "\n",
    "    print (\"-------------------------------------\")\n",
    "    #laplacian marche\n",
    "    val = laplacian_similarity(sous_graph[0],sous_graph[i])\n",
    "    #val1=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=60,upper_bound=1e10)\n",
    "    #val2=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=120,upper_bound=1e10)\n",
    "    #val3=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=180,upper_bound=1e10)\n",
    "    #print (\"comparing \",hex(id(sous_graph[0])),\" and \",hex(id(sous_graph[i])))\n",
    "    #print (val1,\" \",val2,\" \",val3) \n",
    "    print(sous_graph[0])\n",
    "    print(sous_graph[i]) \n",
    "    print(\" similarity = \",val)\n",
    "    exe_time=(time.time() - start):.4\n",
    "    print(\"---laplacian similarity = %s seconds ---\" %         f\"{(time.time() - start):.4}\"    );start = time.time()\n",
    "\n",
    "    print (\"-------------------------------------\")\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58fe1cb0",
   "metadata": {},
   "source": [
    "plan,strategie , objectif\n",
    "changement de plan\n",
    "probleme , le poid des arc devien quoi ? \n",
    "comment ajouter amt apres coup , il suffit de l'ajouter sur les donnée\n",
    "avan le SOM\n",
    "                                            probably better\n",
    "j'inverse le graph                |  je le coupe en n sous_graphs\n",
    "je le coupe en n sous_graphs      |  j'inverse les sous_graphs\n",
    "\n",
    "\n",
    "je compresse les sous graphs \n",
    "je SOM sur les cous graphs\n",
    "\n",
    "complexité= O(n*tps_compression + SOM) // SOM = 6min = negligeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a90e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dont_execute():\n",
    "    \"\"\"\n",
    "        ''' Sample usage\n",
    "    python run_karate.py -node2vec 1\n",
    "    '''\n",
    "    parser = ArgumentParser(description='Graph Embedding Experiments on Karate Graph')\n",
    "    parser.add_argument('-node2vec', '--node2vec',\n",
    "                        help='whether to run node2vec (default: False)')\n",
    "    args = vars(parser.parse_args())\n",
    "    try:\n",
    "        run_n2v = bool(int(args[\"node2vec\"]))\n",
    "    except:\n",
    "        run_n2v = False\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "def test_on_list(liste):\n",
    "    i=0\n",
    "    while (i<10):\n",
    "        liste.append(i)\n",
    "        i+=1\n",
    "def int_to_str(G):\n",
    "    # convert nodes from int to str format\n",
    "    keys = np.arange(0,int(len(dictionary.keys())))\n",
    "    values = [str(i) for i in keys]\n",
    "    dic = dict(zip(keys, values))\n",
    "    H = nx.relabel_nodes(G, dic)\n",
    "\n",
    "def my_fun():\n",
    "    print('How many cats do you have?\\n')\n",
    "    numCats = input()\n",
    "    try:\n",
    "        if int(numCats) > 3:\n",
    "            print('That is a lot of cats.')\n",
    "        else:\n",
    "            print('That is not that many cats.')\n",
    "    except ValueError:\n",
    "        print(\"Value error\")  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24566e9",
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"---depuis le debut  %s seconds ---\" % (time.time() - program_start));start = time.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/shenweichen/GraphEmbedding.git\n",
    " \n",
    "#!cd GraphEmbedding/\n",
    "#!python setup.py install\n",
    "#!pip install -U gensim\n",
    "#!pip install smart_open[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_embeding(liste,sous_graph):\n",
    "    i=0\n",
    "    num_frame=len(sous_graph)\n",
    "    G = sous_graph[i]\n",
    "    model = DeepWalk(G, walk_length=10, num_walks=80, workers=3)\n",
    "    model.train(window_size=5,iter=3) \n",
    "    liste.append(model.get_embeddings())\n",
    "    i+=1\n",
    "    while (i<num_frame):\n",
    "\n",
    "        # train the model and generate embeddings\n",
    "        G = sous_graph[i]\n",
    "        model = DeepWalk(G, walk_length=10, num_walks=80, workers=3)\n",
    "        model.train(window_size=5,iter=3) \n",
    "        liste.append(model.get_embeddings())\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de05b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedings=list()\n",
    "#all_embeding(embedings,sous_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_embeding(embedings,sous_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b61c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cdd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage\n",
    "print(sous_graph[0])\n",
    "#drawing(sous_graph[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d425f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sous_graph[0].nodes))\n",
    "print(len(g.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5f40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cdda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#370 MiB = 300 000 Mo\n",
    "# avec g/200 ca compile , tres .... lentement , mais ca compile\n",
    "too_long=True\n",
    "if(not too_long):\n",
    "    val = edit_dist_nx(sous_graph[0],sous_graph[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada9777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb057eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419c3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( type(sous_graph[0][1][694]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e786d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_info(connected_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8874c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modif_graph_testing(graph):\n",
    "    graph[1][2][\"weight\"]=2\n",
    "    \n",
    "def invert_node_testing():\n",
    "    graph=nx.Graph()\n",
    "    graph.add_nodes_from([0,1,2,3,4])\n",
    "    graph.add_edge(0,1,weight=0,edge_id=\"a\")\n",
    "    graph.add_edge(1,2,weight=0,edge_id=\"b\")\n",
    "    graph.add_edge(2,3,weight=0,edge_id=\"c\")\n",
    "    graph.add_edge(3,4,weight=0,edge_id=\"d\")\n",
    "    graph.add_edge(4,2,weight=0,edge_id=\"e\")\n",
    "    print(graph.nodes)\n",
    "    print(graph.edges)\n",
    "    print(\"avan 1--2--3--4\")\n",
    "    new_graph=invert_graph(graph)\n",
    "    print(\"apres 1--2--3--4\")\n",
    "    print(new_graph.nodes)\n",
    "    print(new_graph.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=nx.Graph()\n",
    "graph.add_edge(1,2,weight=0)\n",
    "\n",
    "\n",
    "print(graph[1][2])\n",
    "modif_graph_testing(graph)\n",
    "\n",
    "print(graph[1][2])\n",
    "invert_node_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce8c946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41053a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3821904",
   "metadata": {},
   "outputs": [],
   "source": [
    "### le programe est la pour debugger , je le remetrais a sa place apres\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################################################################################################################################################################\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_calculations(exe_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3e163e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc677c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe923640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eec9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
