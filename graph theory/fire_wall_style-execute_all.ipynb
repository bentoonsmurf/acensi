{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4de58f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import terminé a : 03:50:53\n"
     ]
    }
   ],
   "source": [
    "#import librairies \n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import progressbar\n",
    "import time\n",
    "from time import process_time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "    \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score,precision_score,recall_score, precision_recall_fscore_support \n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "#from sklearn_som.som import SOM\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from GEM.gem.utils      import graph_util, plot_util\n",
    "from GEM.gem.evaluation import visualize_embedding as viz\n",
    "from GEM.gem.evaluation import evaluate_graph_reconstruction as gr\n",
    "from GEM.gem.embedding.gf       import GraphFactorization\n",
    "#from GEM.gem.embedding.sdne     import SDNE\n",
    "#from argparse import ArgumentParser\n",
    "#from GraphEmbedding.ge import DeepWalk\n",
    "#from GraphEmbedding.ge import SDNE\n",
    "from karateclub.graph_embedding import Graph2Vec\n",
    "from karateclub.node_embedding.neighbourhood import HOPE\n",
    "from karateclub.node_embedding.neighbourhood import DeepWalk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_frame=200#arbitraire , a tester plus serieusement\n",
    "\n",
    "print(\"import terminé a :\",time.strftime(\"%H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176c2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953c2308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fonctions declaré a : 03:50:53\n"
     ]
    }
   ],
   "source": [
    "#ce dictionaire contien le nom de chaques colones avec la valeur du f1_score\n",
    "#qu'ils on obtenu apres etre ajouté au data_set\n",
    "#initialisé a 0\n",
    "#-1,name1,name2,w,b\n",
    "\n",
    "def convert_dist_to_zero_and_ones(data_set_dist, threshold=0.3):\n",
    "    new_data_set = data_set_dist < threshold\n",
    "    return new_data_set.astype(int)\n",
    "\n",
    "def create_pair_dict(columns_list=[]):\n",
    "    if (columns_list==[]):\n",
    "        print(\"you forgot to input a list of columns\")\n",
    "        return []\n",
    "    pair_dict=dict()\n",
    "    for name1 in columns_list:\n",
    "        for name2 in columns_list:# oui ce n'est pas optimisé\n",
    "            pair_names=name1+\"_\"+name2\n",
    "            reverse_pair_names=name2+\"_\"+name1\n",
    "            if name1!=name2 and pair_names not in pair_dict.keys() and reverse_pair_names not in pair_dict.keys():\n",
    "                pair_dict[pair_names]=[-1,name1,name2,0,0]\n",
    "    \n",
    "    return pair_dict\n",
    "\n",
    "def create_monstruous_pair_data_set_deprecated(pair_dict,panda_data_set):\n",
    "    columns_list = panda_data_set.columns.tolist()\n",
    "    if (columns_list==[]):\n",
    "        print(\"you forgot to input a data_set\")\n",
    "        return {},[]\n",
    "    if (pair_dict=={}):\n",
    "        print(\"you forgot to input a dict\")\n",
    "        return {},[]\n",
    "    #pair_dict=dict()\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(pair_dict));i=0\n",
    "    monstruous_pair_data_set=[]\n",
    "    for pair in pair_dict.items():\n",
    "        pair_dict[pair[0]][0]=i\n",
    "        #print(pair[1][0],pair[1][1],pair[1][2])# value name1,name2\n",
    "        tmp_data_set=panda_data_set[[pair[1][1],pair[1][2]]]\n",
    "        tmp_w,tmp_b=linear_regresion(tmp_data_set)\n",
    "        pair_dict[pair[0]][3]=tmp_w\n",
    "        pair_dict[pair[0]][4]=tmp_b\n",
    "        monstruous_pair_data_set.append(distances(tmp_data_set,tmp_w,tmp_b))\n",
    "        process_bar.update(i);i+=1\n",
    "    #the monstruous data_set should contain 0 and 1\n",
    "    return pair_dict,monstruous_pair_data_set\n",
    "\n",
    "def create_monstruous_pair_data_set(pair_dict,panda_data_set):\n",
    "    columns_list = panda_data_set.columns.tolist()\n",
    "    if (columns_list==[]):\n",
    "        print(\"you forgot to input a data_set\")\n",
    "        return {},[]\n",
    "    if (pair_dict=={}):\n",
    "        print(\"you forgot to input a dict\")\n",
    "        return {},[]\n",
    "    #pair_dict=dict()\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(pair_dict));i=0\n",
    "    monstruous_pair_data_set=np.array([])\n",
    "    for pair in pair_dict.items():\n",
    "        #print(pair[1][0],pair[1][1],pair[1][2])# id,name1,name2,w,b\n",
    "        pair_dict[pair[0]][0]=i\n",
    "        tmp_data_set=panda_data_set[[pair[1][1],pair[1][2]]]\n",
    "        tmp_w,tmp_b=linear_regresion(tmp_data_set)\n",
    "        pair_dict[pair[0]][3]=tmp_w\n",
    "        pair_dict[pair[0]][4]=tmp_b\n",
    "        \n",
    "        if(monstruous_pair_data_set.size ==0):\n",
    "            monstruous_pair_data_set=distances_expand(tmp_data_set,tmp_w,tmp_b)\n",
    "        else:\n",
    "            monstruous_pair_data_set=np.concatenate((monstruous_pair_data_set,distances_expand(tmp_data_set,tmp_w,tmp_b)),axis=1)\n",
    "        process_bar.update(i);i+=1\n",
    "    #the monstruous data_set should contain 0 and 1\n",
    "    return pair_dict,monstruous_pair_data_set\n",
    "\n",
    "def make_one_graph(line ,pair_dict):\n",
    "    g=nx.Graph()\n",
    "    \n",
    "    for pair in pair_dict.items():\n",
    "        #print(pair[1][0],pair[1][1],pair[1][2])# id,name1,name2,w,b\n",
    "        i= pair[1][0]\n",
    "        arc_val=line[i]\n",
    "\n",
    "        if arc_val ==1:\n",
    "            name_1=pair[1][1]\n",
    "            name_2=pair[1][2]\n",
    "            g.add_edge(name_1,name_2)\n",
    "    \n",
    "    return g\n",
    "\n",
    "def create_graphs(monstruous_binary_np_data_set,pair_dict):\n",
    "    start = time.time()\n",
    "    graph_list=[]\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(monstruous_binary_np_data_set));i=0\n",
    "   \n",
    "    for line in monstruous_binary_np_data_set:\n",
    "        #print(type(line),line.shape)\n",
    "\n",
    "        graph_list.append( make_one_graph(line ,pair_dict))\n",
    "        process_bar.update(i);i+=1\n",
    "    print(\"---graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    " \n",
    "    return graph_list\n",
    "\n",
    "def save_np(np_array,name):\n",
    "    if(\".npy\" not in name):\n",
    "        print(\"you save a numpy array in a file.npy\")\n",
    "        return 0\n",
    "    np.save(name, np_array)\n",
    "\n",
    "def load_np(file_name):\n",
    "    return np.load(file_name)\n",
    "\n",
    "    \n",
    "############################################## liste des options d'extractions\n",
    "def graph_max_degree(g):\n",
    "    degrees = [val for (node, val) in g.degree()]\n",
    "    maxd=max(degrees)\n",
    "    return maxd\n",
    "def geodesic_dist(graph):\n",
    "    return nx.average_shortest_path_length(graph)\n",
    "\n",
    "#special thanks to Francisco A. Rodrigues, University of São Paulo.\n",
    "# http://conteudo.icmc.usp.br/pessoas/francisco\n",
    "def degree_distribution(G):\n",
    "    vk = dict(G.degree())\n",
    "    vk = list(vk.values()) # we get only the degree values\n",
    "    maxk = np.max(vk)\n",
    "    mink = np.min(min)\n",
    "    kvalues= np.arange(0,maxk+1) # possible values of k\n",
    "    Pk = np.zeros(maxk+1) # P(k)\n",
    "    for k in vk:\n",
    "        Pk[k] = Pk[k] + 1\n",
    "    Pk = Pk/sum(Pk) # the sum of the elements of P(k) must to be equal to one\n",
    "    return kvalues,Pk\n",
    "def shannon_entropy(G):\n",
    "    k,Pk = degree_distribution(G)\n",
    "    H = 0\n",
    "    for p in Pk:\n",
    "        if(p > 0):\n",
    "            H = H - p*math.log(p, 2)\n",
    "    return H\n",
    "\n",
    "def contain_meso_scale(graph):\n",
    "    \n",
    "    return False    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_info_from_one_graph(g, to_do_list):\n",
    "    graph_property=np.array([])\n",
    "    calc_result=0\n",
    "    \n",
    "    if(\"max_degree\" in to_do_list):\n",
    "        #print (\" max degree\")\n",
    "        calc_result=graph_max_degree(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"assortativity\" in to_do_list):\n",
    "        calc_result = nx.degree_assortativity_coefficient(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"clustering\" in to_do_list):\n",
    "        calc_result= approximation.average_clustering(g, trials=1000, seed=10)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"global_efficiency\" in to_do_list):\n",
    "        calc_result= nx.global_efficiency(g)\n",
    "        graph_property=np.append(graph_property,calc_result)   \n",
    "    if(\"geodesic_dist\" in to_do_list):\n",
    "        if nx.is_connected(g):\n",
    "            calc_result=geodesic_dist(g)\n",
    "        else:\n",
    "            calc_result=len(g.nodes()) # = la dist la plus grande\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"contain_meso_scale\" in to_do_list):#to do\n",
    "        calc_result=contain_meso_scale(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"Shannon_entropy\" in to_do_list):#to do\n",
    "        calc_result=shannon_entropy(g)\n",
    "        graph_property=np.append(graph_property,calc_result)  \n",
    "    #change this ()\n",
    "    #            ()\n",
    "    #            ()\n",
    "    #      to this ()()()\n",
    "    return np.expand_dims(graph_property,axis=0)\n",
    "\n",
    "def extract_info_from_graphs(graph_list, to_do_list):\n",
    "    \n",
    "    monstruous_info_data_set=np.array([])\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(graph_list));i=0\n",
    "   \n",
    "    \n",
    "    for graph in graph_list:\n",
    "        \n",
    "        if(monstruous_info_data_set.size ==0):\n",
    "            monstruous_info_data_set=extract_info_from_one_graph(graph, to_do_list)\n",
    "        else:\n",
    "            monstruous_info_data_set=np.concatenate((monstruous_info_data_set,extract_info_from_one_graph(graph, to_do_list)),axis=0)\n",
    "        process_bar.update(i);i+=1\n",
    "    \n",
    "    return monstruous_info_data_set\n",
    "\n",
    "\n",
    "\n",
    "def create_graphs_to_delete(monstruous_binary_np_data_set,pair_dict):\n",
    "    start = time.time()\n",
    "    graph_list=[]\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(monstruous_binary_np_data_set));i=0\n",
    "   \n",
    "    for line in monstruous_binary_np_data_set:\n",
    "        #print(type(line),line.shape)\n",
    "\n",
    "        graph_list.append( make_one_graph(line ,pair_dict))\n",
    "        process_bar.update(i);i+=1\n",
    "    print(\"---graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_info_from_binary_data_set(monstruous_binary_np_data_set,pair_dict, to_do_list):\n",
    "    start_time = process_time() \n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(monstruous_binary_np_data_set));i=0\n",
    "    monstruous_info_data_set=np.array([])\n",
    "    counter = 0\n",
    "    contruct_time=0\n",
    "    calcul_time=0\n",
    "    for line in monstruous_binary_np_data_set:\n",
    "        in_loop_time = process_time()\n",
    "        graph=make_one_graph(line ,pair_dict)\n",
    "        contruct_time = contruct_time+ process_time()  - in_loop_time\n",
    "        \n",
    "        in_loop_time = process_time()\n",
    "        if(monstruous_info_data_set.size ==0):\n",
    "            monstruous_info_data_set=extract_info_from_one_graph(graph, to_do_list)\n",
    "        else:\n",
    "            monstruous_info_data_set=np.concatenate((monstruous_info_data_set,extract_info_from_one_graph(graph, to_do_list)),axis=0)\n",
    "        calcul_time = calcul_time+ process_time()  - in_loop_time\n",
    "        process_bar.update(i);i+=1\n",
    "        \n",
    "        #####################################################################\n",
    "        del graph # je delete le graph pour etre sur de liberer la memoire\n",
    "        #gc.collect() #je n'appelle pas le garbageColector = cout 22 heures\n",
    "        #calcul_time =  521.984375 contruct_time 59.3125\n",
    "        #counter=counter+1\n",
    "        #if(counter == 100000):  \n",
    "            #print(process_time()  - start_time, \"seconds\");start_time = process_time()\n",
    "            #print(\"calcul_time = \",calcul_time,\"contruct_time\",contruct_time)\n",
    "            #return monstruous_info_data_set\n",
    "            \n",
    "        \n",
    "    \n",
    "    print(\"---graph extraction = %s seconds ---\" % (process_time()  - start_time));start_time = process_time()\n",
    "    return monstruous_info_data_set\n",
    "\n",
    "# Function to find distance line equation ax + by + c =0\n",
    "#y=mx+c  ----> mx -y +c =0  ---> b=-1 ,a=weight ,c=bias\n",
    "def shortest_distance(x1, y1, a, b, c):\n",
    "    \n",
    "    d = abs((a * x1 + b * y1 + c)) / (math.sqrt(a * a + b * b))\n",
    "    #print(\"Perpendicular distance is \",d)\n",
    "    return d\n",
    "\n",
    "def distances(data_set,w,b):\n",
    "    np_data=data_set.to_numpy()\n",
    "    np_dist=[]\n",
    "    for line in np_data:\n",
    "        x1=line[0]\n",
    "        y1=line[1]\n",
    "        np_dist.append(shortest_distance(x1, y1, w, -1, b))\n",
    "    \n",
    "    return np.array(np_dist)\n",
    "\n",
    "def distances_expand(data_set,w,b):\n",
    "    np_data=data_set.to_numpy()\n",
    "    np_dist=[]\n",
    "    for line in np_data:\n",
    "        x1=line[0]\n",
    "        y1=line[1]\n",
    "        np_dist.append(shortest_distance(x1, y1, w, -1, b))\n",
    "    \n",
    "    return np.expand_dims( np.array(np_dist)  ,axis=1)\n",
    "# y = mx +b\n",
    "def line_equation_from_two_points(x1,y1,x2,y2):\n",
    "    m=(y2-y1)/(x2-x1)\n",
    "    b=y1-m*x1\n",
    "    return m,b\n",
    "\n",
    "\n",
    "\n",
    "def shortest_distance_test():\n",
    "    print(shortest_distance(0, 0, 1, -1, 1))\n",
    "    print(shortest_distance(-1, 0, 1, -1, 1))\n",
    "    print(shortest_distance(1, 0, 1, -1, 1))\n",
    "    print(math.sqrt(2))\n",
    "    print(shortest_distance(3, 0, 1, -1, 1))\n",
    "    print(math.sqrt(2*2+2*2))\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def affiche_simple_graphique(threshold_list,recall,f1,title=\"\"):\n",
    "    %matplotlib inline\n",
    "    plt.plot(threshold_list,f1,  label='F1 score',color=\"green\")\n",
    "    plt.plot(threshold_list,recall,  label='recall',color=\"darkgoldenrod\")\n",
    "    plt.plot(threshold_list,[x*0 for x in threshold_list],  label='water level',color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    gain_recall=sum(recall)/len(recall)\n",
    "    gain_f1 = sum(f1)/len(f1)\n",
    "    if(gain_recall>=0):\n",
    "        print(\"average recall  \",'\\033[92m'+\"gain \"+ '\\033[0m',\"%.4f\" % gain_recall)\n",
    "    else:\n",
    "        print(\"average recall \",'\\033[91m'+\"loss \"+ '\\033[0m',\"%.4f\" % gain_recall)\n",
    "    if(gain_f1>=0):\n",
    "        print(\"average f1 score  \",'\\033[92m'+\"gain \"+ '\\033[0m',\"%.4f\" %gain_f1)\n",
    "    else:\n",
    "        print(\"average f1 score  \",'\\033[91m'+\"loss \"+ '\\033[0m',\"%.4f\" %gain_f1)\n",
    "\n",
    "def dict_mean(d_list,target=\"1\"):\n",
    "    dict_list=list()\n",
    "    mean_dict = {}\n",
    "    if(target==\"accuracy\"):\n",
    "        summ=0\n",
    "        for d in d_list:\n",
    "            summ=summ+d[\"accuracy\"]\n",
    "        return summ/len(d_list)\n",
    "    else:\n",
    "        for d in d_list:\n",
    "            dict_list.append(d[target])#extract the lines i want\n",
    "        for key in dict_list[0].keys():\n",
    "            mean_dict[key] = sum(d[key] for d in dict_list) / len(dict_list)\n",
    "    return mean_dict\n",
    "\n",
    "def classification_mean(cl_list):\n",
    "    avg_0 =dict_mean(cl_list,target=\"0\")\n",
    "    avg_1 =dict_mean(cl_list,target=\"1\")\n",
    "    avg_accuracy =dict_mean(cl_list,target=\"accuracy\")\n",
    "    avg_macro =dict_mean(cl_list,target=\"macro avg\")\n",
    "    avg_weighted =dict_mean(cl_list,target=\"weighted avg\")\n",
    "    return { \"0\": avg_0 ,\"1\":avg_1,\"accuracy\":avg_accuracy ,\"macro avg\":avg_macro,\"weighted avg\":avg_weighted }               \n",
    "    \n",
    "\n",
    "#https://www.machinelearningplus.com/deep-learning/linear-regression-tensorflow/\n",
    "###############################################################################\n",
    "################# partie linear regression ####################################\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def lin_reg_bootstrap(panda_data_set,nb_iter=1000):\n",
    "    columns_list = panda_data_set.columns.tolist()\n",
    "    x_train=NormalizeData(panda_data_set[columns_list[0]].to_numpy())\n",
    "    y_train=NormalizeData(panda_data_set[columns_list[1]].to_numpy())\n",
    "    data_set_size=len(x_train)\n",
    "    m=0\n",
    "    b=0\n",
    "    counter=0\n",
    "    for i in range(nb_iter):\n",
    "        p1=random.randint(0, data_set_size-1)\n",
    "        p2=random.randint(0, data_set_size-1)\n",
    "        \n",
    "        x1=x_train[p1]\n",
    "        y1=y_train[p1]        \n",
    "        x2=x_train[p2]\n",
    "        y2=y_train[p2]\n",
    "        if((x2-x1)!=0):\n",
    "            m_tmp,b_tmp=line_equation_from_two_points(x1,y1,x2,y2)\n",
    "            m=m+m_tmp\n",
    "            b=b+b_tmp\n",
    "        else:\n",
    "            counter=counter+1\n",
    "    m=m/(nb_iter-counter)\n",
    "    b=b/(nb_iter-counter)\n",
    "    return m,b\n",
    "    \n",
    "def linreg(x,weight,bias):#x is a np list\n",
    "    y = weight*x + bias\n",
    "    return y\n",
    "\n",
    "# Define loss function (MSE)\n",
    "def squared_error(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "def not_squared_error(y_pred, y_true):\n",
    "    return tf.reduce_mean(y_pred - y_true)\n",
    "\n",
    "def linear_regresion(panda_data_set,boot_iter=1000):\n",
    "    columns_list = panda_data_set.columns.tolist()\n",
    "    #x_train=panda_data_set[columns_list[0]].to_numpy()\n",
    "    #y_train=panda_data_set[columns_list[1]].to_numpy()\n",
    "    x_train=NormalizeData(panda_data_set[columns_list[0]].to_numpy())\n",
    "    y_train=NormalizeData(panda_data_set[columns_list[1]].to_numpy())\n",
    "    #print(\"x_train max =\",np.amax(x_train, axis=0))\n",
    "    #print(\"y_train max =\",np.amax(y_train, axis=0))\n",
    "    learning_rate = 0.01\n",
    "    # Number of loops for training through all your data to update the parameters\n",
    "    training_epochs = 100\n",
    "    \n",
    "    boot_weight,boot_bias=lin_reg_bootstrap(panda_data_set,nb_iter=boot_iter)\n",
    "    weight = tf.Variable(boot_weight)\n",
    "    bias   = tf.Variable(boot_bias)\n",
    "    #weight = tf.Variable(0.)\n",
    "    #bias   = tf.Variable(0.)\n",
    "    \n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Compute loss within Gradient Tape context\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_predicted = linreg(x_train,weight,bias)\n",
    "            #loss = squared_error(y_predicted, y_train)\n",
    "            loss = not_squared_error(y_predicted, y_train)\n",
    "            # Get gradients\n",
    "            gradients = tape.gradient(loss, [weight,bias])\n",
    "\n",
    "            # Adjust weights\n",
    "            weight.assign_sub(gradients[0]*learning_rate)\n",
    "            bias.assign_sub(gradients[1]*learning_rate)\n",
    "\n",
    "    \n",
    "    \n",
    "    return weight.numpy(),bias.numpy()\n",
    "\n",
    "print(\"fonctions declaré a :\",time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb9e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67ec17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['merchant', 'category', 'amt', 'gender', 'state', 'zip', 'lat', 'long', 'city_pop', 'dob', 'unix_time', 'merch_lat', 'merch_long', 'delta_time', 'delta_amt', 'delta_time_category', 'delta_amt_category', 'delta_time_merchant', 'delta_amt_merchant', 'avg_amt', 'delta_avg_amt', 'avg_amt_category', 'delta_avg_amt_category', 'avg_amt_merchant', 'avg_amt_state', 'avg_amt_city', 'avg_amt_job', 'delta_avg_amt_category_job', 'month', 'day', 'hour']\n",
      "--- import data_set = 41.174514055252075 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#import le data_set complet --- import data_set = 28.00195622444153 seconds ---\n",
    "start = time.time()\n",
    "\n",
    "data_file= os.path.abspath('data')\n",
    "full_path=data_file+'\\\\'+'fraudTrain.csv'   # unmodified train set\n",
    "train_df=pd.read_csv(full_path)\n",
    "full_path=data_file+'\\\\'+'fraudTest.csv'\n",
    "test_df=pd.read_csv(full_path)\n",
    "\n",
    "\n",
    "\n",
    "full_path=data_file+'\\\\'+'X_train_1_2_svm.csv'\n",
    "xtrain_transformed_complique=pd.read_csv(full_path)\n",
    "ytrain_transformed_complique=train_df['is_fraud'].iloc[:int(len(train_df)*0.8)]\n",
    "\n",
    "full_path=data_file+'\\\\'+'X_val_1_2_svm.csv'\n",
    "xval_transformed_complique=pd.read_csv(full_path)\n",
    "yval_transformed_complique=train_df['is_fraud'].iloc[len(ytrain_transformed_complique):]\n",
    "\n",
    "\n",
    "full_path=data_file+'\\\\'+'X_test_1_2_svm.csv'\n",
    "xtest_transformed_complique=pd.read_csv(full_path)\n",
    "ytest_transformed_complique=test_df['is_fraud']\n",
    "\n",
    "\n",
    "train_df=train_df.drop(columns=['Unnamed: 0'])\n",
    "test_df=test_df.drop(columns=['Unnamed: 0'])\n",
    "xtrain_transformed_complique=xtrain_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "xval_transformed_complique=xval_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "xtest_transformed_complique=xtest_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "cols = xtrain_transformed_complique.columns.tolist()\n",
    "print(cols)\n",
    "print(\"--- import data_set = %s seconds ---\" % (time.time() - start));start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9f590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "1024\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "dict_378 = create_pair_dict(cols)\n",
    "print (len(dict_378))\n",
    "print(32*32)\n",
    "print(len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b517c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10740133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fbf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd41fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177000d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af4d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test avec xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387153d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:51:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1031372\n",
      "           1       0.98      0.83      0.90      5968\n",
      "\n",
      "    accuracy                           1.00   1037340\n",
      "   macro avg       0.99      0.91      0.95   1037340\n",
      "weighted avg       1.00      1.00      1.00   1037340\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=50, gamma=0.05,eta=0.05,max_depth=7, n_jobs=16)\n",
    "\n",
    "xgb.fit(xtrain_transformed_complique,ytrain_transformed_complique)\n",
    "y_train_pred=xgb.predict(xtrain_transformed_complique)\n",
    "y_test_pred=xgb.predict(xtest_transformed_complique)\n",
    "print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "print(classification_report(ytest_transformed_complique,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f38d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_xgboost=classification_report(ytest_transformed_complique,y_test_pred,output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30eed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0daa2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.1min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RandomForest sans ajout = 254.9519715309143 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "max_depth = 15\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=max_depth, min_samples_leaf= 3, min_samples_split= 2, n_estimators= 140, verbose=1, n_jobs=16)\n",
    "rf.fit(xtrain_transformed_complique, ytrain_transformed_complique)\n",
    "# Prediction for the training/validation set\n",
    "y_train_pred = rf.predict(xtrain_transformed_complique)\n",
    "y_test_pred = rf.predict(xtest_transformed_complique)\n",
    "\n",
    "print(\"---RandomForest sans ajout = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97ce98da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1031372\n",
      "           1       1.00      0.83      0.91      5968\n",
      "\n",
      "    accuracy                           1.00   1037340\n",
      "   macro avg       1.00      0.92      0.95   1037340\n",
      "weighted avg       1.00      1.00      1.00   1037340\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.73      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.87      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "\n",
    "cl_rf=classification_report(ytest_transformed_complique,y_test_pred,output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2791ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4168d9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.75      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.81      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.85      0.84      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.92      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.80      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.99      0.65      0.78      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.83      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.78      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.89      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.79      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.90      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.68      0.87      0.76      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.84      0.93      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.75      0.85      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.88      0.93      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.76      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.76      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.77      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.82      0.82      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.77      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.60      0.88      0.71      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.80      0.94      0.85    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.74      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9482  f1-score: 0.8437\n",
      "---NN sans ajout = 1892.9275393486023 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# manual f1 score \n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "#trouve le meilleur dict\n",
    "def find_best_dict(dict_list):\n",
    "    threshold=0.92\n",
    "    while(threshold>0.50):\n",
    "        tmp_list=list()\n",
    "        for di in dict_list:\n",
    "            precision=(di[\"1\"][\"precision\"])\n",
    "            if(precision>threshold):\n",
    "                tmp_list.append(di)\n",
    "        if(tmp_list):\n",
    "            newlist = sorted(tmp_list, key=lambda d: d[\"1\"]['f1-score'],reverse=True)\n",
    "            print(\"choosen model precision: %.4f\" %newlist[0][\"1\"][\"precision\"],\" f1-score: %.4f\" %newlist[0][\"1\"]['f1-score'])\n",
    "            return newlist[0]\n",
    "        threshold=threshold-0.04\n",
    "    print(\"nothing good was found\")\n",
    "    return_value=sorted(dict_list, key=lambda d: d[\"1\"]['f1-score'],reverse=True)\n",
    "    return return_value[0]\n",
    "\n",
    "\n",
    "def fixed_nn_exec_time(xtrain_transformed_complique,ytrain_transformed_complique ,\n",
    "                        xtest_transformed_complique,ytest_transformed_complique ,\n",
    "                        tmps_exec=30,max_iter=1000):\n",
    "    start_function = time.time()\n",
    "    results=[]\n",
    "    curent_iter=0\n",
    "    while((tmps_exec*60)>(time.time() - start_function)):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_shape=(len(xtrain_transformed_complique.columns),),\n",
    "                        activation='relu')),\n",
    "        model.add(BatchNormalization()),\n",
    "        model.add(Dense(16, activation='relu')),\n",
    "        model.add(Dense(8, activation='relu')),\n",
    "        model.add(Dropout(0.2)),\n",
    "        model.add(Dense(4, activation='relu')),\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.001) #optimizer\n",
    "        los=tf.keras.losses.BinaryCrossentropy()\n",
    "        model.compile(optimizer=opt, loss=\"binary_crossentropy\", \n",
    "                      metrics=[tf.keras.metrics.Precision(),\"accuracy\",f1])\n",
    "\n",
    "        history= model.fit(xtrain_transformed_complique, ytrain_transformed_complique\n",
    "                           ,epochs = 10, batch_size=128, verbose = 0)\n",
    "        history_dictict = history.history\n",
    "        y_test_pred =(model.predict(xtest_transformed_complique) >0.5).astype(\"int32\")\n",
    "        print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "\n",
    "        cl_nn=classification_report(ytest_transformed_complique,y_test_pred\n",
    "                                    ,output_dict=True)\n",
    "        results.append(cl_nn)\n",
    "\n",
    "        curent_iter=curent_iter+1\n",
    "        if curent_iter > max_iter:\n",
    "            find_best_dict(results)\n",
    "        \n",
    "    return find_best_dict(results)\n",
    "    \n",
    "def deprecated_nn():\n",
    "    #metrics=[\"accuracy\",f1]\n",
    "    start = time.time()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(len(xtrain_transformed_complique.columns),),\n",
    "                    activation='relu')),\n",
    "    model.add(BatchNormalization()),\n",
    "    model.add(Dense(16, activation='relu')),\n",
    "    model.add(Dense(8, activation='relu')),\n",
    "    model.add(Dropout(0.2)),\n",
    "    model.add(Dense(4, activation='relu')),\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001) #optimizer\n",
    "    los=tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", \n",
    "                  metrics=[\"accuracy\",f1])\n",
    "\n",
    "\n",
    "    history= model.fit(xtrain_transformed_complique, ytrain_transformed_complique\n",
    "                       ,epochs = 10, batch_size=128, verbose = 0)\n",
    "                       #,class_weight=weight)#didnt work\n",
    "    history_dictict = history.history\n",
    "    #sigmoid return values from 0 to 1 , not exactly 0 and 1\n",
    "    y_train_pred=(model.predict(xtrain_transformed_complique)>0.5).astype(\"int32\")\n",
    "    y_test_pred =(model.predict(xtest_transformed_complique) >0.5).astype(\"int32\")\n",
    "\n",
    "    print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "    print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "\n",
    "    cl_nn=classification_report(ytest_transformed_complique,y_test_pred\n",
    "                                ,output_dict=True)\n",
    "\n",
    "###################################################################################    \n",
    "    \n",
    "    \n",
    "cl_nn=fixed_nn_exec_time(xtrain_transformed_complique,ytrain_transformed_complique ,\n",
    "                        xtest_transformed_complique,ytest_transformed_complique ,\n",
    "                        tmps_exec=30,max_iter=1000)\n",
    "#print(cl_nn)\n",
    "\n",
    "print(\"---NN sans ajout = %s seconds ---\" % (time.time() - start));start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414d718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8537b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504672f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc071d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- svm fit = 2767.061908006668 seconds ---\n",
      "---SVM y_test_pred = 529.2993576526642 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.66      0.76      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.83      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "start = time.time()\n",
    "svm_model = svm.SVC(kernel=\"rbf\", gamma = 0.02, C=10)#, max_iter=100000)\n",
    "svm_model.fit(xtrain_transformed_complique,ytrain_transformed_complique)\n",
    "print(\"--- svm fit = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "y_test_pred=svm_model.predict(xtest_transformed_complique)\n",
    "print(\"---SVM y_test_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "#y_train_pred=svm_model.predict(xtrain_transformed_complique)\n",
    "#print(\"---svm y_train_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "#print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "#cl=classification_report(ytest_transformed_complique,Y_test_pred,output_dict=True)\n",
    "\n",
    "\n",
    "cl_svm=classification_report(ytest_transformed_complique,y_test_pred\n",
    "                            ,output_dict=True)\n",
    "print(\"--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a30f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b378ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d4de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bcb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b46ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### big exec ###########################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631bc71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut du treshold  0.2\n",
      "---loading data = 0.5313405990600586 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:34:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 90.5683605670929 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.72      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 268.90276288986206 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.80      0.78      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.89      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.85      0.80      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.90      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.73      0.84      0.78      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.86      0.92      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.83      0.82      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.77      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.78      0.81      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.89      0.90      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.72      0.76      0.74      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.86      0.88      0.87    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.78      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.89      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.78      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.83      0.77      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.89      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.60      0.83      0.70      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.80      0.91      0.85    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.76      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.77      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.73      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.85      0.76      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.88      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.80      0.80      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.90      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9401  f1-score: 0.8410\n",
      "---neural network = 1889.9763083457947 seconds ---\n",
      "svm start\n",
      "--- svm fit = 3395.968042373657 seconds ---\n",
      "---SVM y_test_pred = 642.7229678630829 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.61      0.72      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.80      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 4039.968411207199 seconds ---\n",
      "treshold  0.2  terminé a : 12:19:18\n",
      "-----------------------------------------------------------------------------------------\n",
      "debut du treshold  0.25\n",
      "---loading data = 0.4970121383666992 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:19:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 93.6388885974884 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.72      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 260.4137716293335 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.78      0.83      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.89      0.92      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.64      0.76      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.82      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.73      0.81      0.77      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.87      0.91      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.78      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.89      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.78      0.74      0.76      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.89      0.87      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.79      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.70      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.85      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.69      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.84      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.74      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.75      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    553574\n",
      "           1       0.23      0.75      0.35      2145\n",
      "\n",
      "    accuracy                           0.99    555719\n",
      "   macro avg       0.62      0.87      0.67    555719\n",
      "weighted avg       1.00      0.99      0.99    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.77      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.72      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.86      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.77      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.73      0.78      0.75      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.87      0.89      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.48      0.77      0.59      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.74      0.88      0.79    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9239  f1-score: 0.8434\n",
      "---neural network = 1904.2141444683075 seconds ---\n",
      "svm start\n",
      "--- svm fit = 3594.0157310962677 seconds ---\n",
      "---SVM y_test_pred = 653.3558733463287 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.61      0.72      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.80      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 4248.639578819275 seconds ---\n",
      "treshold  0.25  terminé a : 14:07:45\n",
      "-----------------------------------------------------------------------------------------\n",
      "debut du treshold  0.3\n",
      "---loading data = 0.49744558334350586 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.90      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 94.79971289634705 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.72      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 262.13520336151123 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    553574\n",
      "           1       0.36      0.76      0.49      2145\n",
      "\n",
      "    accuracy                           0.99    555719\n",
      "   macro avg       0.68      0.88      0.74    555719\n",
      "weighted avg       1.00      0.99      0.99    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.75      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.75      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.79      0.83      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.91      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.86      0.78      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.65      0.86      0.74      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.83      0.93      0.87    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.77      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.74      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.87      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.82      0.82      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.78      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.76      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.88      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.70      0.80      0.75      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.85      0.90      0.87    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.64      0.77      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.82      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.80      0.71      0.75      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.85      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.53      0.74      0.62      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.76      0.87      0.81    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.79      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9465  f1-score: 0.8473\n",
      "---neural network = 1880.7954967021942 seconds ---\n",
      "svm start\n",
      "--- svm fit = 3434.8901369571686 seconds ---\n",
      "---SVM y_test_pred = 615.6925954818726 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.85      0.61      0.71      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.80      0.85    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 4051.857339859009 seconds ---\n",
      "treshold  0.3  terminé a : 15:52:35\n",
      "-----------------------------------------------------------------------------------------\n",
      "debut du treshold  0.35\n",
      "---loading data = 0.5352725982666016 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:52:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.90      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 94.92639756202698 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.74      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.87      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 261.6075847148895 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.83      0.83      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.79      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.80      0.81      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.91      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.80      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.90      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.73      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.87      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.85      0.78      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    553574\n",
      "           1       0.08      0.81      0.15      2145\n",
      "\n",
      "    accuracy                           0.96    555719\n",
      "   macro avg       0.54      0.89      0.56    555719\n",
      "weighted avg       1.00      0.96      0.98    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.78      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    553574\n",
      "           1       0.35      0.83      0.49      2145\n",
      "\n",
      "    accuracy                           0.99    555719\n",
      "   macro avg       0.68      0.91      0.74    555719\n",
      "weighted avg       1.00      0.99      0.99    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.86      0.79      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.90      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.76      0.81      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.88      0.91      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.86      0.81      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.79      0.81      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.91      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.76      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.98      0.61      0.76      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.81      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.81      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9376  f1-score: 0.8417\n",
      "---neural network = 1888.415901184082 seconds ---\n",
      "svm start\n",
      "--- svm fit = 3512.994668006897 seconds ---\n",
      "---SVM y_test_pred = 613.0776727199554 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.86      0.63      0.72      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.81      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 4127.335265874863 seconds ---\n",
      "treshold  0.35  terminé a : 17:38:48\n",
      "-----------------------------------------------------------------------------------------\n",
      "debut du treshold  0.4\n",
      "---loading data = 0.4921395778656006 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:38:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.90      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 94.99723744392395 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.74      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.87      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 263.0444014072418 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.77      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.89      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.74      0.85      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.87      0.93      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.82      0.79      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.90      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.85      0.81      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.90      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.80      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.90      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.77      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.89      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.96      0.67      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.83      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.74      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.81      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.70      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.85      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.78      0.81      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.89      0.91      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.79      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.90      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.83      0.77      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.89      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.82      0.82      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.78      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.89      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.80      0.82      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9495  f1-score: 0.8296\n",
      "---neural network = 1897.3827464580536 seconds ---\n",
      "svm start\n",
      "--- svm fit = 3396.8422026634216 seconds ---\n",
      "---SVM y_test_pred = 609.5501635074615 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.86      0.63      0.72      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.81      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 4007.6476962566376 seconds ---\n",
      "treshold  0.4  terminé a : 19:23:12\n",
      "-----------------------------------------------------------------------------------------\n",
      "debut du treshold  0.45\n",
      "---loading data = 0.4818990230560303 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:23:15] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 95.19844961166382 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.72      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 261.34592723846436 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.81      0.84      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.92      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.77      0.85      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.89      0.93      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.80      0.77      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.89      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.74      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.80      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.78      0.80      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.89      0.90      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.67      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.84      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.83      0.80      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.90      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.78      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.38      0.74      0.50      2145\n",
      "\n",
      "    accuracy                           0.99    555719\n",
      "   macro avg       0.69      0.87      0.75    555719\n",
      "weighted avg       1.00      0.99      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.79      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.74      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.78      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.75      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.87      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.74      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.76      0.82      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.88      0.91      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9457  f1-score: 0.8349\n",
      "---neural network = 1905.6694059371948 seconds ---\n",
      "svm start\n",
      "--- svm fit = 3368.6620473861694 seconds ---\n",
      "---SVM y_test_pred = 606.3827414512634 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.64      0.74      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.82      0.87    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 3976.295095682144 seconds ---\n",
      "treshold  0.45  terminé a : 21:07:11\n",
      "-----------------------------------------------------------------------------------------\n",
      "debut du treshold  0.5\n",
      "---loading data = 0.48517680168151855 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 94.26778841018677 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.73      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.86      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 260.58603715896606 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.74      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.77      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.75      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.65      0.77      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.83      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.76      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.88      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.79      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.77      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.76      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.74      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.96      0.65      0.77      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.82      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.77      0.74      0.76      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.89      0.87      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.71      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.86      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.79      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.72      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.82      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.69      0.72      0.70      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.84      0.86      0.85    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9355  f1-score: 0.8451\n",
      "---neural network = 1898.4415209293365 seconds ---\n",
      "svm start\n",
      "--- svm fit = 4530.967277050018 seconds ---\n",
      "---SVM y_test_pred = 601.5564610958099 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.61      0.73      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.80      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 5133.7773225307465 seconds ---\n",
      "treshold  0.5  terminé a : 23:10:18\n",
      "-----------------------------------------------------------------------------------------\n",
      "debut du treshold  0.55\n",
      "---loading data = 0.46753501892089844 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:10:21] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 94.84431385993958 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.73      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.86      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 261.0887818336487 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.79      0.82      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.89      0.91      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.80      0.82      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.77      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.66      0.72      0.69      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.83      0.86      0.84    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.69      0.80      0.74      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.84      0.90      0.87    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    553574\n",
      "           1       0.20      0.76      0.31      2145\n",
      "\n",
      "    accuracy                           0.99    555719\n",
      "   macro avg       0.60      0.87      0.65    555719\n",
      "weighted avg       1.00      0.99      0.99    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.81      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.76      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.73      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.83      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.92      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.96      0.70      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.85      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.92      0.71      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.86      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.86      0.80      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.76      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.80      0.81      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.90      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.79      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9316  f1-score: 0.8460\n",
      "---neural network = 1900.1415309906006 seconds ---\n",
      "svm start\n",
      "--- svm fit = 4568.376457691193 seconds ---\n",
      "---SVM y_test_pred = 616.4253659248352 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.61      0.73      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.80      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 5186.076910018921 seconds ---\n",
      "treshold  0.55  terminé a : 01:14:21\n",
      "-----------------------------------------------------------------------------------------\n",
      "debut du treshold  0.6\n",
      "---loading data = 0.5276618003845215 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:14:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.90      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 95.02759790420532 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.72      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 262.4804174900055 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.76      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.81      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.81      0.82      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.90      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.79      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.89      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.77      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.80      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.77      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.75      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.87      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.76      0.74      0.75      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.88      0.87      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.76      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.96      0.72      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.86      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.85      0.77      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.77      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.96      0.69      0.80      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.84      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.74      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.87      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9533  f1-score: 0.8349\n",
      "---neural network = 1805.925051689148 seconds ---\n",
      "svm start\n",
      "--- svm fit = 3435.6023259162903 seconds ---\n",
      "---SVM y_test_pred = 610.7029466629028 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.60      0.72      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.80      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 4047.55011844635 seconds ---\n",
      "treshold  0.6  terminé a : 02:57:52\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "xgboost_results=[]\n",
    "nn_results=[]\n",
    "rf_results=[]\n",
    "svm_results=[]\n",
    "to_do_list=[\"max_degree\",\"assortativity\",\"clustering\",\n",
    "            \"global_efficiency\",\"geodesic_dist\",\"Shannon_entropy\"]\n",
    "\n",
    "threshold_list=[0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6]\n",
    "\n",
    "#threshold_list=[0.5]\n",
    "\n",
    "for treshold_value in threshold_list:\n",
    "    start = time.time()\n",
    "    print(\"debut du treshold \" ,treshold_value)\n",
    "    \n",
    "    name=\"data/\"+\"train_graph_properties\"+str(treshold_value)+\".npy\"\n",
    "    loaded_np=np.load(name)\n",
    "    df_addon = pd.DataFrame(loaded_np, columns = to_do_list)\n",
    "    X_train_plus_graph_df=pd.concat([xtrain_transformed_complique,df_addon],axis=1)\n",
    "    X_train_plus_graph =np.concatenate((xtrain_transformed_complique,loaded_np),axis=1)\n",
    "\n",
    "\n",
    "    name=\"data/\"+\"val_graph_properties\"+str(treshold_value)+\".npy\"\n",
    "    loaded_np=np.load(name)\n",
    "    df_addon = pd.DataFrame(loaded_np, columns = to_do_list)\n",
    "    X_val_plus_graph_df=pd.concat([xval_transformed_complique,df_addon],axis=1)\n",
    "    X_val_plus_graph =np.concatenate((xval_transformed_complique,loaded_np),axis=1)\n",
    "\n",
    "    name=\"data/\"+\"test_graph_properties\"+str(treshold_value)+\".npy\"\n",
    "    loaded_np=np.load(name)\n",
    "    df_addon = pd.DataFrame(loaded_np, columns = to_do_list)\n",
    "    X_test_plus_graph_df=pd.concat([xtest_transformed_complique,df_addon],axis=1)\n",
    "    X_test_plus_graph =np.concatenate((xtest_transformed_complique,loaded_np),axis=1)\n",
    "    \n",
    "    \n",
    "    print(\"---loading data = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    #################### loading data finished \n",
    "    \n",
    "    \n",
    "    print(\"xgboost start\")\n",
    "    xgb = XGBClassifier(n_estimators=50, gamma=0.05,eta=0.05,max_depth=7, n_jobs=16)\n",
    "    xgb.fit(X_train_plus_graph,ytrain_transformed_complique)\n",
    "    #Y_train_pred_graph=xgb.predict(X_train_plus_graph)\n",
    "    Y_test_pred_graph=xgb.predict(X_test_plus_graph)\n",
    "    #print(classification_report(ytrain_transformed_complique,Y_train_pred_graph))\n",
    "    print(classification_report(ytest_transformed_complique,Y_test_pred_graph))\n",
    "    xgboost_results.append(classification_report(ytest_transformed_complique,Y_test_pred_graph,output_dict=True))\n",
    "    print(\"---XGboost = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    \n",
    "    print(\"rf start\")\n",
    "    max_depth = 15\n",
    "    rf = RandomForestClassifier(random_state=0, max_depth=max_depth, min_samples_leaf= 3, min_samples_split= 2, n_estimators= 140, verbose=1, n_jobs=16)\n",
    "    rf.fit(X_train_plus_graph, ytrain_transformed_complique)\n",
    "    # Prediction for the training/validation set\n",
    "    #Y_train_pred_graph = rf.predict(X_train_plus_graph)\n",
    "    Y_test_pred_graph= rf.predict(X_test_plus_graph)\n",
    "    print(classification_report(ytest_transformed_complique,Y_test_pred_graph))\n",
    "    rf_results.append(classification_report(ytest_transformed_complique,Y_test_pred_graph,output_dict=True))\n",
    "    print(\"---RandomForest = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "\n",
    "\n",
    "    print(\"start nn\") \n",
    "    nn_res=fixed_nn_exec_time(X_train_plus_graph_df,ytrain_transformed_complique ,\n",
    "                        X_test_plus_graph_df,ytest_transformed_complique ,\n",
    "                        tmps_exec=30)\n",
    "    nn_results.append(nn_res)\n",
    "    print(\"---neural network = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    \n",
    "    \n",
    "    print(\"svm start\")\n",
    "    start_svm = time.time()\n",
    "    svm_model = svm.SVC(kernel=\"rbf\", gamma = 0.02, C=10)#, max_iter=100000)\n",
    "    svm_model.fit(X_train_plus_graph,ytrain_transformed_complique)\n",
    "    print(\"--- svm fit = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    Y_test_pred_graph=svm_model.predict(X_test_plus_graph)\n",
    "    print(\"---SVM y_test_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    #y_train_pred=svm_model.predict(xtrain_transformed_complique)\n",
    "    #print(\"---svm y_train_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    #print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "    print(classification_report(ytest_transformed_complique,Y_test_pred_graph))\n",
    "    svm_results.append(classification_report(ytest_transformed_complique,Y_test_pred_graph,output_dict=True))\n",
    "    \n",
    "    print(\"---svm = %s seconds ---\" % (time.time() - start_svm));start = time.time()\n",
    "    \n",
    "\n",
    "    print(\"treshold \" ,treshold_value,\" terminé a :\",time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "    print(\"-----------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b197c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b1c7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average recall   \u001b[92mgain \u001b[0m 0.0009\n",
      "average f1 score   \u001b[91mloss \u001b[0m -0.0016\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average recall  \u001b[91mloss \u001b[0m -0.0045\n",
      "average f1 score   \u001b[91mloss \u001b[0m -0.0036\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average recall  \u001b[91mloss \u001b[0m -0.0000\n",
      "average f1 score   \u001b[91mloss \u001b[0m -0.0032\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average recall  \u001b[91mloss \u001b[0m -0.0416\n",
      "average f1 score   \u001b[91mloss \u001b[0m -0.0400\n"
     ]
    }
   ],
   "source": [
    "xgboost_recalls=[]\n",
    "xgboost_f1=[]\n",
    "for cl2 in xgboost_results:\n",
    "    recall_diff=(cl2[\"1\"][\"recall\"]-cl_xgboost[\"1\"][\"recall\"])\n",
    "    f1_diff=(cl2[\"1\"][\"f1-score\"]-cl_xgboost[\"1\"][\"f1-score\"])\n",
    "    xgboost_recalls.append(recall_diff)\n",
    "    xgboost_f1.append(f1_diff)\n",
    "affiche_simple_graphique(threshold_list,xgboost_recalls,xgboost_f1,\n",
    "                         title=\"xgboost\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "rf_recalls=[]\n",
    "rf_f1=[]\n",
    "for cl2 in rf_results:\n",
    "    recall_diff=(cl2[\"1\"][\"recall\"]-cl_rf[\"1\"][\"recall\"])\n",
    "    f1_diff=(cl2[\"1\"][\"f1-score\"]-cl_rf[\"1\"][\"f1-score\"])\n",
    "    rf_recalls.append(recall_diff)\n",
    "    rf_f1.append(f1_diff)\n",
    "affiche_simple_graphique(threshold_list,rf_recalls,rf_f1,\n",
    "                         title=\"rf\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "nn_recalls=[]\n",
    "nn_f1=[]\n",
    "for cl2 in nn_results:\n",
    "    recall_diff=(cl2[\"1\"][\"recall\"]-cl_nn[\"1\"][\"recall\"])\n",
    "    f1_diff=(cl2[\"1\"][\"f1-score\"]-cl_nn[\"1\"][\"f1-score\"])\n",
    "    nn_recalls.append(recall_diff)\n",
    "    nn_f1.append(f1_diff)\n",
    "affiche_simple_graphique(threshold_list,nn_recalls,nn_f1,\n",
    "                         title=\"nn\")\n",
    "print(\"----------------------------------------------------------\") \n",
    "\n",
    "svm_recalls=[]\n",
    "svm_f1=[]\n",
    "for cl2 in svm_results:\n",
    "    recall_diff=(cl2[\"1\"][\"recall\"]-cl_svm[\"1\"][\"recall\"])\n",
    "    f1_diff=(cl2[\"1\"][\"f1-score\"]-cl_svm[\"1\"][\"f1-score\"])\n",
    "    svm_recalls.append(recall_diff)\n",
    "    svm_f1.append(f1_diff)\n",
    "affiche_simple_graphique(threshold_list,svm_recalls,svm_f1,\n",
    "                         title=\"svm\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc55513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80a17c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the full program took  = 83220.29744505882 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- the full program took  = %s seconds ---\" % (time.time() - program_start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dfd230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run awe graph embedding on the small graphs \n",
    "#https://github.com/nd7141/AWE/blob/master/Tutorial.ipynb \n",
    "#awe embedding l=7 , nm_walk =125000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d5d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d4318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e9c2012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d0ed2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da54b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---my time  = 760.6580209732056 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"---my time  = %s seconds ---\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09e4091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---his time  = 1287.7854628562927 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"---his time  = %s seconds ---\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8d6a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c611d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---his time  = 3417.5372326374054 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"---his time  = %s seconds ---\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb52d4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
