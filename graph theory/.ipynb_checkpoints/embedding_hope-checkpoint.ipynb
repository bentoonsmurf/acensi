{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "090123ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import terminé a : 10:16:16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importation des librairies \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import progressbar\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score,precision_score,recall_score, precision_recall_fscore_support \n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn_som.som import SOM\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from GEM.gem.utils      import graph_util, plot_util\n",
    "from GEM.gem.evaluation import visualize_embedding as viz\n",
    "from GEM.gem.evaluation import evaluate_graph_reconstruction as gr\n",
    "from GEM.gem.embedding.gf       import GraphFactorization\n",
    "#from GEM.gem.embedding.sdne     import SDNE\n",
    "#from argparse import ArgumentParser\n",
    "#from GraphEmbedding.ge import DeepWalk\n",
    "#from GraphEmbedding.ge import SDNE\n",
    "from karateclub.graph_embedding import Graph2Vec\n",
    "from karateclub.node_embedding.neighbourhood import HOPE\n",
    "from karateclub.node_embedding.neighbourhood import DeepWalk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_frame=200#arbitraire , a tester plus serieusement\n",
    "\n",
    "print(\"import terminé a :\",time.strftime(\"%H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb8668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instals():\n",
    "    !pip install progressbar2\n",
    "    !pip3 install PyQt5\n",
    "    \n",
    "    \n",
    "\n",
    "def create_graph(X_train_ultra_simple):\n",
    "    g = nx.MultiGraph()\n",
    "\n",
    "    start = time.time()\n",
    "    i=0\n",
    "    while (i<len(X_train_ultra_simple)):\n",
    "        a=X_train_ultra_simple[\"merchant\"][i]\n",
    "        b=X_train_ultra_simple[\"cc_num\"][i]\n",
    "        g.add_edge(a,b,weight=1,edge_id=i)\n",
    "        i=i+1\n",
    "    \n",
    "    print(\"---graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return g\n",
    "\n",
    "def create_graph_deprecated(X_train_ultra_simple):\n",
    "    g = nx.MultiGraph()\n",
    "\n",
    "    start = time.time()\n",
    "    i=0\n",
    "    while (i<len(X_train_ultra_simple)):\n",
    "        a=X_train_ultra_simple[\"merchant\"][i]\n",
    "        b=X_train_ultra_simple[\"cc_num\"][i]\n",
    "        g.add_edge(a,b,weight=0,edge_id=i)\n",
    "        i=i+1\n",
    "    i=0\n",
    "    while (i<len(X_train_ultra_simple)):# on lis 2 fois mais ca coute que 4 sec\n",
    "        a=X_train_ultra_simple[\"merchant\"][i]\n",
    "        b=X_train_ultra_simple[\"cc_num\"][i]\n",
    "        g[a][b][\"weight\"]=g[a][b][\"weight\"]+1 # il falais initialiser en premier\n",
    "        i=i+1\n",
    "    \n",
    "    print(\"---graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return g\n",
    "\n",
    "def fill(g,liste):\n",
    "  \n",
    "    while(liste):\n",
    "        a=liste.pop()\n",
    "        i=0\n",
    "        while(i<len(liste)):\n",
    "            b=liste[i]\n",
    "            g.add_edge(a,b,weight=1)\n",
    "            i+=1\n",
    "    \n",
    "    #return g\n",
    "\n",
    "def init_sub_graph(nb_frames):\n",
    "    # divison en plusieures sous graphs \n",
    "    sous_graph=[]\n",
    "    i=0\n",
    "    i2=0\n",
    "    sub_g=0\n",
    "    while ( i<num_frame):\n",
    "        sous_graph.append(nx.MultiGraph())\n",
    "        i=i+1\n",
    "    return sous_graph\n",
    "\n",
    "def bipartite_dict(dict_merchants,dict_cc_num):\n",
    "\n",
    "    dict_merchants_copy=dict_merchants.copy()\n",
    "    dict_merchants_copy = dict([(value, key) for key, value in dict_merchants_copy.items()])\n",
    "    dict_cc_num_copy=dict_cc_num.copy()\n",
    "    dict_cc_num_copy = dict([(value, key) for key, value in dict_cc_num_copy.items()])\n",
    "\n",
    "    for key in dict_merchants_copy.keys():\n",
    "        dict_merchants_copy[key] = 0\n",
    "    for key in dict_cc_num_copy.keys():\n",
    "        dict_cc_num_copy[key] = 1\n",
    "    return dict_merchants_copy,dict_cc_num_copy\n",
    "\n",
    "def create_sub_graph(g,nb_frames,dict_merchants,dict_cc_num):\n",
    "    sous_graph=init_sub_graph(nb_frames)\n",
    "    dict_merchants_copy,dict_cc_num_copy=bipartite_dict(dict_merchants,dict_cc_num)    \n",
    "    time_frame_size=len(X_train_ultra_simple) / num_frame\n",
    "    start = time.time()\n",
    "    connected_count=0\n",
    "    i=0\n",
    "    i2=0\n",
    "    sub_g=0\n",
    "    while (i<len(X_train_ultra_simple)):\n",
    "        a=X_train_ultra_simple[\"merchant\"][i]# rendre plus lisible\n",
    "        b=X_train_ultra_simple[\"cc_num\"][i]\n",
    "        sous_graph[sub_g].add_edge(a,b,weight=1,edge_id=i,edge_rid=i2)\n",
    "\n",
    "        i=i+1\n",
    "        i2=i2+1\n",
    "        if i2>= time_frame_size:\n",
    "            nx.set_node_attributes(sous_graph[sub_g], dict_merchants_copy, \"bipartite\")\n",
    "            nx.set_node_attributes(sous_graph[sub_g], dict_cc_num_copy, \"bipartite\")\n",
    "            i2=0\n",
    "            if(nx.is_connected(sous_graph[sub_g])):\n",
    "                connected_count+=1\n",
    "            sub_g=sub_g+1\n",
    "\n",
    "    print(\"---graph split = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "\n",
    "    return sous_graph,connected_count\n",
    "\n",
    "\n",
    "def create_sub_graph_deprecated(g,nb_frames,dict_merchants,dict_cc_num):\n",
    "    sous_graph=init_sub_graph(nb_frames)\n",
    "    dict_merchants_copy,dict_cc_num_copy=bipartite_dict(dict_merchants,dict_cc_num)    \n",
    "    time_frame_size=len(X_train_ultra_simple) / num_frame\n",
    "    start = time.time()\n",
    "    connected_count=0\n",
    "    i=0\n",
    "    i2=0\n",
    "    sub_g=0\n",
    "    while (i<len(X_train_ultra_simple)):\n",
    "        a=X_train_ultra_simple[\"merchant\"][i]# rendre plus lisible\n",
    "        b=X_train_ultra_simple[\"cc_num\"][i]\n",
    "        if(sous_graph[sub_g].has_edge(a,b)):\n",
    "            sous_graph[sub_g][a][b][\"weight\"]=sous_graph[sub_g][a][b][\"weight\"]+1 \n",
    "        else:\n",
    "            sous_graph[sub_g].add_edge(a,b,weight=1,edge_id=i)\n",
    "            #sous_graph[sub_g][a][\"bipartite\"]=0\n",
    "            #sous_graph[sub_g][b][\"bipartite\"]=1\n",
    "        i=i+1\n",
    "        i2=i2+1\n",
    "        if i2>= time_frame_size:\n",
    "            nx.set_node_attributes(sous_graph[sub_g], dict_merchants_copy, \"bipartite\")\n",
    "            nx.set_node_attributes(sous_graph[sub_g], dict_cc_num_copy, \"bipartite\")\n",
    "            i2=0\n",
    "            if(nx.is_connected(sous_graph[sub_g])):\n",
    "                connected_count+=1\n",
    "            sub_g=sub_g+1\n",
    "\n",
    "    print(\"---graph split = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "\n",
    "    return sous_graph,connected_count\n",
    "\n",
    "\n",
    "def invert_graph(gr):\n",
    "    new_graph=nx.MultiGraph()\n",
    "    #tous les arc d'un sommet sont connecté entre eux\n",
    "    #step 1 = dans new_graph creer un sommet pour chaque arc\n",
    "\n",
    "    for edge in gr.edges(data=True):\n",
    "        #print(edge)\n",
    "        node_id=edge[2][\"edge_rid\"]\n",
    "        new_graph.add_node(node_id)\n",
    "\n",
    "        #print(\" g[edge[0]][edge[1]][edge_id] = \",g[edge[0]][edge[1]][\"edge_id\"])\n",
    "    #pour chaque node de g relier enssemble tous les arc\n",
    "    for node in gr.nodes:\n",
    "        _edge_list=list(gr.edges(node,data=\"edge_rid\"))\n",
    "        node_list=[]\n",
    "        i=0\n",
    "        #print(_edge_list)\n",
    "        for items in _edge_list:\n",
    "            #print(node[0])\n",
    "            node_list.append(_edge_list[i][2])\n",
    "            i=i+1            \n",
    "        fill(new_graph,node_list)\n",
    "\n",
    "\n",
    "    return new_graph\n",
    "\n",
    "def invert_graph_deprecated(gr):\n",
    "    new_graph=nx.MultiGraph()\n",
    "    #tous les arc d'un sommet sont connecté entre eux\n",
    "    #step 1 = dans new_graph creer un sommet pour chaque arc\n",
    "\n",
    "    for edge in gr.edges(data=True):\n",
    "        #print(edge)\n",
    "        node_id=edge[2][\"edge_rid\"]\n",
    "        new_graph.add_node(node_id)\n",
    "\n",
    "        #print(\" g[edge[0]][edge[1]][edge_id] = \",g[edge[0]][edge[1]][\"edge_id\"])\n",
    "    #pour chaque node de g relier enssemble tous les arc\n",
    "    for node in gr.nodes:\n",
    "        dico=list(gr[node])# traitement de 1 node\n",
    "        #print(dico)\n",
    "        node_list=[]\n",
    "        for key in dico:\n",
    "            \n",
    "            node_id=gr[node][key][0][\"edge_rid\"]# to test\n",
    "            node_list.append(node_id)\n",
    "        fill(new_graph,node_list)\n",
    "\n",
    "\n",
    "    return new_graph\n",
    "\n",
    "\n",
    "def create_inverted_sub_graph(sous_graph):\n",
    "    start = time.time\n",
    "    inv_sous_graph=[]\n",
    "    for sg in sous_graph:\n",
    "        inv_sous_graph.append(invert_graph(sg))\n",
    "        print(\".\",end=\"\")\n",
    "    return inv_sous_graph\n",
    "    print(\"---create_inverted_sub_graph  %s seconds ---\" % (time.time() - start));start = time.time\n",
    "\n",
    "\n",
    "\n",
    "def start_time_eval():\n",
    "    start = time.time()\n",
    "    i=0\n",
    "    while(i<1000000):\n",
    "        i=i+1\n",
    "    boucle_time=time.time() - start\n",
    "    start = time.time()\n",
    "    i=0\n",
    "    while(i<1000000):\n",
    "        poubelle =time.time()\n",
    "        i=i+1\n",
    "    print(\"---1 milion de time.time=  %s seconds ---\" % (time.time() - start-boucle_time));start = time.time()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#return le nombre d'arete du graph weighted_g\n",
    "def nb_edge(weighted_g):\n",
    "    summ=0\n",
    "    NODES = list(weighted_g.nodes)\n",
    "    for node in NODES:\n",
    "        summ= summ+G.degree[node]\n",
    "    return summ/2\n",
    "\n",
    "def replissement(weighted_g, nb_merc,nb_cc_num):\n",
    "    nb_edges=nb_edge(weighted_g)\n",
    "    nb_max_edges =(nb_merc* nb_cc_num)#graph bipati\n",
    "    return  nb_edges / nb_max_edges\n",
    "    \n",
    "def edge_repartition(g,len_dict_merchants):\n",
    "    repartition=[]\n",
    "    #remplissage de repartiotion avec 0 pour eviter les bugg\n",
    "    \n",
    "    #for each vertex \n",
    "        # for each edge in vertex.edges\n",
    "            #repartition[ edge.poid ] ++\n",
    "    print (\"\")\n",
    "    \n",
    "\n",
    "def slow_concat(d1,d2):\n",
    "    return dict(d1.items() | d2.items())\n",
    "\n",
    "def ditc_maping_so_slow_but_why(X_train_ultra_simple,dict_merchants,dict_cc_num):\n",
    "    #---dictionary maping = 4272.313026428223 seconds ---\n",
    "    start = time.time()\n",
    "    size =len(X_train_ultra_simple)\n",
    "    i=0\n",
    "    time_val=[]\n",
    "    while (i<size):\n",
    "        X_train_ultra_simple.iat[i,0]=dict_merchants[X_train_ultra_simple.iat[i,0]]\n",
    "        X_train_ultra_simple.iat[i,1]=dict_cc_num[X_train_ultra_simple.iat[i,1]]\n",
    "        time_val.append(time.time() - start);start = time.time()\n",
    "        i=i+1\n",
    "    return time_val\n",
    "\n",
    "\n",
    "def ditc_maping(X_train_ultra_simple,dict_merchants_cc_num):\n",
    "    X_train_ultra_simple[\"merchant\"].replace(dict_merchants_cc_num, inplace=True)\n",
    "    X_train_ultra_simple[\"cc_num\"].replace(dict_merchants_cc_num, inplace=True)\n",
    "\n",
    "def ditc_maping_2(X_train_ultra_simple,dict_merchants_cc_num):\n",
    "    X_train_ultra_simple[\"merchant\"].replace(dict_merchants_cc_num, inplace=True)\n",
    "    X_train_ultra_simple[\"cc_num\"].replace(dict_merchants_cc_num, inplace=True)\n",
    "\n",
    "    \n",
    "def create_split_dict(X_train_ultra_simple):\n",
    "    start = time.time()\n",
    "    dict_merchants=dict()\n",
    "    dict_cc_num=dict()\n",
    "    index =0\n",
    "    merc_id=0\n",
    "    cc_id=0\n",
    "    while index < len(X_train_ultra_simple):\n",
    "        if X_train_ultra_simple[\"merchant\"][index] not in dict_merchants.keys():\n",
    "            dict_merchants[X_train_ultra_simple[\"merchant\"][index]] = merc_id\n",
    "            merc_id=merc_id+1\n",
    "        index=index+1\n",
    "\n",
    "    print(\"---remplissage dict_merchants  %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    index=0\n",
    "    while index < len(X_train_ultra_simple):\n",
    "        if X_train_ultra_simple[\"cc_num\"][index] not in dict_cc_num.keys():\n",
    "            dict_cc_num[X_train_ultra_simple[\"cc_num\"][index]] = merc_id\n",
    "            merc_id=merc_id+1\n",
    "        index=index+1\n",
    "\n",
    "    print(\"---remplissage dict_cc_num %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return dict_merchants,dict_cc_num\n",
    "\n",
    "def create_dict(X_train_ultra_simple):\n",
    "    dict_merchants,dict_cc_num=create_split_dict(X_train_ultra_simple)\n",
    "    \n",
    "    return slow_concat(dict_merchants,dict_cc_num)\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "#########################################################################\n",
    "def create_dictionary_hell():# missing double values\n",
    "    start = time.time()\n",
    "    dictionary_hell=[]\n",
    "    nodes=[]\n",
    "    nb_sg=len(sous_graph)\n",
    "    print(len(sous_graph))\n",
    "    sg_index=0\n",
    "    merc_id=0\n",
    "    while sg_index < nb_sg:\n",
    "        i=0\n",
    "        merc_id=0\n",
    "        nodes= list(sous_graph[sg_index].nodes)\n",
    "        dictionary_hell.append(dict())\n",
    "        while( i<len(nodes)):\n",
    "            if nodes[i] not in dictionary_hell[sg_index].keys():\n",
    "                dictionary_hell[sg_index][nodes[i]] = merc_id\n",
    "                merc_id=merc_id+1\n",
    "                \n",
    "            i=i+1\n",
    "\n",
    "        sg_index=sg_index+1\n",
    "    print(\"--- dictionary__hell %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return dictionary_hell\n",
    "\n",
    "def relabel_graph(r_sous_graph,dictionary_hell,sous_graph):\n",
    "    print (\"relabel_\",end=\"\")\n",
    "    start = time.time()\n",
    "    i=0  \n",
    "    while i<len(sous_graph):\n",
    "        r_sous_graph.append(nx.relabel_nodes(sous_graph[i], dictionary_hell[i],copy=True))\n",
    "        i=i+1\n",
    "        print(\".\",end=\"\")\n",
    "    print(\"--- relabel_graph %s seconds ---\" % (time.time() - start))\n",
    "\n",
    "def unrelabel_graph(unr_sous_graph,dictionary_hell,sous_graph):\n",
    "    start = time.time()\n",
    "    i=0\n",
    "    while i<len(dictionary_hell):\n",
    "        if i==len(sous_graph):\n",
    "            (print(\"errno=\",i,end=','))\n",
    "        inv_map = {v: k for k, v in dictionary_hell[i].items()}\n",
    "        unr_sous_graph.append(nx.relabel_nodes(sous_graph[i], inv_map,copy=True))\n",
    "        i=i+1\n",
    "    print(\"--- revert labelling %s seconds ---\" % (time.time() - start))\n",
    "\n",
    "\n",
    "def print_info_diverses(X_train_ultra_simple,dico):\n",
    "    print(X_train_ultra_simple[\"merchant\"][0])\n",
    "    print(X_train_ultra_simple[\"cc_num\"][0])\n",
    "    print(X_train_ultra_simple.columns)\n",
    "    print(X_train_ultra_simple.loc[0][\"merchant\"])\n",
    "\n",
    "    print (len(dico) , \"humans in the system \")#1676\n",
    "    print(X_train_ultra_simple[\"cc_num\"][0])\n",
    "    print (dict_merchants[ \"fraud_Rippin, Kub and Mann\"], type(dico[ \"fraud_Rippin, Kub and Mann\"]))\n",
    "    \n",
    "\n",
    "#laplacian similarity 1/2\n",
    "def select_k(spectrum, minimum_energy = 0.9):#\n",
    "    running_total = 0.0\n",
    "    total = sum(spectrum)\n",
    "    if total == 0.0:\n",
    "        return len(spectrum)\n",
    "    for i in range(len(spectrum)):\n",
    "        running_total += spectrum[i]\n",
    "        if running_total / total >= minimum_energy:\n",
    "            return i + 1\n",
    "    return len(spectrum)\n",
    "\n",
    "#laplacian similarity 2/2\n",
    "def laplacian_similarity(graph1,graph2):\n",
    "    laplacian1 = nx.spectrum.laplacian_spectrum(graph1)\n",
    "    laplacian2 = nx.spectrum.laplacian_spectrum(graph2)\n",
    "\n",
    "    k1 = select_k(laplacian1)\n",
    "    k2 = select_k(laplacian2)\n",
    "    k = min(k1, k2)\n",
    "    print(\"k selected =\",k)\n",
    "    similarity = sum((laplacian1[:k] - laplacian2[:k])**2)\n",
    "    return similarity\n",
    "\n",
    "def string_edit_dist():\n",
    "    print(\"https://anhaidgroup.github.io/py_stringmatching/v0.3.x/Levenshtein.html\")\n",
    "def edit_dist_nx(g1,g2):\n",
    "    \n",
    "    for v in nx.optimize_graph_edit_distance(g1, g2):\n",
    "        minv = v\n",
    "    return minv\n",
    "\n",
    "\n",
    "def graph_degree(g):\n",
    "    degrees = [val for (node, val) in g.degree()]\n",
    "    maxd=max(degrees)\n",
    "    avg=sum(degrees)/len(degrees)\n",
    "    print(\"max degree =\",maxd,\" mean = \",avg)\n",
    "    return maxd,avg\n",
    "def print_graph_info(connected_count):\n",
    "    \n",
    "    print(connected_count,\"connected graphs\")\n",
    "    print(len(sous_graph[0].edges),\" transactions \")\n",
    "    print(\"sous_graph[0][0] , type = \",type(sous_graph[0][0]),\"\\n\")\n",
    "    print(\"sous_graph[0].nodes , type = \",type(sous_graph[0].nodes),\"\\n\")\n",
    "    print(list(sous_graph[0].nodes))\n",
    "    print(\"------------\")\n",
    "    sub_g=0;node=0\n",
    "    dico=dict(sous_graph[sub_g][node])\n",
    "    for key in dico:\n",
    "         print(sous_graph[0][0][key],\"key = \",key)\n",
    "    print(dict(sous_graph[0][0]))\n",
    "    print(\"------------\")\n",
    "    print( type(sous_graph[0][0][693]))\n",
    "    print(sous_graph[0][0][693])\n",
    "    print(\"---------\")\n",
    "    print((sous_graph[0].edges))\n",
    "    \n",
    "def draw_1(g):\n",
    "    start = time.time()\n",
    "    #subax1 = plt.subplot()\n",
    "    nx.draw(sous_graph[0], with_labels=False, node_size= 1)\n",
    "    plt.savefig(\"draw_1.png\")\n",
    "    plt.show()\n",
    "    print(\"---draw  %s seconds ---\" % (time.time() - start));start = time.time\n",
    "def draw_2(g):\n",
    "    start = time.time()\n",
    "    #subax2 = plt.subplot()\n",
    "    options = {\n",
    "        'node_size': 100,\n",
    "        'width': 3,\n",
    "    }\n",
    "    nx.draw_spectral(g, **options)#approximation of the ratio cut\n",
    "    plt.savefig(\"draw_2.png\")\n",
    "    plt.show()\n",
    "    print(\"---draw  %s seconds ---\" % (time.time() - start));start = time.time\n",
    "def draw_3(g):\n",
    "    start = time.time()\n",
    "    #subax3 = plt.subplot()\n",
    "\n",
    "    nx.draw_shell(g, with_labels=False,node_size= 1)# font_weight='bold')\n",
    "    plt.savefig(\"draw_3.png\")\n",
    "    plt.show()\n",
    "    print(\"---draw  %s seconds ---\" % (time.time() - start));start = time.time\n",
    "    \n",
    "def draw_4(g,numb_merchant):\n",
    "    total=len(g.nodes)#les valeures ascossié ne sont pas les bonnes mais c'est \n",
    "    X = list(range(0,numb_merchant ))# juste pour la position geographique \n",
    "    Y= list(range(numb_merchant,total ))\n",
    "    pos = dict()\n",
    "    pos.update( (n, (1, i)) for i, n in enumerate(X) ) # put nodes from X at x=1\n",
    "    pos.update( (n, (2, i)) for i, n in enumerate(Y) ) # put nodes from Y at x=2\n",
    "    nx.draw(g, pos=pos,node_size= 1)\n",
    "    plt.savefig(\"draw_4.png\")\n",
    "    plt.show()\n",
    "\n",
    "def drawing(g):\n",
    "    %matplotlib inline\n",
    "    draw_1(g)\n",
    "    draw_2(g)\n",
    "    draw_3(g)\n",
    "    draw_4(g,len(dict_merchants.keys()))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def complexity_calculations():\n",
    "    val=0\n",
    "    train_size=len(Y_train)\n",
    "    test_size=len(Y_test)\n",
    "    \n",
    "    #l'idee premiere\n",
    "    print(\"-----------------\")\n",
    "    print(\"tester la similarité de 1 graph modifié avec tt les autres \")\n",
    "    print(\"pour 0.5 sec par calcul et \",num_frame,\" frames\" )\n",
    "    print( num_frame*0.5,\" sec\")\n",
    "    print(\"-----------------\")\n",
    "    print(\"modifier le graph et recomencer , pour chaques valeures dans train\")\n",
    "    print(\"pour completement calculer  les similarité de 1 transaction\")\n",
    "    print( num_frame*0.5*train_size,\" sec\")\n",
    "    print(\"donc \",int(num_frame*0.5*train_size/(3600*24)),\" jours\")\n",
    "    print(\"-----------------\")\n",
    "    \n",
    "    big_number = num_frame*0.5*train_size*test_size\n",
    "    big_number_year=int(big_number/31540000)\n",
    "    print(\"pour un total de \",big_number,\" sec\")\n",
    "    print(\"donc \",big_number_year,\" ans\")\n",
    "    print(\"-----------------\")\n",
    "    print(\"en reduisant la precision au minimum\")\n",
    "    print(\"chaque transaction n'aura que 1 calcul de similarité\")\n",
    "    print(\"precision max 50% , doubler le temps de calcul double la precision\")\n",
    "    big_number=0.5*test_size\n",
    "    print(\"pour un total de \",big_number,\" sec\")\n",
    "    print(\"donc \",int(big_number/3600),\" heures\")\n",
    "    \n",
    "def print_version():\n",
    "    print (\"python \",sys.version)\n",
    "\n",
    "\n",
    "def hope_on_inv_sg(inv_sg):\n",
    "\n",
    "    start = time.time()\n",
    "    # hope attributed example\n",
    "    model = HOPE(dimensions=58)\n",
    "    liste=[]\n",
    "    i=0\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=num_frame)\n",
    "    while (i<num_frame):\n",
    "        # train the model and generate embeddings\n",
    "        process_bar.update(i)\n",
    "        model.fit(inv_sg[i])\n",
    "        liste.append(model.get_embedding())\n",
    "        i+=1\n",
    "    print(\"---hope embedding = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return liste  \n",
    "\n",
    "def deepwalk_on_inv_sg(inv_sg):\n",
    "\n",
    "    start = time.time()\n",
    "    # hope attributed example\n",
    "    model = DeepWalk(dimensions=58)\n",
    "    liste=[]\n",
    "    i=0\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=num_frame)\n",
    "    while (i<num_frame):\n",
    "        # train the model and generate embeddings\n",
    "        process_bar.update(i)\n",
    "        model.fit(inv_sg[i])\n",
    "        liste.append(model.get_embedding())\n",
    "        i+=1\n",
    "    print(\"---deepwalk embedding = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return liste      \n",
    "\n",
    "\n",
    "print(\"fonctions declaré a :\",time.strftime(\"%H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431325d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long']\n"
     ]
    }
   ],
   "source": [
    "##download data\n",
    "\n",
    "program_start = time.time()\n",
    "\n",
    "import os\n",
    "data_file= os.path.abspath('../../data')\n",
    "full_path=data_file+'\\\\'+'fraudTrain.csv'\n",
    "train_df=pd.read_csv(full_path)\n",
    "full_path=data_file+'\\\\'+'fraudTest.csv'\n",
    "test_df=pd.read_csv(full_path)\n",
    "\n",
    "cols = train_df.columns.tolist()\n",
    "cols = [c for c in cols if c not in [\"is_fraud\"]]\n",
    "target = \"is_fraud\"\n",
    "print(cols)\n",
    "\n",
    "#Definition des nouvelles variables X_train and Y_train\n",
    "X_train = train_df[cols]\n",
    "Y_train = train_df[target]\n",
    "\n",
    "#Definition des nouvelles variables X_test and Y_test\n",
    "X_test = test_df[cols]\n",
    "Y_test = test_df[target]\n",
    "\n",
    "features = [ 'merchant', 'cc_num']\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]\n",
    "\n",
    "X_train_ultra_simple = X_train.copy()\n",
    "X_test_ultra_simple = X_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d79b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---remplissage dict_merchants  7.904718637466431 seconds ---\n",
      "---remplissage dict_cc_num 9.43501615524292 seconds ---\n",
      "---dictionary maping = 52.46685242652893 seconds ---\n",
      "---graph construction = 20.6938796043396 seconds ---\n",
      "---graph split = 24.268494367599487 seconds ---\n",
      "189  connected graphs\n",
      "---depuis le debut  122.91589331626892 seconds ---\n",
      "try\n",
      "MultiGraph with 1583 nodes and 6484 edges\n",
      "1583\n",
      "1676\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#remplissage des dictionaires\n",
    "\n",
    "dict_merchants,dict_cc_num=create_split_dict(X_train_ultra_simple)\n",
    "dictionary=slow_concat(dict_merchants,dict_cc_num)\n",
    "#dictionary=create_dict(X_train_ultra_simple)\n",
    "\n",
    "# associer a chaque marchant son numero dans le dictionaire\n",
    "#pour la lisibilité , et l'affichage\n",
    "start = time.time()\n",
    "ditc_maping(X_train_ultra_simple,dictionary)\n",
    "\n",
    "print(\"---dictionary maping = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "\n",
    "\n",
    "#pip install tk\n",
    "\n",
    "    ##creation du graph\n",
    "    \n",
    "\n",
    "g = create_graph(X_train_ultra_simple)#40 sec\n",
    "\n",
    "#!jupyter notebook --generate-config\n",
    "# divison en plusieures sous graphs #20 sec\n",
    "\n",
    "sous_graph,connected_count=create_sub_graph(g,num_frame,dict_merchants,dict_cc_num)\n",
    "#dictionary_hell=create_dictionary_hell()\n",
    "\n",
    "#pour afficher , attention au cascades\n",
    "#!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "\n",
    "\n",
    "print(connected_count,\" connected graphs\")\n",
    "i=3\n",
    "#while(i<num_frame):# doesnt work or my graph are the same\n",
    "while(i<3):\n",
    "    start = time.time()\n",
    "\n",
    "    print (\"-------------------------------------\")\n",
    "    #laplacian marche\n",
    "    val = laplacian_similarity(sous_graph[0],sous_graph[i])\n",
    "    #val1=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=60,upper_bound=1e10)\n",
    "    #val2=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=120,upper_bound=1e10)\n",
    "    #val3=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=180,upper_bound=1e10)\n",
    "    #print (\"comparing \",hex(id(sous_graph[0])),\" and \",hex(id(sous_graph[i])))\n",
    "    #print (val1,\" \",val2,\" \",val3) \n",
    "    print(sous_graph[0])\n",
    "    print(sous_graph[i]) \n",
    "    print(\" similarity = \",val)\n",
    "    print(\"---laplacian similarity = %s seconds ---\" %         f\"{(time.time() - start):.4}\"    );start = time.time()\n",
    "\n",
    "    print (\"-------------------------------------\")\n",
    "    i=i+1\n",
    "''' \n",
    "plan,strategie , objectif\n",
    "changement de plan\n",
    "probleme , le poid des arc devien quoi ? \n",
    "comment ajouter amt apres coup , il suffit de l'ajouter sur les donnée\n",
    "avan le SOM\n",
    "                                            probably better\n",
    "j'inverse le graph                |  je le coupe en n sous_graphs\n",
    "je le coupe en n sous_graphs      |  j'inverse les sous_graphs\n",
    "\n",
    "\n",
    "je compresse les sous graphs \n",
    "je SOM sur les cous graphs\n",
    "\n",
    "complexité= O(n*tps_compression + SOM) // SOM = 6min = negligeable\n",
    "'''    \n",
    "\n",
    "\n",
    "print(\"---depuis le debut  %s seconds ---\" % (time.time() - program_start));start = time.time\n",
    "#!git clone https://github.com/shenweichen/GraphEmbedding.git\n",
    "\n",
    "def int_to_str(G):\n",
    "    # convert nodes from int to str format\n",
    "    keys = np.arange(0,int(len(dictionary.keys())))\n",
    "    values = [str(i) for i in keys]\n",
    "    dic = dict(zip(keys, values))\n",
    "    H = nx.relabel_nodes(G, dic)\n",
    "\n",
    "def my_fun():\n",
    "    print('How many cats do you have?\\n')\n",
    "    numCats = input()\n",
    "    try:\n",
    "        if int(numCats) > 3:\n",
    "            print('That is a lot of cats.')\n",
    "        else:\n",
    "            print('That is not that many cats.')\n",
    "    except ValueError:\n",
    "        print(\"Value error\")  \n",
    "def modif_graph_testing(graph):\n",
    "    graph[1][2][\"weight\"]=2\n",
    "    \n",
    "def invert_node_testing():\n",
    "    graph=nx.MultiGraph()\n",
    "    graph.add_nodes_from([0,1,2,3,4])\n",
    "    graph.add_edge(0,1,weight=0,edge_id=\"a\")\n",
    "    graph.add_edge(1,2,weight=0,edge_id=\"b\")\n",
    "    graph.add_edge(2,3,weight=0,edge_id=\"c\")\n",
    "    graph.add_edge(3,4,weight=0,edge_id=\"d\")\n",
    "    graph.add_edge(4,2,weight=0,edge_id=\"e\")\n",
    "    print(graph.nodes)\n",
    "    print(graph.edges)\n",
    "    print(\"avan 1--2--3--4\")\n",
    "    #new_graph=inver t_graph(graph)\n",
    "    print(\"apres 1--2--3--4\")\n",
    "    print(new_graph.nodes)\n",
    "    print(new_graph.edges)\n",
    "    \n",
    "    \n",
    "embedings=list()\n",
    "#all_embeding(embedings,sous_graph)\n",
    "#all_embeding(embedings,sous_graph)\n",
    "print(\"try\")\n",
    "\n",
    "if(False):\n",
    "    liste=[]\n",
    "    i=0\n",
    "    num_frame=len(sous_graph)\n",
    "    G = sous_graph[i]\n",
    "    liste.append(encapsulation(G))\n",
    "    i+=1\n",
    "\n",
    "    G = sous_graph[i]\n",
    "    liste.append(encapsulation(G))\n",
    "    i+=1\n",
    "\n",
    "#crash_free()\n",
    "#!pip3 install PyQt5\n",
    "# affichage\n",
    "print(sous_graph[0])\n",
    "#drawing(sous_graph[0])\n",
    "\n",
    "print(len(sous_graph[0].nodes))\n",
    "print(len(g.nodes))\n",
    "\n",
    "\n",
    "#370 MiB = 300 000 Mo\n",
    "# avec g/200 ca compile , tres .... lentement , mais ca compile\n",
    "too_long=True\n",
    "if(not too_long):\n",
    "    val = edit_dist_nx(sous_graph[0],sous_graph[1])\n",
    "\n",
    "\n",
    "affichage=False\n",
    "if(affichage):\n",
    "    complexity_calculations()\n",
    "    drawing(g)\n",
    "    print_graph_info(connected_count)\n",
    "\n",
    "\n",
    "### partie karateclub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6a91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### partie karateclub\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e3cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................--- graph construction = 58.506235122680664 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#graph construction\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "inv_sg = create_inverted_sub_graph(sous_graph)\n",
    "\n",
    "#r_sous_graph=[]\n",
    "#relabel_graph(r_sous_graph,dictionary_hell,inv_sg)\n",
    "#unr_sous_graph=[]\n",
    "#unrelabel_graph(unr_sous_graph,dictionary_hell,r_sous_graph)\n",
    "\n",
    "print(\"--- graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b06d26a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#inv_sg = create_inverted_sub_graph(sous_graph)\n",
    "#for node in inv_sg[30].nodes(data=True):\n",
    "    #print(node)\n",
    "def is_it_missing_a_number(whatever):\n",
    "    missing=False\n",
    "    if isinstance(whatever,dict):\n",
    "    \n",
    "        l=sorted(whatever.keys())\n",
    "        i=0\n",
    "        while i<len(l):\n",
    "            if l[i]!=i:\n",
    "                missing=True\n",
    "            i=i+1\n",
    "        i=i-1\n",
    "        #print(\"len(dict)= \",len(l),\" , lastval = \",l[i],end=\" \")\n",
    "        if(missing):\n",
    "            print(\" missing a number\",end=\" \")\n",
    "            return True\n",
    "    if isinstance(whatever,list):\n",
    "        l=sorted(whatever)\n",
    "        i=0\n",
    "        while i<len(l):\n",
    "            if l[i]!=i:\n",
    "                missing=True\n",
    "            i=i+1\n",
    "        i=i-1\n",
    "        #print(\"len(list)= \",len(l),\" , lastval = \",l[i],end=\" \")\n",
    "        if(missing):\n",
    "            print(\" missing a number\",end=\" \")\n",
    "            return True\n",
    "    #print(\"\\n\")\n",
    "    return False\n",
    "    \n",
    "def is_inv_working():\n",
    "    print (len(inv_sg[30].nodes))\n",
    "    l1=list(inv_sg[30].nodes)\n",
    "    l2=list(unr_sous_graph[30].nodes)\n",
    "    i=0\n",
    "    while(i<len( inv_sg[30])):\n",
    "        if(l1[i] != l2[i]):\n",
    "            print(\"not_the_same\")\n",
    "        i=i+1\n",
    "\n",
    "\n",
    "    i=0# il y a au moins les memes values\n",
    "    for k in inv_sg[30] :\n",
    "        #print(\",\",end=\"\");i=i+1\n",
    "        if k not in(unr_sous_graph[30] ):\n",
    "            print(\"not_the_same\")\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f71190ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sorted(list(r_sous_graph[0].nodes)))\n",
    "#print(sorted((dictionary_hell[0]).keys()))\n",
    "#is_it_missing_a_number(dictionary_hell[1])\n",
    "i=0\n",
    "while(i<len(inv_sg)):\n",
    "    nodes = inv_sg[i].nodes(data=False)\n",
    "    is_it_missing_a_number(list(nodes))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76816aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---hope embedding = 354.7910692691803 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#---hope embedding = 354.7910692691803 seconds ---\n",
    "hope_emb = hope_on_inv_sg(inv_sg)# doc reading needed , for node order\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Graph2Vec attributed example\n",
    "if(False):\n",
    "    small_sous_graph=[r_sous_graph[0],r_sous_graph[1]]\n",
    "    \n",
    "    model = Graph2Vec(attributed=False)\n",
    "    model.fit(small_sous_graph)\n",
    "    ecmb=model.get_embedding()\n",
    "\n",
    "    print(type(range(r_sous_graph[0].number_of_nodes())))\n",
    "\n",
    "    print(\"---embedding = %s seconds ---\" % (time.time() - start));start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e224bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepwalk_emb=deepwalk_on_inv_sg(inv_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675a616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f613f992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=nx.MultiGraph()\n",
    "if(True):\n",
    "    graph.add_edge(0,1,weight=1,edge_id=\"a\")\n",
    "    graph.add_edge(1,2,weight=1,edge_id=\"b\")\n",
    "    graph.add_edge(2,3,weight=2,edge_id=\"c\")\n",
    "    graph.add_edge(3,4,weight=1,edge_id=\"d\")\n",
    "    graph.add_edge(3,4,weight=1,edge_id=\"e\")\n",
    "print(graph.edges(data=True))\n",
    "l=graph.edges(3,data=\"edge_id\");i=0\n",
    "print(list(l)[1])\n",
    "\n",
    "\n",
    "for edge in graph.edges(data=True):\n",
    "    count_down=edge[2][\"weight\"]\n",
    "    while(count_down>0):\n",
    "        print(count_down)\n",
    "        count_down=count_down-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ded700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "_max=0\n",
    "for gr in inv_sg:\n",
    "    current_max,mean =graph_degree(gr)\n",
    "    if current_max>_max:\n",
    "        _max=current_max\n",
    "print (\"max degree= \",_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f5d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4895be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95586a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
