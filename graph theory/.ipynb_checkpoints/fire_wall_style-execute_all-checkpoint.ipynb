{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4de58f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import terminé a : 10:15:29\n"
     ]
    }
   ],
   "source": [
    "#import librairies \n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import progressbar\n",
    "import time\n",
    "from time import process_time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "    \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score,precision_score,recall_score, precision_recall_fscore_support \n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "\n",
    "#from sklearn_som.som import SOM\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from GEM.gem.utils      import graph_util, plot_util\n",
    "from GEM.gem.evaluation import visualize_embedding as viz\n",
    "from GEM.gem.evaluation import evaluate_graph_reconstruction as gr\n",
    "from GEM.gem.embedding.gf       import GraphFactorization\n",
    "#from GEM.gem.embedding.sdne     import SDNE\n",
    "#from argparse import ArgumentParser\n",
    "#from GraphEmbedding.ge import DeepWalk\n",
    "#from GraphEmbedding.ge import SDNE\n",
    "from karateclub.graph_embedding import Graph2Vec\n",
    "from karateclub.node_embedding.neighbourhood import HOPE\n",
    "from karateclub.node_embedding.neighbourhood import DeepWalk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_frame=200#arbitraire , a tester plus serieusement\n",
    "\n",
    "print(\"import terminé a :\",time.strftime(\"%H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176c2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "953c2308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fonctions declaré a : 15:29:31\n"
     ]
    }
   ],
   "source": [
    "#ce dictionaire contien le nom de chaques colones avec la valeur du f1_score\n",
    "#qu'ils on obtenu apres etre ajouté au data_set\n",
    "#initialisé a 0\n",
    "#-1,name1,name2,w,b\n",
    "\n",
    "def convert_dist_to_zero_and_ones(data_set_dist, threshold=0.3):\n",
    "    new_data_set = data_set_dist < threshold\n",
    "    return new_data_set.astype(int)\n",
    "\n",
    "def create_pair_dict(columns_list=[]):\n",
    "    if (columns_list==[]):\n",
    "        print(\"you forgot to input a list of columns\")\n",
    "        return []\n",
    "    pair_dict=dict()\n",
    "    for name1 in columns_list:\n",
    "        for name2 in columns_list:# oui ce n'est pas optimisé\n",
    "            pair_names=name1+\"_\"+name2\n",
    "            reverse_pair_names=name2+\"_\"+name1\n",
    "            if name1!=name2 and pair_names not in pair_dict.keys() and reverse_pair_names not in pair_dict.keys():\n",
    "                pair_dict[pair_names]=[-1,name1,name2,0,0]\n",
    "    \n",
    "    return pair_dict\n",
    "\n",
    "def create_monstruous_pair_data_set_deprecated(pair_dict,panda_data_set):\n",
    "    columns_list = panda_data_set.columns.tolist()\n",
    "    if (columns_list==[]):\n",
    "        print(\"you forgot to input a data_set\")\n",
    "        return {},[]\n",
    "    if (pair_dict=={}):\n",
    "        print(\"you forgot to input a dict\")\n",
    "        return {},[]\n",
    "    #pair_dict=dict()\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(pair_dict));i=0\n",
    "    monstruous_pair_data_set=[]\n",
    "    for pair in pair_dict.items():\n",
    "        pair_dict[pair[0]][0]=i\n",
    "        #print(pair[1][0],pair[1][1],pair[1][2])# value name1,name2\n",
    "        tmp_data_set=panda_data_set[[pair[1][1],pair[1][2]]]\n",
    "        tmp_w,tmp_b=linear_regresion(tmp_data_set)\n",
    "        pair_dict[pair[0]][3]=tmp_w\n",
    "        pair_dict[pair[0]][4]=tmp_b\n",
    "        monstruous_pair_data_set.append(distances(tmp_data_set,tmp_w,tmp_b))\n",
    "        process_bar.update(i);i+=1\n",
    "    #the monstruous data_set should contain 0 and 1\n",
    "    return pair_dict,monstruous_pair_data_set\n",
    "\n",
    "def create_monstruous_pair_data_set(pair_dict,panda_data_set):\n",
    "    columns_list = panda_data_set.columns.tolist()\n",
    "    if (columns_list==[]):\n",
    "        print(\"you forgot to input a data_set\")\n",
    "        return {},[]\n",
    "    if (pair_dict=={}):\n",
    "        print(\"you forgot to input a dict\")\n",
    "        return {},[]\n",
    "    #pair_dict=dict()\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(pair_dict));i=0\n",
    "    monstruous_pair_data_set=np.array([])\n",
    "    for pair in pair_dict.items():\n",
    "        #print(pair[1][0],pair[1][1],pair[1][2])# id,name1,name2,w,b\n",
    "        pair_dict[pair[0]][0]=i\n",
    "        tmp_data_set=panda_data_set[[pair[1][1],pair[1][2]]]\n",
    "        tmp_w,tmp_b=linear_regresion(tmp_data_set)\n",
    "        pair_dict[pair[0]][3]=tmp_w\n",
    "        pair_dict[pair[0]][4]=tmp_b\n",
    "        \n",
    "        if(monstruous_pair_data_set.size ==0):\n",
    "            monstruous_pair_data_set=distances_expand(tmp_data_set,tmp_w,tmp_b)\n",
    "        else:\n",
    "            monstruous_pair_data_set=np.concatenate((monstruous_pair_data_set,distances_expand(tmp_data_set,tmp_w,tmp_b)),axis=1)\n",
    "        process_bar.update(i);i+=1\n",
    "    #the monstruous data_set should contain 0 and 1\n",
    "    return pair_dict,monstruous_pair_data_set\n",
    "\n",
    "def make_one_graph(line ,pair_dict):\n",
    "    g=nx.Graph()\n",
    "    \n",
    "    for pair in pair_dict.items():\n",
    "        #print(pair[1][0],pair[1][1],pair[1][2])# id,name1,name2,w,b\n",
    "        i= pair[1][0]\n",
    "        arc_val=line[i]\n",
    "\n",
    "        if arc_val ==1:\n",
    "            name_1=pair[1][1]\n",
    "            name_2=pair[1][2]\n",
    "            g.add_edge(name_1,name_2)\n",
    "    \n",
    "    return g\n",
    "\n",
    "def create_graphs(monstruous_binary_np_data_set,pair_dict):\n",
    "    start = time.time()\n",
    "    graph_list=[]\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(monstruous_binary_np_data_set));i=0\n",
    "   \n",
    "    for line in monstruous_binary_np_data_set:\n",
    "        #print(type(line),line.shape)\n",
    "\n",
    "        graph_list.append( make_one_graph(line ,pair_dict))\n",
    "        process_bar.update(i);i+=1\n",
    "    print(\"---graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    " \n",
    "    return graph_list\n",
    "\n",
    "def save_np(np_array,name):\n",
    "    if(\".npy\" not in name):\n",
    "        print(\"you save a numpy array in a file.npy\")\n",
    "        return 0\n",
    "    np.save(name, np_array)\n",
    "\n",
    "def load_np(file_name):\n",
    "    return np.load(file_name)\n",
    "\n",
    "    \n",
    "############################################## liste des options d'extractions\n",
    "def graph_max_degree(g):\n",
    "    degrees = [val for (node, val) in g.degree()]\n",
    "    maxd=max(degrees)\n",
    "    return maxd\n",
    "def geodesic_dist(graph):\n",
    "    return nx.average_shortest_path_length(graph)\n",
    "\n",
    "#special thanks to Francisco A. Rodrigues, University of São Paulo.\n",
    "# http://conteudo.icmc.usp.br/pessoas/francisco\n",
    "def degree_distribution(G):\n",
    "    vk = dict(G.degree())\n",
    "    vk = list(vk.values()) # we get only the degree values\n",
    "    maxk = np.max(vk)\n",
    "    mink = np.min(min)\n",
    "    kvalues= np.arange(0,maxk+1) # possible values of k\n",
    "    Pk = np.zeros(maxk+1) # P(k)\n",
    "    for k in vk:\n",
    "        Pk[k] = Pk[k] + 1\n",
    "    Pk = Pk/sum(Pk) # the sum of the elements of P(k) must to be equal to one\n",
    "    return kvalues,Pk\n",
    "def shannon_entropy(G):\n",
    "    k,Pk = degree_distribution(G)\n",
    "    H = 0\n",
    "    for p in Pk:\n",
    "        if(p > 0):\n",
    "            H = H - p*math.log(p, 2)\n",
    "    return H\n",
    "\n",
    "def contain_meso_scale(graph):\n",
    "    \n",
    "    return False    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_info_from_one_graph(g, to_do_list):\n",
    "    graph_property=np.array([])\n",
    "    calc_result=0\n",
    "    \n",
    "    if(\"max_degree\" in to_do_list):\n",
    "        #print (\" max degree\")\n",
    "        calc_result=graph_max_degree(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"assortativity\" in to_do_list):\n",
    "        calc_result = nx.degree_assortativity_coefficient(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"clustering\" in to_do_list):\n",
    "        calc_result= approximation.average_clustering(g, trials=1000, seed=10)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"global_efficiency\" in to_do_list):\n",
    "        calc_result= nx.global_efficiency(g)\n",
    "        graph_property=np.append(graph_property,calc_result)   \n",
    "    if(\"geodesic_dist\" in to_do_list):\n",
    "        if nx.is_connected(g):\n",
    "            calc_result=geodesic_dist(g)\n",
    "        else:\n",
    "            calc_result=len(g.nodes()) # = la dist la plus grande\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"contain_meso_scale\" in to_do_list):#to do\n",
    "        calc_result=contain_meso_scale(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"Shannon_entropy\" in to_do_list):#to do\n",
    "        calc_result=shannon_entropy(g)\n",
    "        graph_property=np.append(graph_property,calc_result)  \n",
    "    #change this ()\n",
    "    #            ()\n",
    "    #            ()\n",
    "    #      to this ()()()\n",
    "    return np.expand_dims(graph_property,axis=0)\n",
    "\n",
    "def extract_info_from_graphs(graph_list, to_do_list):\n",
    "    \n",
    "    monstruous_info_data_set=np.array([])\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(graph_list));i=0\n",
    "   \n",
    "    \n",
    "    for graph in graph_list:\n",
    "        \n",
    "        if(monstruous_info_data_set.size ==0):\n",
    "            monstruous_info_data_set=extract_info_from_one_graph(graph, to_do_list)\n",
    "        else:\n",
    "            monstruous_info_data_set=np.concatenate((monstruous_info_data_set,extract_info_from_one_graph(graph, to_do_list)),axis=0)\n",
    "        process_bar.update(i);i+=1\n",
    "    \n",
    "    return monstruous_info_data_set\n",
    "\n",
    "\n",
    "\n",
    "def create_graphs_to_delete(monstruous_binary_np_data_set,pair_dict):\n",
    "    start = time.time()\n",
    "    graph_list=[]\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(monstruous_binary_np_data_set));i=0\n",
    "   \n",
    "    for line in monstruous_binary_np_data_set:\n",
    "        #print(type(line),line.shape)\n",
    "\n",
    "        graph_list.append( make_one_graph(line ,pair_dict))\n",
    "        process_bar.update(i);i+=1\n",
    "    print(\"---graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_info_from_binary_data_set(monstruous_binary_np_data_set,pair_dict, to_do_list):\n",
    "    start_time = process_time() \n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(monstruous_binary_np_data_set));i=0\n",
    "    monstruous_info_data_set=np.array([])\n",
    "    counter = 0\n",
    "    contruct_time=0\n",
    "    calcul_time=0\n",
    "    for line in monstruous_binary_np_data_set:\n",
    "        in_loop_time = process_time()\n",
    "        graph=make_one_graph(line ,pair_dict)\n",
    "        contruct_time = contruct_time+ process_time()  - in_loop_time\n",
    "        \n",
    "        in_loop_time = process_time()\n",
    "        if(monstruous_info_data_set.size ==0):\n",
    "            monstruous_info_data_set=extract_info_from_one_graph(graph, to_do_list)\n",
    "        else:\n",
    "            monstruous_info_data_set=np.concatenate((monstruous_info_data_set,extract_info_from_one_graph(graph, to_do_list)),axis=0)\n",
    "        calcul_time = calcul_time+ process_time()  - in_loop_time\n",
    "        process_bar.update(i);i+=1\n",
    "        \n",
    "        #####################################################################\n",
    "        del graph # je delete le graph pour etre sur de liberer la memoire\n",
    "        #gc.collect() #je n'appelle pas le garbageColector = cout 22 heures\n",
    "        #calcul_time =  521.984375 contruct_time 59.3125\n",
    "        #counter=counter+1\n",
    "        #if(counter == 100000):  \n",
    "            #print(process_time()  - start_time, \"seconds\");start_time = process_time()\n",
    "            #print(\"calcul_time = \",calcul_time,\"contruct_time\",contruct_time)\n",
    "            #return monstruous_info_data_set\n",
    "            \n",
    "        \n",
    "    \n",
    "    print(\"---graph extraction = %s seconds ---\" % (process_time()  - start_time));start_time = process_time()\n",
    "    return monstruous_info_data_set\n",
    "\n",
    "# Function to find distance line equation ax + by + c =0\n",
    "#y=mx+c  ----> mx -y +c =0  ---> b=-1 ,a=weight ,c=bias\n",
    "def shortest_distance(x1, y1, a, b, c):\n",
    "    \n",
    "    d = abs((a * x1 + b * y1 + c)) / (math.sqrt(a * a + b * b))\n",
    "    #print(\"Perpendicular distance is \",d)\n",
    "    return d\n",
    "\n",
    "def distances(data_set,w,b):\n",
    "    np_data=data_set.to_numpy()\n",
    "    np_dist=[]\n",
    "    for line in np_data:\n",
    "        x1=line[0]\n",
    "        y1=line[1]\n",
    "        np_dist.append(shortest_distance(x1, y1, w, -1, b))\n",
    "    \n",
    "    return np.array(np_dist)\n",
    "\n",
    "def distances_expand(data_set,w,b):\n",
    "    np_data=data_set.to_numpy()\n",
    "    np_dist=[]\n",
    "    for line in np_data:\n",
    "        x1=line[0]\n",
    "        y1=line[1]\n",
    "        np_dist.append(shortest_distance(x1, y1, w, -1, b))\n",
    "    \n",
    "    return np.expand_dims( np.array(np_dist)  ,axis=1)\n",
    "# y = mx +b\n",
    "def line_equation_from_two_points(x1,y1,x2,y2):\n",
    "    m=(y2-y1)/(x2-x1)\n",
    "    b=y1-m*x1\n",
    "    return m,b\n",
    "\n",
    "\n",
    "\n",
    "def shortest_distance_test():\n",
    "    print(shortest_distance(0, 0, 1, -1, 1))\n",
    "    print(shortest_distance(-1, 0, 1, -1, 1))\n",
    "    print(shortest_distance(1, 0, 1, -1, 1))\n",
    "    print(math.sqrt(2))\n",
    "    print(shortest_distance(3, 0, 1, -1, 1))\n",
    "    print(math.sqrt(2*2+2*2))\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def affiche_simple_graphique(threshold_list,recall,f1,title=\"\"):\n",
    "    %matplotlib inline\n",
    "    plt.plot(threshold_list,f1,  label='F1 score',color=\"green\")\n",
    "    plt.plot(threshold_list,recall,  label='recall',color=\"darkgoldenrod\")\n",
    "    plt.plot(threshold_list,[x*0 for x in threshold_list],  label='water level',color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    gain_recall=sum(recall)/len(recall)\n",
    "    gain_f1 = sum(f1)/len(f1)\n",
    "    if(gain_recall>=0):\n",
    "        print(\"average recall  \",'\\033[92m'+\"gain \"+ '\\033[0m',\"%.4f\" % gain_recall)\n",
    "    else:\n",
    "        print(\"average recall \",'\\033[91m'+\"loss \"+ '\\033[0m',\"%.4f\" % gain_recall)\n",
    "    if(gain_f1>=0):\n",
    "        print(\"average f1 score  \",'\\033[92m'+\"gain \"+ '\\033[0m',\"%.4f\" %gain_f1)\n",
    "    else:\n",
    "        print(\"average f1 score  \",'\\033[91m'+\"loss \"+ '\\033[0m',\"%.4f\" %gain_f1)\n",
    "\n",
    "def dict_mean(d_list,target=\"1\"):\n",
    "    dict_list=list()\n",
    "    mean_dict = {}\n",
    "    if(target==\"accuracy\"):\n",
    "        summ=0\n",
    "        for d in d_list:\n",
    "            summ=summ+d[\"accuracy\"]\n",
    "        return summ/len(d_list)\n",
    "    else:\n",
    "        for d in d_list:\n",
    "            dict_list.append(d[target])#extract the lines i want\n",
    "        for key in dict_list[0].keys():\n",
    "            mean_dict[key] = sum(d[key] for d in dict_list) / len(dict_list)\n",
    "    return mean_dict\n",
    "\n",
    "def classification_mean(cl_list):\n",
    "    avg_0 =dict_mean(cl_list,target=\"0\")\n",
    "    avg_1 =dict_mean(cl_list,target=\"1\")\n",
    "    avg_accuracy =dict_mean(cl_list,target=\"accuracy\")\n",
    "    avg_macro =dict_mean(cl_list,target=\"macro avg\")\n",
    "    avg_weighted =dict_mean(cl_list,target=\"weighted avg\")\n",
    "    return { \"0\": avg_0 ,\"1\":avg_1,\"accuracy\":avg_accuracy ,\"macro avg\":avg_macro,\"weighted avg\":avg_weighted }               \n",
    "    \n",
    "\n",
    "#https://www.machinelearningplus.com/deep-learning/linear-regression-tensorflow/\n",
    "###############################################################################\n",
    "################# partie linear regression ####################################\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def lin_reg_bootstrap(panda_data_set,nb_iter=1000):\n",
    "    columns_list = panda_data_set.columns.tolist()\n",
    "    x_train=NormalizeData(panda_data_set[columns_list[0]].to_numpy())\n",
    "    y_train=NormalizeData(panda_data_set[columns_list[1]].to_numpy())\n",
    "    data_set_size=len(x_train)\n",
    "    m=0\n",
    "    b=0\n",
    "    counter=0\n",
    "    for i in range(nb_iter):\n",
    "        p1=random.randint(0, data_set_size-1)\n",
    "        p2=random.randint(0, data_set_size-1)\n",
    "        \n",
    "        x1=x_train[p1]\n",
    "        y1=y_train[p1]        \n",
    "        x2=x_train[p2]\n",
    "        y2=y_train[p2]\n",
    "        if((x2-x1)!=0):\n",
    "            m_tmp,b_tmp=line_equation_from_two_points(x1,y1,x2,y2)\n",
    "            m=m+m_tmp\n",
    "            b=b+b_tmp\n",
    "        else:\n",
    "            counter=counter+1\n",
    "    m=m/(nb_iter-counter)\n",
    "    b=b/(nb_iter-counter)\n",
    "    return m,b\n",
    "    \n",
    "def linreg(x,weight,bias):#x is a np list\n",
    "    y = weight*x + bias\n",
    "    return y\n",
    "\n",
    "# Define loss function (MSE)\n",
    "def squared_error(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "def not_squared_error(y_pred, y_true):\n",
    "    return tf.reduce_mean(y_pred - y_true)\n",
    "\n",
    "def linear_regresion(panda_data_set,boot_iter=1000):\n",
    "    columns_list = panda_data_set.columns.tolist()\n",
    "    #x_train=panda_data_set[columns_list[0]].to_numpy()\n",
    "    #y_train=panda_data_set[columns_list[1]].to_numpy()\n",
    "    x_train=NormalizeData(panda_data_set[columns_list[0]].to_numpy())\n",
    "    y_train=NormalizeData(panda_data_set[columns_list[1]].to_numpy())\n",
    "    #print(\"x_train max =\",np.amax(x_train, axis=0))\n",
    "    #print(\"y_train max =\",np.amax(y_train, axis=0))\n",
    "    learning_rate = 0.01\n",
    "    # Number of loops for training through all your data to update the parameters\n",
    "    training_epochs = 100\n",
    "    \n",
    "    boot_weight,boot_bias=lin_reg_bootstrap(panda_data_set,nb_iter=boot_iter)\n",
    "    weight = tf.Variable(boot_weight)\n",
    "    bias   = tf.Variable(boot_bias)\n",
    "    #weight = tf.Variable(0.)\n",
    "    #bias   = tf.Variable(0.)\n",
    "    \n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Compute loss within Gradient Tape context\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_predicted = linreg(x_train,weight,bias)\n",
    "            #loss = squared_error(y_predicted, y_train)\n",
    "            loss = not_squared_error(y_predicted, y_train)\n",
    "            # Get gradients\n",
    "            gradients = tape.gradient(loss, [weight,bias])\n",
    "\n",
    "            # Adjust weights\n",
    "            weight.assign_sub(gradients[0]*learning_rate)\n",
    "            bias.assign_sub(gradients[1]*learning_rate)\n",
    "\n",
    "    \n",
    "    \n",
    "    return weight.numpy(),bias.numpy()\n",
    "\n",
    "print(\"fonctions declaré a :\",time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb9e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67ec17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['merchant', 'category', 'amt', 'gender', 'state', 'zip', 'lat', 'long', 'city_pop', 'dob', 'unix_time', 'merch_lat', 'merch_long', 'delta_time', 'delta_amt', 'delta_time_category', 'delta_amt_category', 'delta_time_merchant', 'delta_amt_merchant', 'avg_amt', 'delta_avg_amt', 'avg_amt_category', 'delta_avg_amt_category', 'avg_amt_merchant', 'avg_amt_state', 'avg_amt_city', 'avg_amt_job', 'delta_avg_amt_category_job', 'month', 'day', 'hour']\n",
      "--- import data_set = 21.45082187652588 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#import le data_set complet --- import data_set = 28.00195622444153 seconds ---\n",
    "start = time.time()\n",
    "\n",
    "data_file= os.path.abspath('data')\n",
    "full_path=data_file+'\\\\'+'fraudTrain.csv'   # unmodified train set\n",
    "train_df=pd.read_csv(full_path)\n",
    "full_path=data_file+'\\\\'+'fraudTest.csv'\n",
    "test_df=pd.read_csv(full_path)\n",
    "\n",
    "\n",
    "\n",
    "full_path=data_file+'\\\\'+'X_train_1_2_svm.csv'\n",
    "xtrain_transformed_complique=pd.read_csv(full_path)\n",
    "ytrain_transformed_complique=train_df['is_fraud'].iloc[:int(len(train_df)*0.8)]\n",
    "\n",
    "full_path=data_file+'\\\\'+'X_val_1_2_svm.csv'\n",
    "xval_transformed_complique=pd.read_csv(full_path)\n",
    "yval_transformed_complique=train_df['is_fraud'].iloc[len(ytrain_transformed_complique):]\n",
    "\n",
    "\n",
    "full_path=data_file+'\\\\'+'X_test_1_2_svm.csv'\n",
    "xtest_transformed_complique=pd.read_csv(full_path)\n",
    "ytest_transformed_complique=test_df['is_fraud']\n",
    "\n",
    "\n",
    "train_df=train_df.drop(columns=['Unnamed: 0'])\n",
    "test_df=test_df.drop(columns=['Unnamed: 0'])\n",
    "xtrain_transformed_complique=xtrain_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "xval_transformed_complique=xval_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "xtest_transformed_complique=xtest_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "cols = xtrain_transformed_complique.columns.tolist()\n",
    "print(cols)\n",
    "print(\"--- import data_set = %s seconds ---\" % (time.time() - start));start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee9f590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "1024\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "dict_378 = create_pair_dict(cols)\n",
    "print (len(dict_378))\n",
    "print(32*32)\n",
    "print(len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b517c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10740133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fbf04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd41fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177000d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af4d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test avec xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "387153d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:15:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1031372\n",
      "           1       0.98      0.83      0.90      5968\n",
      "\n",
      "    accuracy                           1.00   1037340\n",
      "   macro avg       0.99      0.91      0.95   1037340\n",
      "weighted avg       1.00      1.00      1.00   1037340\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=50, gamma=0.05,eta=0.05,max_depth=7, n_jobs=16)\n",
    "\n",
    "xgb.fit(xtrain_transformed_complique,ytrain_transformed_complique)\n",
    "y_train_pred=xgb.predict(xtrain_transformed_complique)\n",
    "y_test_pred=xgb.predict(xtest_transformed_complique)\n",
    "print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "print(classification_report(ytest_transformed_complique,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f38d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_xgboost=classification_report(ytest_transformed_complique,y_test_pred,output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30eed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0daa2a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RandomForest sans ajout = 218.59841108322144 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "max_depth = 15\n",
    "rf = RandomForestClassifier(random_state=0, max_depth=max_depth, min_samples_leaf= 3, min_samples_split= 2, n_estimators= 140, verbose=1, n_jobs=16)\n",
    "rf.fit(xtrain_transformed_complique, ytrain_transformed_complique)\n",
    "# Prediction for the training/validation set\n",
    "y_train_pred = rf.predict(xtrain_transformed_complique)\n",
    "y_test_pred = rf.predict(xtest_transformed_complique)\n",
    "\n",
    "print(\"---RandomForest sans ajout = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97ce98da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1031372\n",
      "           1       1.00      0.83      0.91      5968\n",
      "\n",
      "    accuracy                           1.00   1037340\n",
      "   macro avg       1.00      0.92      0.95   1037340\n",
      "weighted avg       1.00      1.00      1.00   1037340\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.73      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.87      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "\n",
    "cl_rf=classification_report(ytest_transformed_complique,y_test_pred,output_dict=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2791ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4168d9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.76      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.80      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.90      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.81      0.82      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.91      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.79      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.79      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.89      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.71      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.85      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.71      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.85      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.81      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.91      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.98      0.70      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.85      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.66      0.78      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.83      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.84      0.83      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.92      0.92      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.76      0.86      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.88      0.93      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.78      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.89      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.82      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.91      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9316091954022988  f1-score: 0.8344916344916344\n",
      "---NN sans ajout = 1954.8949990272522 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# manual f1 score \n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "#trouve le meilleur dict\n",
    "def find_best_dict(dict_list):\n",
    "    threshold=0.92\n",
    "    while(threshold>0.50):\n",
    "        tmp_list=list()\n",
    "        for di in dict_list:\n",
    "            precision=(di[\"1\"][\"precision\"])\n",
    "            if(precision>threshold):\n",
    "                tmp_list.append(di)\n",
    "        if(tmp_list):\n",
    "            newlist = sorted(tmp_list, key=lambda d: d[\"1\"]['f1-score'],reverse=True)\n",
    "            print(\"choosen model precision: %.4f\" %newlist[0][\"1\"][\"precision\"],\" f1-score: %.4f\" %newlist[0][\"1\"]['f1-score'])\n",
    "            return newlist[0]\n",
    "        threshold=threshold-0.04\n",
    "    print(\"nothing good was found\")\n",
    "    return_value=sorted(dict_list, key=lambda d: d[\"1\"]['f1-score'],reverse=True)\n",
    "    return return_value[0]\n",
    "\n",
    "\n",
    "def fixed_nn_exec_time(xtrain_transformed_complique,ytrain_transformed_complique ,\n",
    "                        xtest_transformed_complique,ytest_transformed_complique ,\n",
    "                        tmps_exec=30,max_iter=1000):\n",
    "    start_function = time.time()\n",
    "    results=[]\n",
    "    curent_iter=0\n",
    "    while((tmps_exec*60)>(time.time() - start_function)):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_shape=(len(xtrain_transformed_complique.columns),),\n",
    "                        activation='relu')),\n",
    "        model.add(BatchNormalization()),\n",
    "        model.add(Dense(16, activation='relu')),\n",
    "        model.add(Dense(8, activation='relu')),\n",
    "        model.add(Dropout(0.2)),\n",
    "        model.add(Dense(4, activation='relu')),\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.001) #optimizer\n",
    "        los=tf.keras.losses.BinaryCrossentropy()\n",
    "        model.compile(optimizer=opt, loss=\"binary_crossentropy\", \n",
    "                      metrics=[tf.keras.metrics.Precision(),\"accuracy\",f1])\n",
    "\n",
    "        history= model.fit(xtrain_transformed_complique, ytrain_transformed_complique\n",
    "                           ,epochs = 10, batch_size=128, verbose = 0)\n",
    "        history_dictict = history.history\n",
    "        y_test_pred =(model.predict(xtest_transformed_complique) >0.5).astype(\"int32\")\n",
    "        print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "\n",
    "        cl_nn=classification_report(ytest_transformed_complique,y_test_pred\n",
    "                                    ,output_dict=True)\n",
    "        results.append(cl_nn)\n",
    "\n",
    "        curent_iter=curent_iter+1\n",
    "        if curent_iter > max_iter:\n",
    "            find_best_dict(results)\n",
    "        \n",
    "    return find_best_dict(results)\n",
    "    \n",
    "def deprecated_nn():\n",
    "    #metrics=[\"accuracy\",f1]\n",
    "    start = time.time()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(len(xtrain_transformed_complique.columns),),\n",
    "                    activation='relu')),\n",
    "    model.add(BatchNormalization()),\n",
    "    model.add(Dense(16, activation='relu')),\n",
    "    model.add(Dense(8, activation='relu')),\n",
    "    model.add(Dropout(0.2)),\n",
    "    model.add(Dense(4, activation='relu')),\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001) #optimizer\n",
    "    los=tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", \n",
    "                  metrics=[\"accuracy\",f1])\n",
    "\n",
    "\n",
    "    history= model.fit(xtrain_transformed_complique, ytrain_transformed_complique\n",
    "                       ,epochs = 10, batch_size=128, verbose = 0)\n",
    "                       #,class_weight=weight)#didnt work\n",
    "    history_dictict = history.history\n",
    "    #sigmoid return values from 0 to 1 , not exactly 0 and 1\n",
    "    y_train_pred=(model.predict(xtrain_transformed_complique)>0.5).astype(\"int32\")\n",
    "    y_test_pred =(model.predict(xtest_transformed_complique) >0.5).astype(\"int32\")\n",
    "\n",
    "    print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "    print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "\n",
    "    cl_nn=classification_report(ytest_transformed_complique,y_test_pred\n",
    "                                ,output_dict=True)\n",
    "\n",
    "###################################################################################    \n",
    "    \n",
    "    \n",
    "cl_nn=fixed_nn_exec_time(xtrain_transformed_complique,ytrain_transformed_complique ,\n",
    "                        xtest_transformed_complique,ytest_transformed_complique ,\n",
    "                        tmps_exec=30,max_iter=1000)\n",
    "#print(cl_nn)\n",
    "\n",
    "print(\"---NN sans ajout = %s seconds ---\" % (time.time() - start));start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9414d718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8537b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504672f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc071d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- svm fit = 2569.516764640808 seconds ---\n",
      "---SVM y_test_pred = 561.9156672954559 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.91      0.66      0.76      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.83      0.88    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "start = time.time()\n",
    "svm_model = svm.SVC(kernel=\"rbf\", gamma = 0.02, C=10)#, max_iter=100000)\n",
    "svm_model.fit(xtrain_transformed_complique,ytrain_transformed_complique)\n",
    "print(\"--- svm fit = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "y_test_pred=svm_model.predict(xtest_transformed_complique)\n",
    "print(\"---SVM y_test_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "#y_train_pred=svm_model.predict(xtrain_transformed_complique)\n",
    "#print(\"---svm y_train_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "#print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "#cl=classification_report(ytest_transformed_complique,Y_test_pred,output_dict=True)\n",
    "\n",
    "\n",
    "cl_svm=classification_report(ytest_transformed_complique,y_test_pred\n",
    "                            ,output_dict=True)\n",
    "print(\"--------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a30f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b378ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d4de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bcb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b46ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### big exec ###########################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "631bc71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut du treshold  0.5\n",
      "---loading data = 0.4466593265533447 seconds ---\n",
      "xgboost start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:45:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.79      0.86      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.89      0.93    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---XGboost = 102.99252319335938 seconds ---\n",
      "rf start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 140 out of 140 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.73      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.99      0.86      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---RandomForest = 283.6531205177307 seconds ---\n",
      "start nn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.89      0.78      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.89      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.81      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.90      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.86      0.84      0.85      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.92      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.75      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.97      0.59      0.73      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.80      0.87    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.58      0.77      0.66      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.79      0.88      0.83    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.74      0.81      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.87      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.88      0.77      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.94      0.88      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.83      0.77      0.79      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.91      0.88      0.90    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.62      0.77      0.69      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.81      0.89      0.84    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.58      0.80      0.67      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.79      0.90      0.83    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.86      0.72      0.78      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.86      0.89    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.93      0.74      0.82      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.96      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.94      0.76      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.97      0.88      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.87      0.82      0.84      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.93      0.91      0.92    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision: 0.9421965317919075  f1-score: 0.8412903225806452\n",
      "---neural network = 1854.2095746994019 seconds ---\n",
      "svm start\n",
      "--- svm fit = 4342.53173327446 seconds ---\n",
      "---SVM y_test_pred = 661.0518689155579 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.61      0.73      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.80      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "---svm = 5004.910671472549 seconds ---\n",
      "treshold  0.5  terminé a : 13:46:27\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "xgboost_results=[]\n",
    "nn_results=[]\n",
    "rf_results=[]\n",
    "svm_results=[]\n",
    "    to_do_list=[\"max_degree\",\"assortativity\",\"clustering\",\n",
    "            \"global_efficiency\",\"geodesic_dist\",\"Shannon_entropy\"]\n",
    "\n",
    "threshold_list=[0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6]\n",
    "\n",
    "threshold_list=[0.5]\n",
    "\n",
    "for treshold_value in threshold_list:\n",
    "    start = time.time()\n",
    "    print(\"debut du treshold \" ,treshold_value)\n",
    "    \n",
    "    name=\"data/\"+\"train_graph_properties\"+str(treshold_value)+\".npy\"\n",
    "    loaded_np=np.load(name)\n",
    "    df_addon = pd.DataFrame(loaded_np, columns = to_do_list)\n",
    "    X_train_plus_graph_df=pd.concat([xtrain_transformed_complique,df_addon],axis=1)\n",
    "    X_train_plus_graph =np.concatenate((xtrain_transformed_complique,loaded_np),axis=1)\n",
    "\n",
    "\n",
    "    name=\"data/\"+\"val_graph_properties\"+str(treshold_value)+\".npy\"\n",
    "    loaded_np=np.load(name)\n",
    "    df_addon = pd.DataFrame(loaded_np, columns = to_do_list)\n",
    "    X_val_plus_graph_df=pd.concat([xval_transformed_complique,df_addon],axis=1)\n",
    "    X_val_plus_graph =np.concatenate((xval_transformed_complique,loaded_np),axis=1)\n",
    "\n",
    "    name=\"data/\"+\"test_graph_properties\"+str(treshold_value)+\".npy\"\n",
    "    loaded_np=np.load(name)\n",
    "    df_addon = pd.DataFrame(loaded_np, columns = to_do_list)\n",
    "    X_test_plus_graph_df=pd.concat([xtest_transformed_complique,df_addon],axis=1)\n",
    "    X_test_plus_graph =np.concatenate((xtest_transformed_complique,loaded_np),axis=1)\n",
    "    \n",
    "    \n",
    "    print(\"---loading data = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    #################### loading data finished \n",
    "    \n",
    "    \n",
    "    print(\"xgboost start\")\n",
    "    xgb = XGBClassifier(n_estimators=50, gamma=0.05,eta=0.05,max_depth=7, n_jobs=16)\n",
    "    xgb.fit(X_train_plus_graph,ytrain_transformed_complique)\n",
    "    #Y_train_pred_graph=xgb.predict(X_train_plus_graph)\n",
    "    Y_test_pred_graph=xgb.predict(X_test_plus_graph)\n",
    "    #print(classification_report(ytrain_transformed_complique,Y_train_pred_graph))\n",
    "    print(classification_report(ytest_transformed_complique,Y_test_pred_graph))\n",
    "    xgboost_results.append(classification_report(ytest_transformed_complique,Y_test_pred_graph,output_dict=True))\n",
    "    print(\"---XGboost = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    \n",
    "    print(\"rf start\")\n",
    "    max_depth = 15\n",
    "    rf = RandomForestClassifier(random_state=0, max_depth=max_depth, min_samples_leaf= 3, min_samples_split= 2, n_estimators= 140, verbose=1, n_jobs=16)\n",
    "    rf.fit(X_train_plus_graph, ytrain_transformed_complique)\n",
    "    # Prediction for the training/validation set\n",
    "    #Y_train_pred_graph = rf.predict(X_train_plus_graph)\n",
    "    Y_test_pred_graph= rf.predict(X_test_plus_graph)\n",
    "    print(classification_report(ytest_transformed_complique,Y_test_pred_graph))\n",
    "    rf_results.append(classification_report(ytest_transformed_complique,Y_test_pred_graph,output_dict=True))\n",
    "    print(\"---RandomForest = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "\n",
    "\n",
    "    print(\"start nn\") \n",
    "    nn_res=fixed_nn_exec_time(X_train_plus_graph_df,ytrain_transformed_complique ,\n",
    "                        X_test_plus_graph_df,ytest_transformed_complique ,\n",
    "                        tmps_exec=30)\n",
    "    nn_results.append(nn_res)\n",
    "    print(\"---neural network = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    \n",
    "    \n",
    "    print(\"svm start\")\n",
    "    start_svm = time.time()\n",
    "    svm_model = svm.SVC(kernel=\"rbf\", gamma = 0.02, C=10)#, max_iter=100000)\n",
    "    svm_model.fit(X_train_plus_graph,ytrain_transformed_complique)\n",
    "    print(\"--- svm fit = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    Y_test_pred_graph=svm_model.predict(X_test_plus_graph)\n",
    "    print(\"---SVM y_test_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    #y_train_pred=svm_model.predict(xtrain_transformed_complique)\n",
    "    #print(\"---svm y_train_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    #print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "    print(classification_report(ytest_transformed_complique,Y_test_pred_graph))\n",
    "    svm_results.append(classification_report(ytest_transformed_complique,Y_test_pred_graph,output_dict=True))\n",
    "    \n",
    "    print(\"---svm = %s seconds ---\" % (time.time() - start_svm));start = time.time()\n",
    "    \n",
    "\n",
    "    print(\"treshold \" ,treshold_value,\" terminé a :\",time.strftime(\"%H:%M:%S\", time.localtime()))\n",
    "    print(\"-----------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b197c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SVM y_test_pred = 647.8901529312134 seconds ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.90      0.61      0.73      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.95      0.80      0.86    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred_graph=svm_model.predict(X_test_plus_graph)\n",
    "print(\"---SVM y_test_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "#y_train_pred=svm_model.predict(xtrain_transformed_complique)\n",
    "#print(\"---svm y_train_pred = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "#print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "print(classification_report(ytest_transformed_complique,Y_test_pred_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6b1c7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average recall  \u001b[91mloss \u001b[0m -0.0009\n",
      "average f1 score   \u001b[91mloss \u001b[0m -0.0030\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average recall  \u001b[91mloss \u001b[0m -0.0051\n",
      "average f1 score   \u001b[91mloss \u001b[0m -0.0039\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbDUlEQVR4nO3dfXBV9b3v8fenAZoWH0CIrQewyT2Tc4bghAd3MbSCRWsF6kDtlaPMbS32OCm1aG2vt9XrTOvUOtP6VOTUwnAVldEjtT3FYg890qptfRiU0IscEK1R8RBJEeGWByny4Pf+sZc0xmRnhb2TTVif18westb6fff+faOzP1lr7b2WIgIzM8ueD5R7AmZmVh4OADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRjkAzMwyygFgZpZRDgCzbpC0SdLVktZJ2inpp5IqJX1KUouk/ynpDUmtki4t93zNCnEAmHXfPwFTgBqgHpidrP8ocCIwDPhn4A5Jg8sxQbM0HABm3Tc/IrZExA7gYWBMsv4A8L2IOBARK4A9wD+WaY5mXXIAmHXfn9v8vBc4Lvl5e0Qc7GSb2VHHAWBmllEOADOzjHIAmJlllHxDGDOzbPIegJlZRjkAzMwyygFgZpZRDgAzs4zqV+4JdMfQoUOjurq63NMwM+tT1qxZ82ZEVLVfnyoAJE0BbgcqgDsj4gfttivZPo38tx9nR8QfC9VK+il/+5r8IOAvETGm0Dyqq6tpampKM2UzM0tIeq2j9V0GgKQK4A7gXKAFWC1peUQ832bYVKA2eZwBLADOKFQbERe1eY1bgZ1H1JmZmR2RNOcAxgPNEfFKROwHlgIz2o2ZASyJvFXAIEmnpKlN9h7+CXigyF7MzKwb0gTAMGBzm+WWZF2aMWlqJwJbI+Kljl5cUqOkJklN27ZtSzFdMzNLI805AHWwrv3Xhzsbk6Z2FgX++o+IRcAigFwu568tm/UxBw4coKWlhX379pV7Kse8yspKhg8fTv/+/VONTxMALcCINsvDgS0pxwwoVCupH/B54PRUszWzPqelpYXjjz+e6upq8kd8rSdEBNu3b6elpYWamppUNWkOAa0GaiXVSBoAXAwsbzdmOXCJ8hqAnRHRmqL208ALEdGSarZm1ufs27ePIUOG+M2/h0liyJAh3drT6nIPICIOSpoLPEL+o5yLI2KDpDnJ9oXACvIfAW0m/zHQSwvVtnn6i/HJX7Njnt/8e0d3f8+pvgeQ3N5uRbt1C9v8HMDX0ta22TY77UTNzKy0fCkIMzvmVVRUMGbMmMOPTZs2sX37diZPnsxxxx3H3Llzyz3FsuhTl4IwMzsSH/rQh1i7du171r311lvccMMNrF+/nvXr1/fKPCKCiOADHzg6/vY+OmZhZtbLBg4cyJlnnkllZWXBcddccw11dXXU19dz9dVXA7B161YuuOACRo8ezejRo3n66acBuO222zjttNM47bTTmDdvHgCbNm1i5MiRXH755YwbN47Nmzdz88038/GPf5z6+nq++93v9mifhXgPwMx6zVX/cRVr/7y2pM855qNjmDdlXsExf/3rXxkzZgwANTU1LFu2LNVz79ixg2XLlvHCCy8gib/85S8AXHnllZx11lksW7aMQ4cOsWfPHtasWcPdd9/NM888Q0RwxhlncNZZZzF48GBefPFF7r77bn7yk5+wcuVKXnrpJZ599lkigunTp/OHP/yBSZMmFfFbODIOADM75nV0CCiNE044gcrKSi677DI++9nPcv755wPw2GOPsWTJEiB/fuHEE0/kySef5IILLmDgwIEAfP7zn+eJJ55g+vTpfOxjH6OhoQGAlStXsnLlSsaOHQvAnj17eOmllxwAZnZs6+ov9aNNv379ePbZZ3n00UdZunQpP/7xj3nsscc6HFvo/urvhsK746699lq+8pWvlHy+3eVzAGZmndizZw87d+5k2rRpzJs37/BexDnnnMOCBQsAOHToELt27WLSpEk89NBD7N27l7feeotly5YxceLE9z3neeedx+LFi9mzZw8Ar7/+Om+88Uav9dSW9wDMLLOqq6vZtWsX+/fv56GHHmLlypXU1dUd3r57925mzJjBvn37iAh+9KMfAXD77bfT2NjIXXfdRUVFBQsWLGDChAnMnj2b8ePHA3DZZZcxduxYNm3a9J7X/MxnPsPGjRuZMGECAMcddxz33XcfJ598cu803YYK7bYcbXK5XPiGMGZ9y8aNGxk5cmS5p5EZHf2+Ja2JiFz7sT4EZGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmdkRuOeeew5fRvr666/nlltuKfOMus8BYGaZEhG888475Z7GUcEBYGbHvPaXZL7hhhs6vBzzkiVLqK+vZ/To0Xzxi18E4OGHH+aMM85g7NixfPrTn2br1q3laqPkfCkIM+s1G3/zLXa/sa6kz3n8yfWMPPemLse9e0nmz33uc/z85z9/3+WYhwwZwo033shTTz3F0KFD2bFjBwBnnnkmq1atQhJ33nknN910E7feemtJeygXB4CZZcK7l2S++uqrO7wc83PPPceFF17I0KFDATjppJMAaGlp4aKLLqK1tZX9+/dTU1NTth5KLVUASJoC3A5UAHdGxA/abVeyfRqwF5gdEX/sqlbSFcBc4CDw7xHxraI7MrOjVpq/1HvKu5dk7uxyzPPnzyf/VvZeV1xxBd/85jeZPn06v/vd77j++ut7Y7q9ostzAJIqgDuAqUAdMEtSXbthU4Ha5NEILOiqVtJkYAZQHxGjgL53Ct3M+pzOLsd8zjnn8OCDD7J9+3aAw4eAdu7cybBhwwC49957yzPpHpJmD2A80BwRrwBIWkr+jfv5NmNmAEsif2nRVZIGSToFqC5Q+1XgBxHxNkBElOeC2GaWKZ1djnnUqFFcd911nHXWWVRUVDB27Fjuuecerr/+embOnMmwYcNoaGjg1VdfLXMHpdPl5aAlXQhMiYjLkuUvAmdExNw2Y35F/s38yWT5UeDb5AOgw1pJa4FfAlOAfcDVEbG6g9dvJL9Xwamnnnr6a6+9VlTDZta7fDno3lXqy0G//6AYtE+NzsYUqu0HDAYagP8FPKgODsBFxKKIyEVErqqqKsV0zcwsjTSHgFqAEW2WhwNbUo4ZUKC2BfhFctjoWUnvAEOBbalnb2ZmRyzNHsBqoFZSjaQBwMXA8nZjlgOXKK8B2BkRrV3UPgScDSDpH8iHxZvFNmRmZul0uQcQEQclzQUeIf9RzsURsUHSnGT7QmAF+Y+ANpP/GOilhWqTp14MLJa0HtgPfCn60v0pzcz6uFTfA4iIFeTf5NuuW9jm5wC+lrY2Wb8f+EJ3JmtmZqXjawGZmWWUA8DMrBPz5s1j7969RT1HT1wqulTP6QAwM+vEkQTAoUOHemg2pecAMLNj2k033cT8+fMB+MY3vsHZZ58NwKOPPsoXvpA/DfnVr36VXC7HqFGjDl8eev78+WzZsoXJkyczefJkAFauXMmECRMYN24cM2fOPHw5ierqar73ve9x5pln8rOf/azTubz88stMmTKF008/nYkTJ/LCCy+wc+dOqqurD9+jYO/evYwYMYIDBw50OL6UfDVQM+s1V10Fa9eW9jnHjIF58zrfPmnSJG699VauvPJKmpqaePvttzlw4ABPPvkkEydOBODGG2/kpJNO4tChQ5xzzjmsW7eOK6+8kttuu43HH3+coUOH8uabb/L973+f3/72twwcOJAf/vCH3HbbbXznO98BoLKykieffLLgXBsbG1m4cCG1tbU888wzXH755Tz22GOMHj2a3//+90yePJmHH36Y8847j/79+3c6vlQcAGZ2TDv99NNZs2YNu3fv5oMf/CDjxo2jqamJJ5544vCewYMPPsiiRYs4ePAgra2tPP/889TX17/neVatWsXzzz/PJz/5SQD2799/+HpCABdddFHBeezZs4enn36amTNnHl739ttvH6796U9/yuTJk1m6dCmXX355wfGl4gAws15T6C/1ntK/f3+qq6u5++67+cQnPkF9fT2PP/44L7/8MiNHjuTVV1/llltuYfXq1QwePJjZs2ezb9++9z1PRHDuuefywAMPdPg6715uujPvvPMOgwYNYm0Hu0DTp0/n2muvZceOHaxZs4azzz6bt956q9PxpeJzAGZ2zJs0aRK33HILkyZNYuLEiSxcuJAxY8YgiV27djFw4EBOPPFEtm7dyq9//evDdccffzy7d+8GoKGhgaeeeorm5mYgf6z+T3/6U+o5nHDCCdTU1Bw+RxARPPfcc0D+iqTjx4/n61//Oueffz4VFRUFx5eKA8DMjnkTJ06ktbWVCRMm8JGPfITKysrDx/9Hjx7N2LFjGTVqFF/+8pcPH+KB/DH7qVOnMnnyZKqqqrjnnnuYNWsW9fX1NDQ0dPuk7P33389dd93F6NGjGTVqFL/85S8Pb7vooou477773nMoqdD4UujyctBHk1wuF01NTeWehpl1gy8H3btKfTloMzM7BjkAzMwyygFgZj2uLx1q7su6+3t2AJhZj6qsrGT79u0OgR4WEWzfvp3KysrUNf4egJn1qOHDh9PS0sK2bb7ZX0+rrKxk+PDhqcc7AMysR/Xv35+amppyT8M64ENAZmYZ5QAwM8soB4CZWUY5AMzMMipVAEiaIulFSc2SrulguyTNT7avkzSuq1pJ10t6XdLa5DGtNC2ZmVkaXQaApArgDmAqUAfMklTXbthUoDZ5NAILUtb+KCLGJI8VxTZjZmbppdkDGA80R8QrEbEfWArMaDdmBrAk8lYBgySdkrLWzMzKIE0ADAM2t1luSdalGdNV7dzkkNFiSYNTz9rMzIqWJgDUwbr23+nubEyh2gXA3wNjgFbg1g5fXGqU1CSpyd8kNDMrnTQB0AKMaLM8HNiSckyntRGxNSIORcQ7wP8hf7jofSJiUUTkIiJXVVWVYrpmZpZGmgBYDdRKqpE0ALgYWN5uzHLgkuTTQA3AzohoLVSbnCN41wXA+iJ7MTOzbujyWkARcVDSXOARoAJYHBEbJM1Jti8EVgDTgGZgL3BpodrkqW+SNIb8IaFNwFdK2JeZmXXBt4Q0MzvG+ZaQZmb2Hg4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRjkAzMwyygFgZpZRDgAzs4xyAJiZZZQDwMwso1IFgKQpkl6U1Czpmg62S9L8ZPs6SeO6UXu1pJA0tLhWzMysO7oMAEkVwB3AVKAOmCWprt2wqUBt8mgEFqSplTQCOBf4r6I7MTOzbkmzBzAeaI6IVyJiP7AUmNFuzAxgSeStAgZJOiVF7Y+AbwFRbCNmZtY9aQJgGLC5zXJLsi7NmE5rJU0HXo+I57o5ZzMzK4F+Kcaog3Xt/2LvbEyH6yV9GLgO+EyXLy41kj+sxKmnntrVcDMzSynNHkALMKLN8nBgS8oxna3/e6AGeE7SpmT9HyV9tP2LR8SiiMhFRK6qqirFdM3MLI00AbAaqJVUI2kAcDGwvN2Y5cAlyaeBGoCdEdHaWW1E/GdEnBwR1RFRTT4oxkXEn0vVmJmZFdblIaCIOChpLvAIUAEsjogNkuYk2xcCK4BpQDOwF7i0UG2PdGJmZt2iiL7zAZxcLhdNTU3lnoaZWZ8iaU1E5Nqv9zeBzcwyygFgZpZRDgAzs4xyAJiZZZQDwMwsoxwAZmYZ5QAwM8soB4CZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjUgWApCmSXpTULOmaDrZL0vxk+zpJ47qqlXRDMnatpJWS/q40LZmZWRpdBoCkCuAOYCpQB8ySVNdu2FSgNnk0AgtS1N4cEfURMQb4FfCdorsxM7PU0uwBjAeaI+KViNgPLAVmtBszA1gSeauAQZJOKVQbEbva1A8EoshezMysG9IEwDBgc5vllmRdmjEFayXdKGkz8D/oZA9AUqOkJklN27ZtSzFdMzNLI00AqIN17f9a72xMwdqIuC4iRgD3A3M7evGIWBQRuYjIVVVVpZiumZmlkSYAWoARbZaHA1tSjklTC/CvwH9PMRczMyuRNAGwGqiVVCNpAHAxsLzdmOXAJcmngRqAnRHRWqhWUm2b+unAC0X2YmZm3dCvqwERcVDSXOARoAJYHBEbJM1Jti8EVgDTgGZgL3BpodrkqX8g6R+Bd4DXgDkl7czMzApSRN/58E0ul4umpqZyT8PMrE+RtCYicu3X+5vAZmYZ5QAwM8soB4CZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRjkAzMwyKlUASJoi6UVJzZKu6WC7JM1Ptq+TNK6rWkk3S3ohGb9M0qCSdGRmZql0GQCSKoA7gKlAHTBLUl27YVOB2uTRCCxIUfsb4LSIqAf+BFxbdDdmZpZamj2A8UBzRLwSEfuBpcCMdmNmAEsibxUwSNIphWojYmVEHEzqVwHDS9CPmZmllCYAhgGb2yy3JOvSjElTC/Bl4NcdvbikRklNkpq2bduWYrpmZpZGmgBQB+si5ZguayVdBxwE7u/oxSNiUUTkIiJXVVWVYrpmZpZGvxRjWoARbZaHA1tSjhlQqFbSl4DzgXMion2omJlZD0qzB7AaqJVUI2kAcDGwvN2Y5cAlyaeBGoCdEdFaqFbSFODbwPSI2FuifszMLKUu9wAi4qCkucAjQAWwOCI2SJqTbF8IrACmAc3AXuDSQrXJU/8Y+CDwG0kAqyJiTimbMzOzzqkvHXnJ5XLR1NRU7mmYmfUpktZERK79en8T2MwsoxwAZmYZ5QAwM8soB4CZWUY5AMzMMsoBYGaWUQ4AM7OMcgCYmWWUA8DMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRqUKAElTJL0oqVnSNR1sl6T5yfZ1ksZ1VStppqQNkt6R9L6bFZuZWc/qMgAkVQB3AFOBOmCWpLp2w6YCtcmjEViQonY98HngD8W3YWZm3ZVmD2A80BwRr0TEfmApMKPdmBnAkshbBQySdEqh2ojYGBEvlqwTMzPrljQBMAzY3Ga5JVmXZkya2oIkNUpqktS0bdu27pSamVkBaQJAHayLlGPS1BYUEYsiIhcRuaqqqu6UmplZAf1SjGkBRrRZHg5sSTlmQIpaMzMrgzR7AKuBWkk1kgYAFwPL241ZDlySfBqoAdgZEa0pa83MrAy63AOIiIOS5gKPABXA4ojYIGlOsn0hsAKYBjQDe4FLC9UCSLoA+BegCvh3SWsj4rxSN2hmZh1TRLcOyZdVLpeLpqamck/DzKxPkbQmIt73fSt/E9jMLKMcAGZmGeUAMDPLKAeAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhnlADAzyygHgJlZRjkAzMwyygFgZpZRDgAzs4xyAJiZZZQDwMwsoxwAZmYZ5QAwM8soB4CZWUalCgBJUyS9KKlZ0jUdbJek+cn2dZLGdVUr6SRJv5H0UvLv4NK0ZGZmaXQZAJIqgDuAqUAdMEtSXbthU4Ha5NEILEhRew3waETUAo8my2Zm1kvS7AGMB5oj4pWI2A8sBWa0GzMDWBJ5q4BBkk7ponYGcG/y873A54prxczMuiNNAAwDNrdZbknWpRlTqPYjEdEKkPx7ckcvLqlRUpOkpm3btqWYrpmZpZEmANTBukg5Jk1tQRGxKCJyEZGrqqrqTqmZmRWQJgBagBFtlocDW1KOKVS7NTlMRPLvG+mnbWZmxUoTAKuBWkk1kgYAFwPL241ZDlySfBqoAdiZHNYpVLsc+FLy85eAXxbZi5mZdUO/rgZExEFJc4FHgApgcURskDQn2b4QWAFMA5qBvcClhWqTp/4B8KCkfwb+C5hZ0s7MzKwgRXTrkHxZ5XK5aGpqKvc0zMz6FElrIiLXfr2/CWxmllEOADOzjHIAmJlllAPAzCyj+tRJYEnbgNfKPY8jMBR4s9yT6EVZ6xfcc1b01Z4/FhHv+yZtnwqAvkpSU0dn4I9VWesX3HNWHGs9+xCQmVlGOQDMzDLKAdA7FpV7Ar0sa/2Ce86KY6pnnwMwM8so7wGYmWWUA8DMLKMcAEXo7Ib3HYz7uKRDki5ss+4bkjZIWi/pAUmVvTPr4hTZ89eTfjdIuqpXJlwCXfUs6VOSdkpamzy+k7b2aFVkz4slvSFpfe/OujhH2rOkEZIel7Qx+X/7670/+yMUEX4cwYP85a1fBv4bMAB4DqjrZNxj5C+ZfWGybhjwKvChZPlBYHa5e+rhnk8D1gMfJn8Z8t8CteXuqRQ9A58CfnWkv6+j7VFMz8m2ScA4YH25e+ml/86nAOOSn48H/tQX/jtHhPcAilDohvdtXQH8G++/41k/4EOS+pF/U2x/l7WjUTE9jwRWRcTeiDgI/B64oKcnXAJpey51bTkVNe+I+AOwo6cm10OOuOeIaI2IPyY/7wY28v77ph+VHABHrtAN7wGQNIz8m9zCtusj4nXgFvI3wmklfwe1lT0629I44p7J//U/SdIQSR8mfwOhERz9uuw5MUHSc5J+LWlUN2uPNsX03FeVpGdJ1cBY4JkemWWJOQCOXJob3s8Dvh0Rh95TKA0m/9dFDfB3wEBJX+iJSZbYEfccERuBHwK/Af6D/C72wR6YY6ml6fmP5K+1Mhr4F+ChbtQejYrpua8qumdJx5Hf870qInb1xCRLzQFw5Ard8P5dOWCppE3AhcBPJH0O+DTwakRsi4gDwC+AT/T4jItXTM9ExF0RMS4iJpE/RPBSj8+4eF32HBG7ImJP8vMKoL+koWlqj1LF9NxXFdWzpP7k3/zvj4hf9M6US6DcJyH66oP8MfxXyP8V/+5Jo1EFxt/D306IngFsIH/sX8C9wBXl7qkne06WT07+PRV4ARhc7p5K0TPwUf72pcrx5A/tqbu/r6PlUUzPbbZX07dOAhfz31nAEmBeufvo7qPLm8Jbx6KTG95LmpNsb38MvG3tM5J+Tn6X8iDwf+kDXzEvpufEv0kaAhwAvhYR/69nZ1y8lD1fCHxV0kHgr8DFkX+X6LC2LI10Q5E9I+kB8p+YGSqpBfhuRNxVhlZSK6ZnSWcCXwT+U9La5Cn/d+T3Eo5qvhSEmVlG+RyAmVlGOQDMzDLKAWBmllEOADOzjHIAmJlllAPAzCyjHABmZhn1/wFYDqVLyQJz9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average recall   \u001b[92mgain \u001b[0m 0.0042\n",
      "average f1 score   \u001b[92mgain \u001b[0m 0.0068\n",
      "----------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average recall  \u001b[91mloss \u001b[0m -0.0476\n",
      "average f1 score   \u001b[91mloss \u001b[0m -0.0371\n"
     ]
    }
   ],
   "source": [
    "xgboost_recalls=[]\n",
    "xgboost_f1=[]\n",
    "for cl2 in xgboost_results:\n",
    "    recall_diff=(cl2[\"1\"][\"recall\"]-cl_xgboost[\"1\"][\"recall\"])\n",
    "    f1_diff=(cl2[\"1\"][\"f1-score\"]-cl_xgboost[\"1\"][\"f1-score\"])\n",
    "    xgboost_recalls.append(recall_diff)\n",
    "    xgboost_f1.append(f1_diff)\n",
    "affiche_simple_graphique(threshold_list,xgboost_recalls,xgboost_f1,\n",
    "                         title=\"xgboost\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "rf_recalls=[]\n",
    "rf_f1=[]\n",
    "for cl2 in rf_results:\n",
    "    recall_diff=(cl2[\"1\"][\"recall\"]-cl_rf[\"1\"][\"recall\"])\n",
    "    f1_diff=(cl2[\"1\"][\"f1-score\"]-cl_rf[\"1\"][\"f1-score\"])\n",
    "    rf_recalls.append(recall_diff)\n",
    "    rf_f1.append(f1_diff)\n",
    "affiche_simple_graphique(threshold_list,rf_recalls,rf_f1,\n",
    "                         title=\"rf\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "nn_recalls=[]\n",
    "nn_f1=[]\n",
    "for cl2 in nn_results:\n",
    "    recall_diff=(cl2[\"1\"][\"recall\"]-cl_nn[\"1\"][\"recall\"])\n",
    "    f1_diff=(cl2[\"1\"][\"f1-score\"]-cl_nn[\"1\"][\"f1-score\"])\n",
    "    nn_recalls.append(recall_diff)\n",
    "    nn_f1.append(f1_diff)\n",
    "affiche_simple_graphique(threshold_list,nn_recalls,nn_f1,\n",
    "                         title=\"nn\")\n",
    "print(\"----------------------------------------------------------\") \n",
    "\n",
    "svm_recalls=[]\n",
    "svm_f1=[]\n",
    "for cl2 in svm_results:\n",
    "    recall_diff=(cl2[\"1\"][\"recall\"]-cl_svm[\"1\"][\"recall\"])\n",
    "    f1_diff=(cl2[\"1\"][\"f1-score\"]-cl_svm[\"1\"][\"f1-score\"])\n",
    "    svm_recalls.append(recall_diff)\n",
    "    svm_f1.append(f1_diff)\n",
    "affiche_simple_graphique(threshold_list,svm_recalls,svm_f1,\n",
    "                         title=\"svm\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc55513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80a17c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- the full program took  = 13306.764427900314 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- the full program took  = %s seconds ---\" % (time.time() - program_start))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dfd230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run awe graph embedding on the small graphs \n",
    "#https://github.com/nd7141/AWE/blob/master/Tutorial.ipynb \n",
    "#awe embedding l=7 , nm_walk =125000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d5d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d4318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c2012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0ed2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
