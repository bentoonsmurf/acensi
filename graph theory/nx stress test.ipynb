{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b325e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "import time\n",
    "from time import process_time\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "############################################## liste des options d'extractions\n",
    "def graph_max_degree(g):\n",
    "    degrees = [val for (node, val) in g.degree()]\n",
    "    maxd=max(degrees)\n",
    "    return maxd\n",
    "def geodesic_dist(graph):\n",
    "    return nx.average_shortest_path_length(graph)\n",
    "\n",
    "#special thanks to Francisco A. Rodrigues, University of SÃ£o Paulo.\n",
    "# http://conteudo.icmc.usp.br/pessoas/francisco\n",
    "def degree_distribution(G):\n",
    "    vk = dict(G.degree())\n",
    "    vk = list(vk.values()) # we get only the degree values\n",
    "    maxk = np.max(vk)\n",
    "    mink = np.min(min)\n",
    "    kvalues= np.arange(0,maxk+1) # possible values of k\n",
    "    Pk = np.zeros(maxk+1) # P(k)\n",
    "    for k in vk:\n",
    "        Pk[k] = Pk[k] + 1\n",
    "    Pk = Pk/sum(Pk) # the sum of the elements of P(k) must to be equal to one\n",
    "    return kvalues,Pk\n",
    "def shannon_entropy(G):\n",
    "    k,Pk = degree_distribution(G)\n",
    "    H = 0\n",
    "    for p in Pk:\n",
    "        if(p > 0):\n",
    "            H = H - p*math.log(p, 2)\n",
    "    return H\n",
    "\n",
    "def contain_meso_scale(graph):\n",
    "    \n",
    "    return False    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_info_from_one_graph(g, to_do_list):\n",
    "    graph_property=np.array([])\n",
    "    calc_result=0\n",
    "    \n",
    "    if(\"max_degree\" in to_do_list):\n",
    "        #print (\" max degree\")\n",
    "        calc_result=graph_max_degree(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"assortativity\" in to_do_list):\n",
    "        calc_result = nx.degree_assortativity_coefficient(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"clustering\" in to_do_list):\n",
    "        calc_result= approximation.average_clustering(g, trials=1000, seed=10)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"global_efficiency\" in to_do_list):\n",
    "        calc_result= nx.global_efficiency(g)\n",
    "        graph_property=np.append(graph_property,calc_result)   \n",
    "    if(\"geodesic_dist\" in to_do_list):\n",
    "        calc_result=geodesic_dist(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"contain_meso_scale\" in to_do_list):#to do\n",
    "        calc_result=contain_meso_scale(g)\n",
    "        graph_property=np.append(graph_property,calc_result)\n",
    "    if(\"Shannon_entropy\" in to_do_list):#to do\n",
    "        calc_result=shannon_entropy(g)\n",
    "        graph_property=np.append(graph_property,calc_result)  \n",
    "    #change this ()\n",
    "    #            ()\n",
    "    #            ()\n",
    "    #      to this ()()()\n",
    "    return np.expand_dims(graph_property,axis=0)\n",
    "\n",
    "\n",
    "to_do_list=[\"max_degree\",\"assortativity\",\"Clustering\",\"global_efficiency\",\"geodesic_dist\",\"Shannon_entropy\"]\n",
    "i_lim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7262cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---graph construction = 69.19966745376587 seconds ---\n",
    "i_lim=100\n",
    "if(False):\n",
    "    liste=list()\n",
    "    i=0\n",
    "    start = time.time()\n",
    "    while i<i_lim:\n",
    "        liste.append (nx.complete_graph(32*32))\n",
    "        i=i+1\n",
    "    print(\"---graph construction = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    "    size=sys.getsizeof(liste)\n",
    "    print(size)\n",
    "    print(sys.getsizeof(nx.complete_graph(32*32)))\n",
    "#donc 48 mo pour 1 milions de graph complet\n",
    "#1000 graph = 480 bytes --- 1M graph = 480 000 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec2aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cdf8554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0625 seconds\n",
      "---graph construction sans rien = 0.06142544746398926 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#---graph construction sans collector =69.46875 seconds ---\n",
    "start = time.time()\n",
    "start_time = process_time() \n",
    "\n",
    "\n",
    "i=0\n",
    "while i<i_lim:\n",
    "    graph =nx.complete_graph(32)\n",
    "    i=i+1\n",
    "    \n",
    "time_graph=process_time()  - start_time\n",
    "time_graph_=time_graph/i_lim\n",
    "print(process_time()  - start_time, \"seconds\");start_time = process_time()\n",
    "print(\"---graph construction sans rien = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d850570c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496 , 32\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(len( graph.edges()),\",\",len( graph.nodes()))\n",
    "print(geodesic_dist(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ddab54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benjamin.marty\\Anaconda3\\lib\\site-packages\\networkx\\algorithms\\assortativity\\correlation.py:282: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (xy * (M - ab)).sum() / np.sqrt(vara * varb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375 seconds\n",
      "---graph extraction sans rien = 0.3683955669403076 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#---graph construction sans collector = 231.296875 seconds ---\n",
    "start = time.time()\n",
    "start_time = process_time() \n",
    "\n",
    "\n",
    "i=0\n",
    "while i<i_lim:\n",
    "    graph =nx.complete_graph(32)\n",
    "    i=i+1\n",
    "    \n",
    "    extract_info_from_one_graph(graph, to_do_list)\n",
    "    #del graph\n",
    "    #gc.collect()\n",
    "time_extract_graph=process_time()  - start_time\n",
    "time_extract_graph_=(time_extract_graph-time_graph)/i_lim\n",
    "print(process_time()  - start_time, \"seconds\");start_time = process_time()\n",
    "print(\"---graph extraction sans rien = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0e2fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.359375 seconds\n",
      "---graph extraction evec del = 0.35570645332336426 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#---graph construction sans collector =225.390625 seconds---\n",
    "\n",
    "i=0\n",
    "while i<i_lim:\n",
    "    graph =nx.complete_graph(32)\n",
    "    i=i+1\n",
    "    extract_info_from_one_graph(graph, to_do_list)\n",
    "    del graph\n",
    "    #gc.collect()\n",
    "time_del=process_time()  - start_time\n",
    "time_del_=(time_del-time_extract_graph)/i_lim\n",
    "print(time_del, \"seconds\");start_time = process_time() \n",
    "print(\"---graph extraction evec del = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "799ecb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.328125 seconds\n",
      "---graph construction avec collector = 2.340461015701294 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#---graph construction avec collector = 228.25 seconds ---\n",
    "\n",
    "i=0\n",
    "while i<i_lim:\n",
    "    graph =nx.complete_graph(32)\n",
    "    i=i+1\n",
    "    extract_info_from_one_graph(graph, to_do_list)\n",
    "    del graph\n",
    "    gc.collect()\n",
    "time_collector=process_time()  - start_time\n",
    "time_collector_=(time_collector-time_extract_graph)/i_lim\n",
    "print(time_collector, \"seconds\");start_time = process_time() \n",
    "print(\"---graph construction avec collector = %s seconds ---\" % (time.time() - start));start = time.time()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84f17f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_graph =  0.078125\n",
      "time_graph_ =  0.00078125\n",
      "time_extract_graph =  0.375\n",
      "time_extract_graph_ =  0.00296875\n",
      "time_del =  0.359375\n",
      "time_del_ =  -0.00015625\n",
      "time_collector =  2.328125\n",
      "time_collector_ =  0.01953125\n"
     ]
    }
   ],
   "source": [
    "print(\"time_graph = \",time_graph)\n",
    "print(\"time_graph_ = \",time_graph_)#0.6946875\n",
    "print(\"time_extract_graph = \",time_extract_graph)\n",
    "print(\"time_extract_graph_ = \",time_extract_graph_)#1.61828125\n",
    "print(\"time_del = \",time_del)\n",
    "print(\"time_del_ = \",time_del_)\n",
    "print(\"time_collector = \",time_collector)\n",
    "print(\"time_collector_ = \",time_collector_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "544a7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-156.25\n",
      "19531.25\n"
     ]
    }
   ],
   "source": [
    "print(1000000*time_del_ )\n",
    "print(1000000*time_collector_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f78cc54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "def prgression_en_temps_reel(liste):\n",
    "    process_bar = progressbar.ProgressBar().start(max_value=len(liste));i=0\n",
    "    monstruous_pair_data_set=np.array([])\n",
    "    for trash in liste:\n",
    "        print(\"the item in the list is :\",trash)\n",
    "        process_bar.update(i);i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d769305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
