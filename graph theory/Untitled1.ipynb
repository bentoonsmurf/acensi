{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ ==\" __error_code__\":# '__main__':\n",
    "\n",
    "    run_n2v = False\n",
    "\n",
    "    # File that contains the edges. Format: source target\n",
    "    # Optionally, you can add weights as third column: source target weight\n",
    "    #edge_f = 'data/karate.edgelist'\n",
    "    edge_f=sous_graph[0].edges()\n",
    "    # Specify whether the edges are directed\n",
    "    isDirected = False\n",
    "\n",
    "    # Load graph\n",
    "\n",
    "    G = sous_graph[0]\n",
    "\n",
    "    models = []\n",
    "    # Load the models you want to run\n",
    "    models.append(GraphFactorization(d=2, max_iter=50000, eta=1 * 10**-4, regu=1.0, data_set='karate'))\n",
    "    #models.append(HOPE(d=4, beta=0.01))\n",
    "    #models.append(LaplacianEigenmaps(d=2))\n",
    "    #models.append(LocallyLinearEmbedding(d=2))\n",
    "\n",
    "    #models.append(SDNE(d=2, beta=5, alpha=1e-5, nu1=1e-6, nu2=1e-6, K=3,n_units=[50, 15,], rho=0.3, n_iter=50, xeta=0.01,n_batch=100,modelfile=['enc_model.json', 'dec_model.json'],weightfile=['enc_weights.hdf5', 'dec_weights.hdf5']))\n",
    "\n",
    "    # For each model, learn the embedding and evaluate on graph reconstruction and visualization\n",
    "    for embedding in models:\n",
    "        print ('Num nodes: %d, num edges: %d' % (G.number_of_nodes(), G.number_of_edges()))\n",
    "        t1 = time.time()\n",
    "        # Learn embedding - accepts a networkx graph or file with edge list\n",
    "        Y, t = embedding.learn_embedding(graph=G, edge_f=None, is_weighted=True, no_python=True)\n",
    "        print (embedding._method_name+':\\n\\tTraining time: %f' % (time() - t1))\n",
    "        # Evaluate on graph reconstruction\n",
    "        MAP, prec_curv, err, err_baseline = gr.evaluateStaticGraphReconstruction(G, embedding, Y, None)\n",
    "        #---------------------------------------------------------------------------------\n",
    "        print((\"\\tMAP: {} \\t preccision curve: {}\\n\\n\\n\\n\"+'-'*100).format(MAP,prec_curv[:5]))\n",
    "        #---------------------------------------------------------------------------------\n",
    "        # Visualize\n",
    "        viz.plot_embedding2D(embedding.get_embedding(), di_graph=G, node_colors=None)\n",
    "        plt.show()\n",
    "        plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compression(G):\n",
    "\n",
    "    if ((np.__version__) != \"1.19.5\"):\n",
    "        !pip install numpy==1.19.5\n",
    "    i=0\n",
    "    #num_frame=len(sous_graph)\n",
    "    model = SDNE(G, hidden_size=[256, 128],)\n",
    "    model.train(batch_size=int(len(G.nodes)), epochs=40, verbose=2)\n",
    "    return model.get_embeddings()\n",
    "\n",
    "def crash_free():\n",
    "    try:\n",
    "        liste=[]\n",
    "        i=0\n",
    "        G = sous_graph[i]\n",
    "        liste.append(compression(G))\n",
    "        i+=1\n",
    "        G = sous_graph[i]\n",
    "        liste.append(compression(G))\n",
    "        i+=1\n",
    "    except ValueError:\n",
    "        print(\"error\")  \n",
    "    \n",
    "\n",
    "def encapsulation(G):\n",
    "    i=0\n",
    "    num_frame=len(sous_graph)\n",
    "    model = DeepWalk(G, walk_length=10, num_walks=80, workers=3)\n",
    "    model.train(window_size=5,iter=3) \n",
    "    return model.get_embeddings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "#!cd GraphEmbedding/\n",
    "#!python setup.py install\n",
    "#!pip install -U gensim\n",
    "#!pip install smart_open[all]\n",
    "\n",
    "def all_embeding(liste,sous_graph):\n",
    "    i=0\n",
    "    num_frame=len(sous_graph)\n",
    "    G = sous_graph[i]\n",
    "    model = DeepWalk(G, walk_length=10, num_walks=80, workers=3)\n",
    "    model.train(window_size=5,iter=3) \n",
    "    liste.append(model.get_embeddings())\n",
    "    i+=1\n",
    "    while (i<num_frame):\n",
    "\n",
    "        # train the model and generate embeddings\n",
    "        G = sous_graph[i]\n",
    "        model = DeepWalk(G, walk_length=10, num_walks=80, workers=3)\n",
    "        model.train(window_size=5,iter=3) \n",
    "        liste.append(model.get_embeddings())\n",
    "        i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e21008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_list(liste):\n",
    "    i=0\n",
    "    while (i<10):\n",
    "        liste.append(i)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dont_execute():\n",
    "    \"\"\"\n",
    "        ''' Sample usage\n",
    "    python run_karate.py -node2vec 1\n",
    "    '''\n",
    "    parser = ArgumentParser(description='Graph Embedding Experiments on Karate Graph')\n",
    "    parser.add_argument('-node2vec', '--node2vec',\n",
    "                        help='whether to run node2vec (default: False)')\n",
    "    args = vars(parser.parse_args())\n",
    "    try:\n",
    "        run_n2v = bool(int(args[\"node2vec\"]))\n",
    "    except:\n",
    "        run_n2v = False\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ed2653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar2\n",
      "  Downloading progressbar2-3.55.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six in c:\\users\\benjamin.marty\\anaconda3\\lib\\site-packages (from progressbar2) (1.16.0)\n",
      "Collecting python-utils>=2.3.0\n",
      "  Downloading python_utils-2.6.3-py2.py3-none-any.whl (13 kB)\n",
      "Installing collected packages: python-utils, progressbar2\n",
      "Successfully installed progressbar2-3.55.0 python-utils-2.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31701883",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=nx.MultiGraph()\n",
    "if(True):\n",
    "    graph.add_edge(0,1,weight=1,edge_id=\"a\")\n",
    "    graph.add_edge(1,2,weight=1,edge_id=\"b\")\n",
    "    graph.add_edge(2,3,weight=2,edge_id=\"c\")\n",
    "    graph.add_edge(3,4,weight=1,edge_id=\"d\")\n",
    "    graph.add_edge(3,4,weight=1,edge_id=\"e\")\n",
    "print(graph.edges(data=True))\n",
    "l=graph.edges(3,data=\"edge_id\");i=0\n",
    "print(list(l)[1])\n",
    "\n",
    "\n",
    "for edge in graph.edges(data=True):\n",
    "    count_down=edge[2][\"weight\"]\n",
    "    while(count_down>0):\n",
    "        print(count_down)\n",
    "        count_down=count_down-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=3\n",
    "#while(i<num_frame):# doesnt work or my graph are the same\n",
    "while(i<3):\n",
    "    start = time.time()\n",
    "\n",
    "    print (\"-------------------------------------\")\n",
    "    #laplacian marche\n",
    "    val = laplacian_similarity(sous_graph[0],sous_graph[i])\n",
    "    #val1=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=60,upper_bound=1e10)\n",
    "    #val2=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=120,upper_bound=1e10)\n",
    "    #val3=nx.graph_edit_distance(sous_graph[0],sous_graph[i],timeout=180,upper_bound=1e10)\n",
    "    #print (\"comparing \",hex(id(sous_graph[0])),\" and \",hex(id(sous_graph[i])))\n",
    "    #print (val1,\" \",val2,\" \",val3) \n",
    "    print(sous_graph[0])\n",
    "    print(sous_graph[i]) \n",
    "    print(\" similarity = \",val)\n",
    "    print(\"---laplacian similarity = %s seconds ---\" %         f\"{(time.time() - start):.4}\"    );start = time.time()\n",
    "\n",
    "    print (\"-------------------------------------\")\n",
    "    i=i+1\n",
    "''' \n",
    "plan,strategie , objectif\n",
    "changement de plan\n",
    "probleme , le poid des arc devien quoi ? \n",
    "comment ajouter amt apres coup , il suffit de l'ajouter sur les donnée\n",
    "avan le SOM\n",
    "                                            probably better\n",
    "j'inverse le graph                |  je le coupe en n sous_graphs\n",
    "je le coupe en n sous_graphs      |  j'inverse les sous_graphs\n",
    "\n",
    "\n",
    "je compresse les sous graphs \n",
    "je SOM sur les cous graphs\n",
    "\n",
    "complexité= O(n*tps_compression + SOM) // SOM = 6min = negligeable\n",
    "'''    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acdcd6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_somme(a):\n",
    "    if(a<=0): \n",
    "        return 0\n",
    "    print(\".\")\n",
    "    return recur_somme(a-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2de2977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recur_somme(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dcee252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965.25\n",
      "0.9961401355721147\n",
      "0.9982567822910758\n"
     ]
    }
   ],
   "source": [
    "print(2145*0.45)\n",
    "print(553574/(2145+553574))\n",
    "print(1 - (2145/553574))#accuracy 9942\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5054f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n"
     ]
    }
   ],
   "source": [
    "a_float = 3.14159\n",
    "limited_float = round(a_float, 2)\n",
    "print(limited_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285afe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c09fa810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "full_path=os.path.abspath('../../data')+'\\\\'+'X_train_1_2_svm.csv'\n",
    "xtrain_transformed_complique=pd.read_csv(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "426c0dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                    0.000000\n",
      "merchant                      0.850713\n",
      "category                      0.452436\n",
      "amt                          -0.407384\n",
      "gender                        0.909391\n",
      "state                         0.022993\n",
      "zip                          -0.749119\n",
      "lat                          -0.483394\n",
      "long                          0.657646\n",
      "city_pop                     -0.282897\n",
      "dob                          -0.885034\n",
      "unix_time                    -1.918231\n",
      "merch_lat                    -0.493372\n",
      "merch_long                    0.593891\n",
      "delta_time                   -0.680384\n",
      "delta_amt                    -0.000092\n",
      "delta_time_category          -0.646007\n",
      "delta_amt_category           -0.000050\n",
      "delta_time_merchant          -0.693667\n",
      "delta_amt_merchant            0.001110\n",
      "avg_amt                      -1.188891\n",
      "delta_avg_amt                -0.000153\n",
      "avg_amt_category             -0.765787\n",
      "delta_avg_amt_category        0.000308\n",
      "avg_amt_merchant             -0.301299\n",
      "avg_amt_state                -3.619995\n",
      "avg_amt_city                 -2.219214\n",
      "avg_amt_job                  -2.617976\n",
      "delta_avg_amt_category_job    0.000481\n",
      "month                        -1.513136\n",
      "day                          -0.972908\n",
      "hour                         -1.877778\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(xtrain_transformed_complique.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9892d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "378 xgboost ( 535.5 minutes) + 378 regresions lineaires (??? minutes)\n",
      "ou 1 seul shap , de 400 features (je te raconte pas le tps d'exe de xgboost )\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.comb(28,2))\n",
    "print(math.comb(28,2),\"xgboost (\",math.comb(28,2)*(85/60),\"minutes) +\",math.comb(28,2),\"regresions lineaires (??? minutes)\")\n",
    "print(\"ou 1 seul shap , de 400 features (je te raconte pas le tps d'exe de xgboost )\")\n",
    "#feature_1 feature_2 .. feature_28 graph_link_A_B graph_link_*_* ...\n",
    "#pour calculer l'existance du lien entre a et b \n",
    "#on prend le dataset composé de la feature A et B , on fait une regression lineaire \n",
    "# les points on une distance a la droite généré ,point=coordonée (A,B)\n",
    "#si la distance est plus grande que ... alors on met 1 sinon on met 0 \n",
    "# et voila on a remplis 1 graph_link_A_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acf85d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---boucle inutile = 0.32631421089172363 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "a=0\n",
    "start = time.time()\n",
    "for i in  range(5000000):\n",
    "    a=1\n",
    "\n",
    "print(\"---boucle inutile = %s seconds ---\" % (time.time() - start));start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ce5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
