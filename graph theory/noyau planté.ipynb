{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6f3ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_exec=True\n",
    "first_download=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474313b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import terminé a : 12:30:52\n"
     ]
    }
   ],
   "source": [
    "#import librairies \n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import progressbar\n",
    "import time\n",
    "from time import process_time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "    \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score,classification_report,roc_auc_score,precision_score,recall_score, precision_recall_fscore_support \n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn_som.som import SOM\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from GEM.gem.utils      import graph_util, plot_util\n",
    "from GEM.gem.evaluation import visualize_embedding as viz\n",
    "from GEM.gem.evaluation import evaluate_graph_reconstruction as gr\n",
    "from GEM.gem.embedding.gf       import GraphFactorization\n",
    "#from GEM.gem.embedding.sdne     import SDNE\n",
    "#from argparse import ArgumentParser\n",
    "#from GraphEmbedding.ge import DeepWalk\n",
    "#from GraphEmbedding.ge import SDNE\n",
    "from karateclub.graph_embedding import Graph2Vec\n",
    "from karateclub.node_embedding.neighbourhood import HOPE\n",
    "from karateclub.node_embedding.neighbourhood import DeepWalk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_frame=200#arbitraire , a tester plus serieusement\n",
    "\n",
    "print(\"import terminé a :\",time.strftime(\"%H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d983ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "declaration de fonction terminé a : 12:37:40\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def deprecated_nn():\n",
    "    # manual f1 score \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #metrics=[\"accuracy\",f1]\n",
    "    start = time.time()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(len(xtrain_transformed_complique.columns),),\n",
    "                    activation='relu')),\n",
    "    model.add(BatchNormalization()),\n",
    "    model.add(Dense(16, activation='relu')),\n",
    "    model.add(Dense(8, activation='relu')),\n",
    "    model.add(Dropout(0.2)),\n",
    "    model.add(Dense(4, activation='relu')),\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001) #optimizer\n",
    "    los=tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", \n",
    "                  metrics=[\"accuracy\",f1])\n",
    "\n",
    "\n",
    "    history= model.fit(xtrain_transformed_complique, ytrain_transformed_complique\n",
    "                       ,epochs = 10, batch_size=128, verbose = 0)\n",
    "                       #,class_weight=weight)#didnt work\n",
    "    history_dictict = history.history\n",
    "    #sigmoid return values from 0 to 1 , not exactly 0 and 1\n",
    "    y_train_pred=(model.predict(xtrain_transformed_complique)>0.5).astype(\"int32\")\n",
    "    y_test_pred =(model.predict(xtest_transformed_complique) >0.5).astype(\"int32\")\n",
    "\n",
    "    print(classification_report(ytrain_transformed_complique,y_train_pred))\n",
    "    print(classification_report(ytest_transformed_complique,y_test_pred))\n",
    "\n",
    "    cl_nn=classification_report(ytest_transformed_complique,y_test_pred\n",
    "                                ,output_dict=True)\n",
    "    return cl_nn\n",
    "\n",
    "print(\"declaration de fonction terminé a :\",time.strftime(\"%H:%M:%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e6458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- import data_set = 323.01495718955994 seconds ---\n"
     ]
    }
   ],
   "source": [
    "if(first_download):    \n",
    "    #import le data_set complet --- import data_set = 28.00195622444153 seconds ---\n",
    "    start = time.time()\n",
    "\n",
    "    data_file= os.path.abspath('data')\n",
    "    full_path=data_file+'\\\\'+'fraudTrain.csv'   # unmodified train set\n",
    "    train_df=pd.read_csv(full_path)\n",
    "    full_path=data_file+'\\\\'+'fraudTest.csv'\n",
    "    test_df=pd.read_csv(full_path)\n",
    "\n",
    "\n",
    "\n",
    "    full_path=data_file+'\\\\'+'X_train_1_2_svm.csv'\n",
    "    xtrain_transformed_complique=pd.read_csv(full_path)\n",
    "    ytrain_transformed_complique=train_df['is_fraud'].iloc[:int(len(train_df)*0.8)]\n",
    "\n",
    "    full_path=data_file+'\\\\'+'X_val_1_2_svm.csv'\n",
    "    xval_transformed_complique=pd.read_csv(full_path)\n",
    "    yval_transformed_complique=train_df['is_fraud'].iloc[len(ytrain_transformed_complique):]\n",
    "\n",
    "\n",
    "    full_path=data_file+'\\\\'+'X_test_1_2_svm.csv'\n",
    "    xtest_transformed_complique=pd.read_csv(full_path)\n",
    "    ytest_transformed_complique=test_df['is_fraud']\n",
    "\n",
    "\n",
    "    train_df=train_df.drop(columns=['Unnamed: 0'])\n",
    "    test_df=test_df.drop(columns=['Unnamed: 0'])\n",
    "    xtrain_transformed_complique=xtrain_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "    xval_transformed_complique=xval_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "    xtest_transformed_complique=xtest_transformed_complique.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "    cols = xtrain_transformed_complique.columns.tolist()\n",
    "    print(cols)\n",
    "    first_download=False\n",
    "    \n",
    "print(\"--- import data_set = %s seconds ---\" % (time.time() - start));start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0acff625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1031372\n",
      "           1       0.96      0.80      0.87      5968\n",
      "\n",
      "    accuracy                           1.00   1037340\n",
      "   macro avg       0.98      0.90      0.94   1037340\n",
      "weighted avg       1.00      1.00      1.00   1037340\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.95      0.74      0.83      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.98      0.87      0.91    555719\n",
      "weighted avg       1.00      1.00      1.00    555719\n",
      "\n",
      "choosen model precision:    1  f1-score:    1\n"
     ]
    }
   ],
   "source": [
    "cl=deprecated_nn()\n",
    "\n",
    "print(\"choosen model precision: %4.f\" %cl[\"1\"][\"precision\"],\" f1-score: %.4f\" %cl[\"1\"]['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53c08036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosen model precision: 0.9524  f1-score: 0.8304\n"
     ]
    }
   ],
   "source": [
    "print(\"choosen model precision: %.4f\" %cl[\"1\"][\"precision\"],\" f1-score: %.4f\" %cl[\"1\"]['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92538d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
